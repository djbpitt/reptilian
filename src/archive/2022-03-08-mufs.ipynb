{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Alignment with MUFS (maximal unambiguous frequent sequences)\n",
    "## What weâ€™ve learned\n",
    "\n",
    "1. Unambiguous MFS is better (or, at least, not worse) than any alternative starting point.\n",
    "1. Full-depth partitioning reduces the complexity enormously, so if we do it first, we turn an unscalably large task into multiple much more scalable small tasks.\n",
    "1. After each full-depth partition, start from the beginning (create new MFS) inside each partition.\n",
    "\n",
    "## What we still need to learn\n",
    "\n",
    "1. At some point we run out of full-depth partitions and have to do something different, and we haven't yet decided what that something different is.\n",
    "1. Length matters, so once we run out of full-depth, depth is no longer paramount. Cf. our earlier block priority based on a balancing of depth, length, and token infrequency.\n",
    "1. High-frequency tokens may lead to spurious alignments. We can tabulate token frequencies since we have to touch every token anyway, and then treat tokens with a frequency above a certain threshold as if they were ambiguous.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "1. Build MFS OOTB, keeping only first instance in case of repetition. Use compact feature to remove subsequences. (Requires more elaborate source code, and not the briefer one below.) Or use topk instead of frequent?\n",
    "1. Prioritize MFS based first on depth and then length. Start with only full-depth MFS.\n",
    "1. Place MFS tokens in order, checking each token for ambiguity and placing all of the unambiguous ones.\n",
    "1. After each full-depth partitioning, each partition is a separate alignment task, so go back to step #1, above, separately for each partition and build new MFS.\n",
    "1. When no more full-depths MFSs, change strategy. How? MFS but not full depth? Back to blocks?\n",
    "\n",
    "## What to do next\n",
    "\n",
    "1. Identify ambiguous tokens in MFS so that we can skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "from collections import defaultdict, deque\n",
    "from typing import Set, List\n",
    "from dataclasses import dataclass\n",
    "from bitarray import bitarray\n",
    "import networkx as nx\n",
    "import re\n",
    "import queue\n",
    "\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Load data into plain_text_witnesses (dictionary)\n",
    "#\n",
    "# Load first chapter of six editions of the Origin of species from disk\n",
    "# Each paragraph is a line, with trailing newlines and intervening blank lines, which we strip on import\n",
    "# sigla = ['w0', 'w1', 'w2', 'w3', 'w4', 'w5']\n",
    "# filenames = ['darwin1859.txt', 'darwin1860.txt', 'darwin1861.txt', 'darwin1866.txt', 'darwin1869.txt', 'darwin1872.txt', ]\n",
    "sigla = ['w0', 'w3', 'w4']\n",
    "filenames = ['darwin1859.txt', 'darwin1866.txt', 'darwin1869.txt']\n",
    "first_paragraph = 0\n",
    "last_paragraph = 1\n",
    "how_many_paragraphs = last_paragraph - first_paragraph\n",
    "plain_text_witnesses = {}\n",
    "for siglum, filename in zip(sigla, filenames):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line for line in lines if line != '\\n']\n",
    "        plain_text_witnesses[siglum] = \" \".join(lines[first_paragraph : last_paragraph])\n",
    "if debug:\n",
    "    print(f\"{how_many_paragraphs} paragraphs from {len(sigla)} witnesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Tokenize witnesses\n",
    "def tokenize_witnesses(witness_strings: List[str]): # one string per witness\n",
    "    '''Return list of witnesses, each represented by a list of tokens'''\n",
    "    # TODO: handle punctuation, upper- vs lowercase\n",
    "    witnesses = []\n",
    "    for witness_string in witness_strings:\n",
    "        witness_tokens = witness_string.split()\n",
    "        witnesses.append(witness_tokens)\n",
    "    return witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Witness sigla and witness token lists\n",
    "witness_sigla = [key for key in plain_text_witnesses.keys()]\n",
    "witness_token_lists = tokenize_witnesses([value for value in plain_text_witnesses.values()]) # list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create MFS; void, updates global (results)\n",
    "# TODO: get rid of global (challenging with a recursive function)\n",
    "# TODO: get rid of brute force repeated transitions\n",
    "def frequent_rec(patt, mdb):\n",
    "    \"\"\"Add a docstring someday\"\"\"\n",
    "    results.append((len(mdb), patt))\n",
    "    print(len(results))\n",
    "    if len(results) > 10:\n",
    "        print(results)\n",
    "        raise Exception(\"Results list too long!\")\n",
    "\n",
    "    occurs = defaultdict(list) # keys are token strings, values are lists of tuples of (witness number, witness token offset)\n",
    "    for (i, startpos) in mdb:\n",
    "        seq = db[i] # witness tokens\n",
    "        for j in range(startpos + 1, len(seq)): # index into witness tokens\n",
    "            l = occurs[seq[j]] # list of tuples of positions previously associated with (witness i, token at position j)\n",
    "            if len(l) == 0 or l[-1][0] != i: # if no entries for this token yet or same as the last one\n",
    "                l.append((i, j))\n",
    "    for (c, newmdb) in occurs.items(): # c is word token, newmdb is list of tuples\n",
    "        if len(newmdb) >= minsup: # number of tuples (occurrences of c in vocabulary)\n",
    "            frequent_rec(patt + [(c, newmdb)], newmdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "[(3, []), (3, [('WHEN', [(0, 0), (1, 3), (2, 3)])]), (3, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)]), ('the', [(0, 4), (1, 7)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)]), ('the', [(0, 4), (1, 7)]), ('individuals', [(0, 5), (1, 8)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)]), ('the', [(0, 4), (1, 7)]), ('individuals', [(0, 5), (1, 8)]), ('of', [(0, 6), (1, 9)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)]), ('the', [(0, 4), (1, 7)]), ('individuals', [(0, 5), (1, 8)]), ('of', [(0, 6), (1, 9)]), ('the', [(0, 7), (1, 10)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)]), ('the', [(0, 4), (1, 7)]), ('individuals', [(0, 5), (1, 8)]), ('of', [(0, 6), (1, 9)]), ('the', [(0, 7), (1, 10)]), ('same', [(0, 8), (1, 11)])]), (2, [('WHEN', [(0, 0), (1, 3), (2, 3)]), ('we', [(0, 1), (1, 4), (2, 4)]), ('look', [(0, 2), (1, 5)]), ('to', [(0, 3), (1, 6)]), ('the', [(0, 4), (1, 7)]), ('individuals', [(0, 5), (1, 8)]), ('of', [(0, 6), (1, 9)]), ('the', [(0, 7), (1, 10)]), ('same', [(0, 8), (1, 11)]), ('variety', [(0, 9), (1, 12)])])]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Results list too long!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1186/761839932.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# void; updates global results (list) in place\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# c is word token, newmdb is list of tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mminsup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# number of tuples (occurrences of c in vocabulary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mfrequent_rec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewmdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1186/3205007781.py\u001b[0m in \u001b[0;36mfrequent_rec\u001b[0;34m(patt, mdb)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results list too long!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moccurs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# keys are token strings, values are lists of tuples of (witness number, witness token offset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Results list too long!"
     ]
    }
   ],
   "source": [
    "# db = [\n",
    "#     [\"the\", \"red\", \"and\", \"the\", \"black\", \"cat\"],\n",
    "#     [\"the\", \"black\", \"and\", \"the\", \"red\", \"cat\"],\n",
    "#     [\"the\", \"black\", \"cat\"],\n",
    "# ]\n",
    "db = witness_token_lists\n",
    "minsup = 2 # global constant, used by frequent_rec()\n",
    "\n",
    "results = []\n",
    "\n",
    "frequent_rec([], [(i, -1) for i in range(len(db))]) # void; updates global results (list) in place\n",
    "\n",
    "for result in sorted(results, key=lambda x: (x[0], len(x[1])), reverse=True):\n",
    "    pp.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}