{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Resume here\n",
    "\n",
    "## What weâ€™ve learned\n",
    "\n",
    "1. Unambiguous MFS is better (or, at least, not worse) than any alternative starting point.\n",
    "1. Full-depth partitioning reduces the complexity enormously, so if we do it first, we turn an unscalably large task into multiple much more scalable small tasks.\n",
    "1. After each full-depth partition, start from the beginning (create new MFS) inside each partition.\n",
    "\n",
    "## What we still need to learn\n",
    "\n",
    "1. At some point we run out of full-depth partitions and have to do something different, and we haven't yet decided what that something different is.\n",
    "1. Length matters, so once we run out of full-depth, depth is no longer paramount. Cf. our earlier block priority based on a balancing of depth, length, and token infrequency.\n",
    "1. High-frequency tokens may lead to spurious alignments. We can tabulate token frequencies since we have to touch every token anyway, and then treat tokens with a frequency above a certain threshold as if they were ambiguous.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "1. Build MFS OOTB, keeping only first instance in case of repetition. Use compact feature to remove subsequences. (Requires more elaborate source code, and not the briefer one below.) Or use topk instead of frequent?\n",
    "1. Prioritize MFS based first on depth and then length. Start with only full-depth MFS.\n",
    "1. Place MFS tokens in order, checking each token for ambiguity and placing all of the unambiguous ones.\n",
    "1. After each full-depth partitioning, each partition is a separate alignment task, so go back to step #1, above, separately for each partition and build new MFS.\n",
    "1. When no more full-depths MFSs, change strategy. How? MFS but not full depth? Back to blocks?\n",
    "\n",
    "## What to do next\n",
    "\n",
    "1. Identify ambiguous tokens in MFS so that we can skip them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, [('the', [(0, 0), (1, 0), (2, 0)]), ('black', [(0, 4), (1, 1), (2, 1)]), ('cat', [(0, 5), (1, 5), (2, 2)])])\n",
      "(3, [('the', [(0, 0), (1, 0), (2, 0)]), ('black', [(0, 4), (1, 1), (2, 1)])])\n",
      "(3, [('the', [(0, 0), (1, 0), (2, 0)]), ('cat', [(0, 5), (1, 5), (2, 2)])])\n",
      "(3, [('black', [(0, 4), (1, 1), (2, 1)]), ('cat', [(0, 5), (1, 5), (2, 2)])])\n",
      "(3, [('the', [(0, 0), (1, 0), (2, 0)])])\n",
      "(3, [('black', [(0, 4), (1, 1), (2, 1)])])\n",
      "(3, [('cat', [(0, 5), (1, 5), (2, 2)])])\n",
      "(3, [])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('and', [(0, 2), (1, 2)]), ('the', [(0, 3), (1, 3)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('red', [(0, 1), (1, 4)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('and', [(0, 2), (1, 2)]), ('the', [(0, 3), (1, 3)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('and', [(0, 2), (1, 2)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('the', [(0, 3), (1, 3)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('and', [(0, 2), (1, 2)]), ('the', [(0, 3), (1, 3)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('red', [(0, 1), (1, 4)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('and', [(0, 2), (1, 2)])])\n",
      "(2, [('the', [(0, 0), (1, 0), (2, 0)]), ('the', [(0, 3), (1, 3)])])\n",
      "(2, [('red', [(0, 1), (1, 4)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('and', [(0, 2), (1, 2)]), ('the', [(0, 3), (1, 3)])])\n",
      "(2, [('and', [(0, 2), (1, 2)]), ('cat', [(0, 5), (1, 5)])])\n",
      "(2, [('red', [(0, 1), (1, 4)])])\n",
      "(2, [('and', [(0, 2), (1, 2)])])\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def frequent_rec(patt, mdb):\n",
    "    results.append((len(mdb), patt))\n",
    "\n",
    "    occurs = defaultdict(list) # keys are token strings, values are lists of tuples of (witness number, witness token offset)\n",
    "    for (i, startpos) in mdb:\n",
    "        seq = db[i] # witness tokens\n",
    "        for j in range(startpos + 1, len(seq)): # index into witness tokens\n",
    "            l = occurs[seq[j]] # list of tuples of positions previously associated with (witness i, token at position j)\n",
    "            if len(l) == 0 or l[-1][0] != i: # if no entries for this token yet or same as the last one\n",
    "                l.append((i, j))\n",
    "\n",
    "#     pp.pprint(patt)\n",
    "#     pp.pprint(occurs)\n",
    "\n",
    "    for (c, newmdb) in occurs.items(): # c is word token, newmdb is list of tuples\n",
    "        if len(newmdb) >= minsup: # number of tuples (occurrences of c in vocabulary)\n",
    "            frequent_rec(patt + [(c, newmdb)], newmdb)\n",
    "\n",
    "db = [\n",
    "    [\"the\", \"red\", \"and\", \"the\", \"black\", \"cat\"],\n",
    "    [\"the\", \"black\", \"and\", \"the\", \"red\", \"cat\"],\n",
    "    [\"the\", \"black\", \"cat\"],\n",
    "]\n",
    "\n",
    "# db = [\n",
    "#     [0, 1, 2, 3, 4],\n",
    "#     [1, 1, 1, 3, 4],\n",
    "#     [2, 1, 2, 2, 0],\n",
    "#     [1, 1, 1, 2, 2],\n",
    "# ]\n",
    "\n",
    "minsup = 2\n",
    "\n",
    "results = []\n",
    "\n",
    "frequent_rec([], [(i, -1) for i in range(len(db))]) # void; updates global results (list) in place\n",
    "\n",
    "for result in sorted(results, key=lambda x: (x[0], len(x[1])), reverse=True):\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}