{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Collation with decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find ngrams and positions in witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# two witnesses, with repetition and transposition\n",
    "w1 = \"the red and the black cat\"\n",
    "w2 = \"the black and the red cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def tokenize_witnesses(w1_string, w2_string):\n",
    "    '''Return list of witnesses, each represented by a list of tokens'''\n",
    "    w1_tokens = w1.split()\n",
    "    w2_tokens = w2.split()\n",
    "    witnesses = [w1_tokens, w2_tokens]\n",
    "    return witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'red', 'and', 'the', 'black', 'cat'], ['the', 'black', 'and', 'the', 'red', 'cat']]\n"
     ]
    }
   ],
   "source": [
    "witnesses = tokenize_witnesses(w1, w2)\n",
    "print(witnesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "# create a function that creates n-grams and returns the offsets\n",
    "def compute_ngrams(witness, n):\n",
    "   output = defaultdict(list)\n",
    "   for i in range(len(witness)-n+1):\n",
    "       g = ' '.join(witness[i:i+n])\n",
    "       output[g].append(i)\n",
    "   return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'the': [0, 3], 'red': [1], 'and': [2], 'black': [4], 'cat': [5]})\n",
      "defaultdict(<class 'list'>, {'the red': [0], 'red and': [1], 'and the': [2], 'the black': [3], 'black cat': [4]})\n",
      "defaultdict(<class 'list'>, {'the': [0, 3], 'black': [1], 'and': [2], 'red': [4], 'cat': [5]})\n",
      "defaultdict(<class 'list'>, {'the black': [0], 'black and': [1], 'and the': [2], 'the red': [3], 'red cat': [4]})\n"
     ]
    }
   ],
   "source": [
    "for witness in witnesses:\n",
    "    print(compute_ngrams(witness, 1))\n",
    "    print(compute_ngrams(witness, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the red', 'and the', 'the black'}\n"
     ]
    }
   ],
   "source": [
    "# find bigrams common to the two witnesses\n",
    "w1_bigrams = compute_ngrams(witnesses[0], 2)\n",
    "w2_bigrams = compute_ngrams(witnesses[1], 2)\n",
    "shared_keys = w1_bigrams.keys() & w2_bigrams.keys()\n",
    "print(shared_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_ngrams_all(witness):\n",
    "   '''Create a function that creates n-grams and returns the offsets'''\n",
    "   output = defaultdict(list)\n",
    "   output2 = {}\n",
    "   for n in range(1, len(witness) + 1):\n",
    "       for i in range(len(witness)-n+1):\n",
    "           g = ' '.join(witness[i:i+n])\n",
    "           output[g].append(i)\n",
    "           output2[g] = n\n",
    "   return output, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 defaultdict(<class 'list'>, {'the': [0, 3], 'red': [1], 'and': [2], 'black': [4], 'cat': [5], 'the red': [0], 'red and': [1], 'and the': [2], 'the black': [3], 'black cat': [4], 'the red and': [0], 'red and the': [1], 'and the black': [2], 'the black cat': [3], 'the red and the': [0], 'red and the black': [1], 'and the black cat': [2], 'the red and the black': [0], 'red and the black cat': [1], 'the red and the black cat': [0]})\n",
      "w2 defaultdict(<class 'list'>, {'the': [0, 3], 'black': [1], 'and': [2], 'red': [4], 'cat': [5], 'the black': [0], 'black and': [1], 'and the': [2], 'the red': [3], 'red cat': [4], 'the black and': [0], 'black and the': [1], 'and the red': [2], 'the red cat': [3], 'the black and the': [0], 'black and the red': [1], 'and the red cat': [2], 'the black and the red': [0], 'black and the red cat': [1], 'the black and the red cat': [0]})\n",
      "{'the': 1, 'red': 1, 'and': 1, 'black': 1, 'cat': 1, 'the red': 2, 'red and': 2, 'and the': 2, 'the black': 2, 'black cat': 2, 'the red and': 3, 'red and the': 3, 'and the black': 3, 'the black cat': 3, 'the red and the': 4, 'red and the black': 4, 'and the black cat': 4, 'the red and the black': 5, 'red and the black cat': 5, 'the red and the black cat': 6, 'black and': 2, 'red cat': 2, 'the black and': 3, 'black and the': 3, 'and the red': 3, 'the red cat': 3, 'the black and the': 4, 'black and the red': 4, 'and the red cat': 4, 'the black and the red': 5, 'black and the red cat': 5, 'the black and the red cat': 6}\n"
     ]
    }
   ],
   "source": [
    "# compute ngrams for all (both) witnesses\n",
    "ngram_offset_by_witness_dict = {}\n",
    "ngram_length = {}\n",
    "for index, witness in enumerate(witnesses):\n",
    "    map1, map2 = compute_ngrams_all(witness)\n",
    "    ngram_offset_by_witness_dict['w' + str(index + 1)] = map1\n",
    "    ngram_length.update(map2)\n",
    "\n",
    "for key in ngram_offset_by_witness_dict.keys():\n",
    "    print(key, ngram_offset_by_witness_dict[key])\n",
    "\n",
    "print(ngram_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'black', 'the red', 'red', 'the', 'the black', 'cat', 'and', 'and the'}\n"
     ]
    }
   ],
   "source": [
    "# find keys shared by *all* witnesses\n",
    "shared_ngrams = set(ngram_offset_by_witness_dict[\"w1\"].keys())\n",
    "for value in ngram_offset_by_witness_dict.values():\n",
    "    shared_ngrams = shared_ngrams.intersection(value.keys())\n",
    "\n",
    "print(shared_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'black': [(4, 1)], 'the red': [(0, 3)], 'red': [(1, 4)], 'the': [(0, 0), (0, 3), (3, 0), (3, 3)], 'the black': [(3, 0)], 'cat': [(5, 5)], 'and': [(2, 2)], 'and the': [(2, 2)]})\n"
     ]
    }
   ],
   "source": [
    "# use shared keys to find potential alignments\n",
    "# NB: works for only two witnesses\n",
    "# output format: {ngram : [(0,1), (2,3)]}, where \n",
    "#   the two entries in each tuple are for witnesses A and B\n",
    "from collections import defaultdict\n",
    "\n",
    "potential_alignments = defaultdict(list)\n",
    "for ngram in shared_ngrams:\n",
    "    for w1_offset in ngram_offset_by_witness_dict['w1'][ngram]:\n",
    "        for w2_offset in ngram_offset_by_witness_dict['w2'][ngram]:\n",
    "            potential_alignments[ngram].append((w1_offset, w2_offset))\n",
    "\n",
    "print(potential_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {(4, 1): ['black'], (0, 3): ['the red', 'the'], (1, 4): ['red'], (0, 0): ['the'], (3, 0): ['the', 'the black'], (3, 3): ['the'], (5, 5): ['cat'], (2, 2): ['and', 'and the']})\n"
     ]
    }
   ],
   "source": [
    "# Find actual alignments (ngrams with positions in witnesses)\n",
    "#\n",
    "# Build dictionary of offset_tuple : list_of_ngrams\n",
    "#\n",
    "# Source: https://stackoverflow.com/questions/6190331/how-to-implement-an-ordered-default-dict\n",
    "#\n",
    "# agglomerate = collections.OrderedDict()\n",
    "# for i, x in some_generator():\n",
    "#     agglomerate.setdefault(i, []).append(x)\n",
    "#\n",
    "# Tuples of offsets are keys, sorted; values are lists of ngrams at those offsets\n",
    "\n",
    "alignments = defaultdict(list)\n",
    "for key,value in potential_alignments.items():\n",
    "    for t in value:\n",
    "        alignments[t].append(key)\n",
    "\n",
    "print(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, ('the',)), (0, 3, ('the red', 'the')), (1, 4, ('red',)), (2, 2, ('and the', 'and')), (3, 0, ('the black', 'the')), (3, 3, ('the',)), (4, 1, ('black',)), (5, 5, ('cat',))]\n"
     ]
    }
   ],
   "source": [
    "# Create list of tuples (A-position:int, B-position:int, (ngrams), sorted by A position\n",
    "# Sort ngrams by token count from high to low\n",
    "# ngrams are in a tuple, rather than list, to make them hashable, and therefore set-able\n",
    "#\n",
    "# sorted(alignments.items()) # sorts, but outputs tuples\n",
    "import collections\n",
    "sorted_alignments_witness_A = []\n",
    "for key in sorted(alignments):\n",
    "    sorted_alignments_witness_A.append((key[0],key[1], tuple(sorted(alignments[key], key=lambda x: ngram_length[x], reverse=True ))))\n",
    "\n",
    "print(sorted_alignments_witness_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, ('the',))\n",
      "(0, 3, ('the red', 'the'))\n",
      "(1, 4, ('red',))\n",
      "(2, 2, ('and the', 'and'))\n",
      "(3, 0, ('the black', 'the'))\n",
      "(3, 3, ('the',))\n",
      "(4, 1, ('black',))\n",
      "(5, 5, ('cat',))\n"
     ]
    }
   ],
   "source": [
    "# Does it work?\n",
    "for entry in sorted_alignments_witness_A:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, ('the',)), (3, 0, ('the black', 'the')), (4, 1, ('black',)), (2, 2, ('and the', 'and')), (0, 3, ('the red', 'the')), (3, 3, ('the',)), (1, 4, ('red',)), (5, 5, ('cat',))]\n"
     ]
    }
   ],
   "source": [
    "# TODO: No need to flip and then flip again\n",
    "# Sort dictionary of offset_tuple : list_of_ngrams by tuple; Prefer witness B offsets over witness A offsets\n",
    "# Sort ngrams by length \n",
    "#\n",
    "flipped_witness_offsets = { (k[1], k[0]): v for k,v in alignments.items() }\n",
    "# print(flipped_witness_offsets)\n",
    "\n",
    "sorted_alignments_witness_B = []\n",
    "for key in sorted(flipped_witness_offsets): # flip them back to write A before B\n",
    "    sorted_alignments_witness_B.append((key[1], key[0], tuple(sorted(flipped_witness_offsets[key], key=lambda x: ngram_length[x], reverse=True ))))\n",
    "\n",
    "print(sorted_alignments_witness_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### A decision tree node stores the following properties:\n",
    "* unique id\n",
    "* current location in witness A\n",
    "* current location in witness B\n",
    "* parent (except root)\n",
    "* children\n",
    "* aligned patterns\n",
    "* potential alignments by A\n",
    "* potential alignments by B\n",
    "\n",
    "Edges are not stored separately; edge information is represented by parent and children properties of node\n",
    "\n",
    "### Implement with nested dictionaries:\n",
    "* {id:int : properties:dict} for each node\n",
    "* properties (7) : \n",
    "  * current-location-in-A:int (id of node)\n",
    "  * current-location-in-B:int (id of node)\n",
    "  * parent : id:int\n",
    "  * children : [id:int]\n",
    "  * aligned-patterns : [(offsetA:int, offsetB:int, ngram:str)]\n",
    "  * potential-alignments-by-A : [(offsetA:int, offsetB:int, ngram:str)]\n",
    "  * potential-alignments-by-B : [(offsetB:int, offsetA:int, ngram:str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create outer dictionary for decision tree nodes\n",
    "decision_tree = {}\n",
    "\n",
    "# Add root node\n",
    "decision_tree[0] = {}\n",
    "\n",
    "# Supply properties for root node\n",
    "decision_tree[0]['id'] = 0 # what's my key?\n",
    "decision_tree[0]['current-location-in-A'] = -1 # 0 would be the first position\n",
    "decision_tree[0]['current-location-in-B'] = -1\n",
    "decision_tree[0]['parent'] = None # integer\n",
    "decision_tree[0]['children'] = []\n",
    "decision_tree[0]['aligned-patterns'] = []\n",
    "decision_tree[0]['potential-alignments-by-A'] = sorted_alignments_witness_A\n",
    "decision_tree[0]['potential-alignments-by-B'] = sorted_alignments_witness_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'current-location-in-A': -1,\n",
       " 'current-location-in-B': -1,\n",
       " 'parent': None,\n",
       " 'children': [],\n",
       " 'aligned-patterns': [],\n",
       " 'potential-alignments-by-A': [(0, 0, ('the',)),\n",
       "  (0, 3, ('the red', 'the')),\n",
       "  (1, 4, ('red',)),\n",
       "  (2, 2, ('and the', 'and')),\n",
       "  (3, 0, ('the black', 'the')),\n",
       "  (3, 3, ('the',)),\n",
       "  (4, 1, ('black',)),\n",
       "  (5, 5, ('cat',))],\n",
       " 'potential-alignments-by-B': [(0, 0, ('the',)),\n",
       "  (3, 0, ('the black', 'the')),\n",
       "  (4, 1, ('black',)),\n",
       "  (2, 2, ('and the', 'and')),\n",
       "  (0, 3, ('the red', 'the')),\n",
       "  (3, 3, ('the',)),\n",
       "  (1, 4, ('red',)),\n",
       "  (5, 5, ('cat',))]}"
      ]
     },
     "execution_count": 16,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look\n",
    "decision_tree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0, ('the',)), (0, 3, ('the red', 'the')), (3, 0, ('the black', 'the'))}\n"
     ]
    }
   ],
   "source": [
    "# Traverse from left to right, so children of root are all\n",
    "#   potential alignments at 0 in one or both witnesses\n",
    "#   In this case: four options, three of which are unique\n",
    "#   First item of first tuple is nearest position, so find all tuples with that value\n",
    "\n",
    "nearest_A_matches = [item for item in decision_tree[0]['potential-alignments-by-A'] if item[0] == decision_tree[0]['potential-alignments-by-A'][0][0]]\n",
    "nearest_B_matches = [item for item in decision_tree[0]['potential-alignments-by-B'] if item[1] == decision_tree[0]['potential-alignments-by-B'][0][1]]\n",
    "nearest_matches = {item for item in nearest_A_matches + nearest_B_matches}\n",
    "print(nearest_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Function to add child nodes recursively\n",
    "# Within children:\n",
    "#   Add parent\n",
    "#   Update current location in A and B\n",
    "#   Update aligned patterns\n",
    "#   Update potential alignments for A and B\n",
    "#\n",
    "# For each of the (three) items in the set of nearest_matches, create a child\n",
    "# Assign consecutive id values by counting size of dictionary = could break with multithreading\n",
    "\n",
    "def add_child(child_param: tuple, parent_id: int) -> dict:\n",
    "    # child looks like: (1, 2, ('hi mon', 'hi'))\n",
    "    # start location in A, in B, ngrams at that location\n",
    "    child = (child_param[0], child_param[1], child_param[2][0]) # prune ngrams to keep only longest\n",
    "    current_ngram_length = ngram_length[child[2]]\n",
    "    id = len(decision_tree)\n",
    "    decision_tree[id] = {}\n",
    "    decision_tree[id]['id'] = id\n",
    "    decision_tree[id]['current-location-in-A'] = child[0] + current_ngram_length - 1\n",
    "    decision_tree[id]['current-location-in-B'] = child[1] + current_ngram_length - 1\n",
    "    decision_tree[id]['parent'] = parent_id\n",
    "    decision_tree[id]['children'] = []\n",
    "    aligned_patterns = decision_tree[parent_id]['aligned-patterns'].copy()\n",
    "    aligned_patterns.append(child)\n",
    "    decision_tree[id]['aligned-patterns'] = aligned_patterns\n",
    "\n",
    "    # TODO: Because lists are sorted, once one is far enough to the right to avoid transposition,\n",
    "    #   all following ones are also okay (in this case, though, must process A and B separately)\n",
    "    # Similarly, once one ngram is safe, all shorter ones are also safe, and don't need to be checked\n",
    "    decision_tree[id]['potential-alignments-by-A'] = []\n",
    "    for p in decision_tree[parent_id]['potential-alignments-by-A']: # throw away potentials where no ngram can work\n",
    "        if p[0] > decision_tree[id]['current-location-in-A'] and p[1] > decision_tree[id]['current-location-in-B']:\n",
    "            new_ngram_list = [] # check each ngram in each remaining potential starting from the longest (left)\n",
    "            for q in p[2]:\n",
    "                q_ngram_length = ngram_length[q] # length of current ngram inside current potential\n",
    "                if p[0] + q_ngram_length > decision_tree[id]['current-location-in-A'] and p[1] + q_ngram_length > decision_tree[id]['current-location-in-B']: # keep the ones that don't entail transposition\n",
    "                    new_ngram_list.append(q)\n",
    "            decision_tree[id]['potential-alignments-by-A'].append((p[0], p[1], tuple(new_ngram_list))) # add potential, with pruned list of ngrams, to new potentials\n",
    "\n",
    "            # potentials by A and B are the same tuples, but sorted differently\n",
    "    decision_tree[id]['potential-alignments-by-B'] = sorted(decision_tree[id]['potential-alignments-by-A'], key=lambda x: (x[1], x[0]))\n",
    "\n",
    "    decision_tree[parent_id]['children'].append(id)\n",
    "    \n",
    "    # get nearest matches in new child node and prepare to recur over its children\n",
    "    nearest_A_matches = [item for item in decision_tree[id]['potential-alignments-by-A'] if item[0] == decision_tree[id]['potential-alignments-by-A'][0][0]]\n",
    "    nearest_B_matches = [item for item in decision_tree[id]['potential-alignments-by-B'] if item[1] == decision_tree[id]['potential-alignments-by-B'][0][1]]\n",
    "    nearest_matches = {item for item in nearest_A_matches + nearest_B_matches}\n",
    "    \n",
    "    # recursion ho!\n",
    "    for new_child in nearest_matches:\n",
    "        add_child(new_child, id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'current-location-in-A': -1,\n",
       "  'current-location-in-B': -1,\n",
       "  'parent': None,\n",
       "  'children': [1, 6, 8],\n",
       "  'aligned-patterns': [],\n",
       "  'potential-alignments-by-A': [(0, 0, ('the',)),\n",
       "   (0, 3, ('the red', 'the')),\n",
       "   (1, 4, ('red',)),\n",
       "   (2, 2, ('and the', 'and')),\n",
       "   (3, 0, ('the black', 'the')),\n",
       "   (3, 3, ('the',)),\n",
       "   (4, 1, ('black',)),\n",
       "   (5, 5, ('cat',))],\n",
       "  'potential-alignments-by-B': [(0, 0, ('the',)),\n",
       "   (3, 0, ('the black', 'the')),\n",
       "   (4, 1, ('black',)),\n",
       "   (2, 2, ('and the', 'and')),\n",
       "   (0, 3, ('the red', 'the')),\n",
       "   (3, 3, ('the',)),\n",
       "   (1, 4, ('red',)),\n",
       "   (5, 5, ('cat',))]},\n",
       " 1: {'id': 1,\n",
       "  'current-location-in-A': 0,\n",
       "  'current-location-in-B': 0,\n",
       "  'parent': 0,\n",
       "  'children': [2, 4],\n",
       "  'aligned-patterns': [(0, 0, 'the')],\n",
       "  'potential-alignments-by-A': [(1, 4, ('red',)),\n",
       "   (2, 2, ('and the', 'and')),\n",
       "   (3, 3, ('the',)),\n",
       "   (4, 1, ('black',)),\n",
       "   (5, 5, ('cat',))],\n",
       "  'potential-alignments-by-B': [(4, 1, ('black',)),\n",
       "   (2, 2, ('and the', 'and')),\n",
       "   (3, 3, ('the',)),\n",
       "   (1, 4, ('red',)),\n",
       "   (5, 5, ('cat',))]},\n",
       " 2: {'id': 2,\n",
       "  'current-location-in-A': 4,\n",
       "  'current-location-in-B': 1,\n",
       "  'parent': 1,\n",
       "  'children': [3],\n",
       "  'aligned-patterns': [(0, 0, 'the'), (4, 1, 'black')],\n",
       "  'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "  'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       " 3: {'id': 3,\n",
       "  'current-location-in-A': 5,\n",
       "  'current-location-in-B': 5,\n",
       "  'parent': 2,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [(0, 0, 'the'), (4, 1, 'black'), (5, 5, 'cat')],\n",
       "  'potential-alignments-by-A': [],\n",
       "  'potential-alignments-by-B': []},\n",
       " 4: {'id': 4,\n",
       "  'current-location-in-A': 1,\n",
       "  'current-location-in-B': 4,\n",
       "  'parent': 1,\n",
       "  'children': [5],\n",
       "  'aligned-patterns': [(0, 0, 'the'), (1, 4, 'red')],\n",
       "  'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "  'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       " 5: {'id': 5,\n",
       "  'current-location-in-A': 5,\n",
       "  'current-location-in-B': 5,\n",
       "  'parent': 4,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [(0, 0, 'the'), (1, 4, 'red'), (5, 5, 'cat')],\n",
       "  'potential-alignments-by-A': [],\n",
       "  'potential-alignments-by-B': []},\n",
       " 6: {'id': 6,\n",
       "  'current-location-in-A': 1,\n",
       "  'current-location-in-B': 4,\n",
       "  'parent': 0,\n",
       "  'children': [7],\n",
       "  'aligned-patterns': [(0, 3, 'the red')],\n",
       "  'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "  'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       " 7: {'id': 7,\n",
       "  'current-location-in-A': 5,\n",
       "  'current-location-in-B': 5,\n",
       "  'parent': 6,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [(0, 3, 'the red'), (5, 5, 'cat')],\n",
       "  'potential-alignments-by-A': [],\n",
       "  'potential-alignments-by-B': []},\n",
       " 8: {'id': 8,\n",
       "  'current-location-in-A': 4,\n",
       "  'current-location-in-B': 1,\n",
       "  'parent': 0,\n",
       "  'children': [9],\n",
       "  'aligned-patterns': [(3, 0, 'the black')],\n",
       "  'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "  'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       " 9: {'id': 9,\n",
       "  'current-location-in-A': 5,\n",
       "  'current-location-in-B': 5,\n",
       "  'parent': 8,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [(3, 0, 'the black'), (5, 5, 'cat')],\n",
       "  'potential-alignments-by-A': [],\n",
       "  'potential-alignments-by-B': []}}"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update root node to add children\n",
    "for child in nearest_matches:\n",
    "    add_child(child, 0)\n",
    "\n",
    "# take a look\n",
    "decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# get ready to visualize the decision tree in SVG\n",
    "import graphviz\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"440pt\" height=\"260pt\" viewBox=\"0.00 0.00 439.94 260.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 435.94,-256 435.94,4 -4,4\"/>\n<!-- 1 -->\n<g id=\"node1\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"131.2\" cy=\"-162\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"131.2\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">1:the</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"44.2\" cy=\"-90\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"44.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">2:black</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M113.17,-146.5C101.13,-136.81 85.08,-123.9 71.49,-112.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"73.39,-110 63.41,-106.46 69,-115.45 73.39,-110\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"141.2\" cy=\"-90\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"141.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">4:red</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>1-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133.67,-143.7C134.77,-135.98 136.09,-126.71 137.32,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"140.8,-118.5 138.75,-108.1 133.87,-117.51 140.8,-118.5\"/>\n</g>\n<!-- 0 -->\n<g id=\"node2\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"237.2\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"237.2\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0-&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M218.73,-220.81C202.65,-210.19 179.06,-194.61 160.42,-182.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"162.26,-179.32 151.99,-176.73 158.4,-185.16 162.26,-179.32\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"237.2\" cy=\"-162\" rx=\"53.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"237.2\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">6:the red</text>\n</g>\n<!-- 0&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>0-&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M237.2,-215.7C237.2,-207.98 237.2,-198.71 237.2,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240.7,-190.1 237.2,-180.1 233.7,-190.1 240.7,-190.1\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"370.2\" cy=\"-162\" rx=\"61.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"370.2\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">8:the black</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0-&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M257.69,-222.22C277.59,-211.74 308.27,-195.59 332.57,-182.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"334.31,-185.84 341.53,-178.09 331.05,-179.65 334.31,-185.84\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"44.2\" cy=\"-18\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"44.2\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3:cat</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M44.2,-71.7C44.2,-63.98 44.2,-54.71 44.2,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"47.7,-46.1 44.2,-36.1 40.7,-46.1 47.7,-46.1\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"141.2\" cy=\"-18\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"141.2\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">5:cat</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4-&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M141.2,-71.7C141.2,-63.98 141.2,-54.71 141.2,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"144.7,-46.1 141.2,-36.1 137.7,-46.1 144.7,-46.1\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"237.2\" cy=\"-90\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"237.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">7:cat</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6-&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M237.2,-143.7C237.2,-135.98 237.2,-126.71 237.2,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"240.7,-118.1 237.2,-108.1 233.7,-118.1 240.7,-118.1\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"370.2\" cy=\"-90\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"370.2\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">9:cat</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8-&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M370.2,-143.7C370.2,-135.98 370.2,-126.71 370.2,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"373.7,-118.1 370.2,-108.1 366.7,-118.1 373.7,-118.1\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create graph (based on https://github.com/interedition/collatex/blob/master/collatex-pythonport/collatex/display_module.py)\n",
    "# node id values must be strings\n",
    "a = graphviz.Digraph(format=\"svg\")\n",
    "for key,value in decision_tree.items():\n",
    "    if value['id'] != 0:\n",
    "        node_id = str(value['id'])\n",
    "        a.node(node_id, label=node_id + ':' + value['aligned-patterns'][len(value['aligned-patterns']) - 1][2])\n",
    "        a.edge(str(value['parent']), str(value['id']))\n",
    "SVG(a.view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}