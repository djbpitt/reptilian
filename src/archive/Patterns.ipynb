{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Collation with decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# two witnesses, with repetition and transposition\n",
    "w1 = \"\"\"the red and the black cat\"\"\"\n",
    "w2 = \"\"\"the black and the red cat\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find all ngrams in each witness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'red', 'and', 'the', 'black', 'cat'],\n",
       " ['the', 'black', 'and', 'the', 'red', 'cat']]"
      ]
     },
     "execution_count": 2,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_witnesses(w1_string, w2_string):\n",
    "    '''Return list of witnesses, each represented by a list of tokens'''\n",
    "    w1_tokens = w1.split()\n",
    "    w2_tokens = w2.split()\n",
    "    witnesses = [w1_tokens, w2_tokens]\n",
    "    return witnesses\n",
    "witnesses = tokenize_witnesses(w1, w2)\n",
    "witnesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define function to find positions of ngrams in witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_ngrams_all(witness):\n",
    "   '''Create a function that creates n-grams and returns the offsets'''\n",
    "   output = defaultdict(list)\n",
    "   output2 = {}\n",
    "   for n in range(1, len(witness) + 1):\n",
    "       for i in range(len(witness)-n+1):\n",
    "           g = ' '.join(witness[i:i+n])\n",
    "           output[g].append(i)\n",
    "           output2[g] = n\n",
    "   return output, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Store ngrams lengths in ngram_length dictionary\n",
    "\n",
    "Creates two dictionaries:\n",
    "\n",
    "1. *ngram_length* (key is ngram text, value is ngram token count)\n",
    "1. *ngram_offset_by_witness_dict* (key is witness, value is dictionary keyed by ngram, value is list of offsets of that ngram in that witness)\n",
    "\n",
    "*ngram_length* is used frequently. *ngram_offset_by_witness_dict* is used one, immediately below, to create combined representation of ngram text\n",
    "plus location in both witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1 defaultdict(<class 'list'>, {'the': [0, 3], 'red': [1], 'and': [2], 'black': [4], 'cat': [5], 'the red': [0], 'red and': [1], 'and the': [2], 'the black': [3], 'black cat': [4], 'the red and': [0], 'red and the': [1], 'and the black': [2], 'the black cat': [3], 'the red and the': [0], 'red and the black': [1], 'and the black cat': [2], 'the red and the black': [0], 'red and the black cat': [1], 'the red and the black cat': [0]})\n",
      "w2 defaultdict(<class 'list'>, {'the': [0, 3], 'black': [1], 'and': [2], 'red': [4], 'cat': [5], 'the black': [0], 'black and': [1], 'and the': [2], 'the red': [3], 'red cat': [4], 'the black and': [0], 'black and the': [1], 'and the red': [2], 'the red cat': [3], 'the black and the': [0], 'black and the red': [1], 'and the red cat': [2], 'the black and the red': [0], 'black and the red cat': [1], 'the black and the red cat': [0]})\n",
      "{'the': 1, 'red': 1, 'and': 1, 'black': 1, 'cat': 1, 'the red': 2, 'red and': 2, 'and the': 2, 'the black': 2, 'black cat': 2, 'the red and': 3, 'red and the': 3, 'and the black': 3, 'the black cat': 3, 'the red and the': 4, 'red and the black': 4, 'and the black cat': 4, 'the red and the black': 5, 'red and the black cat': 5, 'the red and the black cat': 6, 'black and': 2, 'red cat': 2, 'the black and': 3, 'black and the': 3, 'and the red': 3, 'the red cat': 3, 'the black and the': 4, 'black and the red': 4, 'and the red cat': 4, 'the black and the red': 5, 'black and the red cat': 5, 'the black and the red cat': 6}\n"
     ]
    }
   ],
   "source": [
    "ngram_offset_by_witness_dict = {} # used to find shared ngrams (next cell)\n",
    "ngram_length = {} # used to look up ngram length (frequently)\n",
    "for index, witness in enumerate(witnesses):\n",
    "    map1, map2 = compute_ngrams_all(witness)\n",
    "    ngram_offset_by_witness_dict['w' + str(index + 1)] = map1\n",
    "    ngram_length.update(map2)\n",
    "\n",
    "for key in ngram_offset_by_witness_dict.keys():\n",
    "    print(key, ngram_offset_by_witness_dict[key])\n",
    "\n",
    "print(ngram_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Find keys shared by all (both) witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'and the', 'black', 'cat', 'red', 'the', 'the black', 'the red'}"
      ]
     },
     "execution_count": 5,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_ngrams = set(ngram_offset_by_witness_dict['w1'].keys()).intersection(set(ngram_offset_by_witness_dict['w2'].keys()))\n",
    "shared_ngrams # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use shared keys to find potential alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'the red': [(0, 3)],\n",
       "             'the': [(0, 0), (0, 3), (3, 0), (3, 3)],\n",
       "             'and': [(2, 2)],\n",
       "             'cat': [(5, 5)],\n",
       "             'the black': [(3, 0)],\n",
       "             'black': [(4, 1)],\n",
       "             'and the': [(2, 2)],\n",
       "             'red': [(1, 4)]})"
      ]
     },
     "execution_count": 6,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output format: {ngram : [(0,1), (2,3)]}, where \n",
    "#   the two entries in each tuple are for witnesses A and B\n",
    "# NOTE: works for only two witnesses\n",
    "from collections import defaultdict\n",
    "\n",
    "potential_alignments = defaultdict(list)\n",
    "for ngram in shared_ngrams:\n",
    "    for w1_offset in ngram_offset_by_witness_dict['w1'][ngram]:\n",
    "        for w2_offset in ngram_offset_by_witness_dict['w2'][ngram]:\n",
    "            potential_alignments[ngram].append((w1_offset, w2_offset))\n",
    "\n",
    "potential_alignments # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Define function to compute weight (relative length and frequency) of ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Formula to compute weight: depth / frequency * length\n",
    "#\n",
    "# depth is the number of witnesses a pattern appears in\n",
    "# frequency is the overall times a pattern occurs in the witness set\n",
    "# length is the number of tokens of a pattern\n",
    "\n",
    "def compute_ngram_weight(ngram):\n",
    "    depth = 2 # constant here; variable if we allow more than two witnesses\n",
    "    frequency = len(potential_alignments[ngram])\n",
    "    length = ngram_length[ngram]\n",
    "    return depth / frequency * length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create ordered dictionary, keyed by ngram text and sorted by ngram weight (high to low)\n",
    "\n",
    "Dictionaries preserve insertion order since Python 3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the red': 4.0,\n",
       " 'the black': 4.0,\n",
       " 'and the': 4.0,\n",
       " 'and': 2.0,\n",
       " 'cat': 2.0,\n",
       " 'black': 2.0,\n",
       " 'red': 2.0,\n",
       " 'the': 0.5}"
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_weights = defaultdict(float)\n",
    "for ngram in potential_alignments.keys():\n",
    "    ngram_weights[ngram] = (compute_ngram_weight(ngram))\n",
    "sorted_ngram_weights = {k: v for k, v in sorted(ngram_weights.items(), key=lambda item: item[1], reverse=True)}\n",
    "sorted_ngram_weights # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Use pandas dataframe instead of dictionary; columns are offsets, single ngrams, ngram weights\n",
    "## Create initial dictionary of all potential ngram alignments, keyed by offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 3): ['the red', 'the'],\n",
       " (3, 0): ['the black', 'the'],\n",
       " (2, 2): ['and the', 'and'],\n",
       " (5, 5): ['cat'],\n",
       " (4, 1): ['black'],\n",
       " (1, 4): ['red'],\n",
       " (0, 0): ['the'],\n",
       " (3, 3): ['the']}"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find actual alignments (ngrams with positions in witnesses)\n",
    "#\n",
    "# Build dictionary of offset_tuple : list_of_ngrams\n",
    "# Tuples of offsets are keys, sorted; values are lists of ngrams at those offsets, unsorted\n",
    "\n",
    "alignments_unsorted = defaultdict(list)\n",
    "for key,value in potential_alignments.items():\n",
    "    for t in value:\n",
    "        alignments_unsorted[t].append(key)\n",
    "# Sort ngrams for each key (pair of offsets) from longest to shortest\n",
    "alignments_sorted_values = {k: sorted(v, key=lambda x: ngram_length[x], reverse=True) for k, v in alignments_unsorted.items()}\n",
    "# Sort dictionary by weight of longest ngram at offset\n",
    "alignments = {k: v for k, v in sorted(alignments_sorted_values.items(), key=lambda item: ngram_weights[item[1][0]], reverse=True)}\n",
    "alignments # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Initialize pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create function to return token positions covered by ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def token_positions_involved_in_ngram(ngram: str, start_position: int) -> range:\n",
    "    return range(start_position, start_position + ngram_length[ngram])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create dataframe for alignment data\n",
    "\n",
    "The ngrams column holds a (mutable) list, which is risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[the red, the]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[the black, the]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[and the, and]</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[cat]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[black]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[red]</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[the]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[the]</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B            ngrams  weight\n",
       "0  0  3    [the red, the]     4.0\n",
       "1  3  0  [the black, the]     4.0\n",
       "2  2  2    [and the, and]     4.0\n",
       "3  5  5             [cat]     2.0\n",
       "4  4  1           [black]     2.0\n",
       "5  1  4             [red]     2.0\n",
       "6  0  0             [the]     0.5\n",
       "7  3  3             [the]     0.5"
      ]
     },
     "execution_count": 12,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([[k[0], k[1], v, sorted_ngram_weights[v[0]]] for k, v in alignments.items()], columns=['A', 'B', 'ngrams', 'weight'])\n",
    "df # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Add bitarrays for the two witnesses for the longest ngram in each pattern instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def find_committed_tokens(df_columns, token_offsets):\n",
    "    '''Return bitarray of tokens in witness committed by longest ngram in row\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    df_columns -- df view of rows x columns, where columns are:\n",
    "        0) start position of ngram in witness\n",
    "        1) list of ngrams in that row (extracts first, which is longest)\n",
    "    token_offsets -- Series of all token positions in witness\n",
    "        (sequential integers from 0, may be different for different witnesses)\n",
    "    '''\n",
    "    committed_tokens = np.arange(df_columns[0], df_columns[0] + ngram_length[df_columns[1][0]], 1)\n",
    "    return np.in1d(token_offsets, committed_tokens) # https://stackoverflow.com/questions/7088625/what-is-the-most-efficient-way-to-check-if-a-value-exists-in-a-numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>weight</th>\n",
       "      <th>ba_A</th>\n",
       "      <th>ba_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[the red, the]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[True, True, False, False, False, False]</td>\n",
       "      <td>[False, False, False, True, True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[the black, the]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[False, False, False, True, True, False]</td>\n",
       "      <td>[True, True, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[and the, and]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[False, False, True, True, False, False]</td>\n",
       "      <td>[False, False, True, True, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[cat]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[False, False, False, False, False, True]</td>\n",
       "      <td>[False, False, False, False, False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[black]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[False, False, False, False, True, False]</td>\n",
       "      <td>[False, True, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[red]</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[False, True, False, False, False, False]</td>\n",
       "      <td>[False, False, False, False, True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[the]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[True, False, False, False, False, False]</td>\n",
       "      <td>[True, False, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[the]</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[False, False, False, True, False, False]</td>\n",
       "      <td>[False, False, False, True, False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B            ngrams  weight                                       ba_A  \\\n",
       "0  0  3    [the red, the]     4.0   [True, True, False, False, False, False]   \n",
       "1  3  0  [the black, the]     4.0   [False, False, False, True, True, False]   \n",
       "2  2  2    [and the, and]     4.0   [False, False, True, True, False, False]   \n",
       "3  5  5             [cat]     2.0  [False, False, False, False, False, True]   \n",
       "4  4  1           [black]     2.0  [False, False, False, False, True, False]   \n",
       "5  1  4             [red]     2.0  [False, True, False, False, False, False]   \n",
       "6  0  0             [the]     0.5  [True, False, False, False, False, False]   \n",
       "7  3  3             [the]     0.5  [False, False, False, True, False, False]   \n",
       "\n",
       "                                        ba_B  \n",
       "0   [False, False, False, True, True, False]  \n",
       "1   [True, True, False, False, False, False]  \n",
       "2   [False, False, True, True, False, False]  \n",
       "3  [False, False, False, False, False, True]  \n",
       "4  [False, True, False, False, False, False]  \n",
       "5  [False, False, False, False, True, False]  \n",
       "6  [True, False, False, False, False, False]  \n",
       "7  [False, False, False, True, False, False]  "
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avoid itertuples; see https://realpython.com/numpy-array-programming/#what-is-vectorization\n",
    "# TODO: \n",
    "token_offsets_A = np.arange(0, len(witnesses[0]), 1) # list of token offsets (need to do witnesses separately, may be different lengths))\n",
    "token_offsets_B = np.arange(0, len(witnesses[1]), 1) # list of token offsets (need to do witnesses separately, may be different lengths))\n",
    "df['ba_A'] = df[['A', 'ngrams']].apply(find_committed_tokens, args=(token_offsets_A,), axis=1)\n",
    "df['ba_B'] = df[['B', 'ngrams']].apply(find_committed_tokens, args=(token_offsets_B,), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create root node of decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "decision_tree = {}\n",
    "\n",
    "# Add root node\n",
    "def create_root_node():\n",
    "    # Create outer dictionary for decision tree nodes\n",
    "    global decision_tree\n",
    "    decision_tree = {}\n",
    "\n",
    "    decision_tree[0] = {}\n",
    "\n",
    "    # Supply properties for root node\n",
    "    decision_tree[0]['id'] = 0 # what's my key?\n",
    "    decision_tree[0]['type'] = None # normally 'align' or 'transpose'\n",
    "    decision_tree[0]['parent'] = None # integer\n",
    "    decision_tree[0]['children'] = []\n",
    "    decision_tree[0]['aligned-patterns'] = []\n",
    "    decision_tree[0]['aligned-patterns-text'] = [] # debug\n",
    "    decision_tree[0]['transposed-patterns'] = []\n",
    "    decision_tree[0]['transposed-patterns-text'] = [] # debug\n",
    "    decision_tree[0]['blocked-patterns'] = []\n",
    "    decision_tree[0]['blocked-patterns-text'] = [] # debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 16,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the highest weight in the table. At the moment without masking.\n",
    "# Given the heightest weight make a selection of the rows equal to that weight.\n",
    "max = df['weight'].max()\n",
    "max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>ngrams</th>\n",
       "      <th>weight</th>\n",
       "      <th>ba_A</th>\n",
       "      <th>ba_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[the red, the]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[True, True, False, False, False, False]</td>\n",
       "      <td>[False, False, False, True, True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[the black, the]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[False, False, False, True, True, False]</td>\n",
       "      <td>[True, True, False, False, False, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[and the, and]</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[False, False, True, True, False, False]</td>\n",
       "      <td>[False, False, True, True, False, False]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B            ngrams  weight                                      ba_A  \\\n",
       "0  0  3    [the red, the]     4.0  [True, True, False, False, False, False]   \n",
       "1  3  0  [the black, the]     4.0  [False, False, False, True, True, False]   \n",
       "2  2  2    [and the, and]     4.0  [False, False, True, True, False, False]   \n",
       "\n",
       "                                       ba_B  \n",
       "0  [False, False, False, True, True, False]  \n",
       "1  [True, True, False, False, False, False]  \n",
       "2  [False, False, True, True, False, False]  "
      ]
     },
     "execution_count": 17,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rarest_patterns = df.loc[df['weight'] == max]\n",
    "rarest_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#         # child looks like: (1, 2, ('hi mon', 'hi'))\n",
    "#         # start location in A, in B, ngrams at that location\n",
    "#         child = (child[0], child[1], child[2][0]) # prune ngrams to keep only longest; NB: redefining \"child\" variable\n",
    "#         current_ngram_length = ngram_length[child[2]]\n",
    "#         id = len(decision_tree)\n",
    "#         decision_tree[id] = {}\n",
    "#         decision_tree[id]['id'] = id\n",
    "#         if child[0] == decision_tree[parent_id]['potential-alignments-by-A'][0][0] and child[1] == decision_tree[parent_id]['potential-alignments-by-B'][0][1]:\n",
    "#             decision_tree[id]['type'] = 'closest-in-both'\n",
    "#         else:\n",
    "#             decision_tree[id]['type'] = 'closest-in-one'\n",
    "#         decision_tree[id]['current-location-in-A'] = child[0] + current_ngram_length - 1\n",
    "#         decision_tree[id]['current-location-in-B'] = child[1] + current_ngram_length - 1\n",
    "#         decision_tree[id]['parent'] = parent_id\n",
    "#         decision_tree[id]['children'] = []\n",
    "#         aligned_patterns = decision_tree[parent_id]['aligned-patterns'].copy()\n",
    "#         aligned_patterns.append(child)\n",
    "#         decision_tree[id]['aligned-patterns'] = aligned_patterns\n",
    "#         transposed_patterns = decision_tree[parent_id]['transposed-patterns'].copy()\n",
    "#         decision_tree[id]['transposed-patterns'] = transposed_patterns\n",
    "\n",
    "#         # TODO: Because lists are sorted, once one is far enough to the right to avoid transposition,\n",
    "#         #   all following ones are also okay (in this case, though, must process A and B separately)\n",
    "#         # Similarly, once one ngram is safe, all shorter ones are also safe, and don't need to be checked\n",
    "#         decision_tree[id]['potential-alignments-by-A'] = []\n",
    "\n",
    "#         # while figuring the new potential alignments by a and b we will find transpositions that we need to store.\n",
    "#         # We use bitarrays to track (avoid) overlap (subsequences) between detected transposed patterns.\n",
    "#         # ba1 and ba2 record transposed patterns\n",
    "#         from bitarray import bitarray\n",
    "#         ba1 = bitarray(len(witnesses[0]))\n",
    "#         ba1.setall(0)\n",
    "#         ba2 = bitarray(len(witnesses[1]))\n",
    "#         ba2.setall(0)\n",
    "\n",
    "#         #TEMP: transposed-patterns': [(2, 2, 'and the'), (4, 1, 'black')],\n",
    "#         for tp in decision_tree[id]['transposed-patterns']:\n",
    "#             # now we need to fill the bitarray; We need the start position in each witness and the length of the pattern.\n",
    "#             tp_ngram_length = ngram_length[tp[2]]\n",
    "#             ba1[tp[0]:tp[0] + tp_ngram_length] = 1\n",
    "#             ba2[tp[1]:tp[1] + tp_ngram_length] = 1\n",
    "\n",
    "#         # ba3 and ba4 record aligned pattern being added\n",
    "#         ba3 = bitarray(len(witnesses[0]))\n",
    "#         ba3.setall(0)\n",
    "#         ba4 = bitarray(len(witnesses[1]))\n",
    "#         ba4.setall(0)\n",
    "#         ba3[child[0]:child[0] + current_ngram_length] = 1\n",
    "#         ba4[child[1]:child[1] + current_ngram_length] = 1\n",
    "\n",
    "#         for p in decision_tree[parent_id]['potential-alignments-by-A']: # check for potentials and transpositions\n",
    "#             if p[0] > decision_tree[id]['current-location-in-A'] and p[1] > decision_tree[id]['current-location-in-B']:\n",
    "#                 decision_tree[id]['potential-alignments-by-A'].append(p) # both are to the right, so it's still potential\n",
    "#             else: # check whether it's a transposition or an overlap\n",
    "#                 for q in p[2]: # iterate over the different n-grams\n",
    "#                     q_ngram_length = ngram_length[q] # length of current ngram inside current potential\n",
    "#                     if ba3[p[0]:p[0] + q_ngram_length].any() or ba4[p[1]:p[1] + q_ngram_length].any(): # overlap; throw it away\n",
    "#                         continue\n",
    "#                     else: # transposition but is it alreadyin the transposed patterns property?\n",
    "#                         if ba1[p[0]:p[0] + q_ngram_length].any() or ba2[p[1]:p[1] + q_ngram_length].any(): # already among transpositions\n",
    "#                             continue\n",
    "#                         decision_tree[id]['transposed-patterns'].append((p[0], p[1], q)) # update bitarrays with the new transposed pattern\n",
    "#                         ba1[p[0]:p[0] + q_ngram_length] = 1\n",
    "#                         ba2[p[1]:p[1] + q_ngram_length] = 1\n",
    "\n",
    "#         # potentials by A and B are the same tuples, but sorted differently\n",
    "#         decision_tree[id]['potential-alignments-by-B'] = sorted(decision_tree[id]['potential-alignments-by-A'], key=lambda x: (x[1], x[0]))\n",
    "\n",
    "#         decision_tree[parent_id]['children'].append(id) # add new child to parent\n",
    "#         if decision_tree[id]['potential-alignments-by-A']:\n",
    "#             add_children(id) # recur to process children of new child\n",
    "\n",
    "#     # add type #3 (skip) node\n",
    "#     if len(decision_tree[parent_id]['children']) > 1:\n",
    "#         skip_node_id = len(decision_tree)\n",
    "#         decision_tree[skip_node_id] = {}\n",
    "#         decision_tree[skip_node_id]['id'] = skip_node_id\n",
    "#         decision_tree[skip_node_id]['type'] = 'skip'\n",
    "#         decision_tree[skip_node_id]['current-location-in-A'] = nearest_A_matches[0][0] + ngram_length[nearest_A_matches[0][2][0]] - 1\n",
    "#         decision_tree[skip_node_id]['current-location-in-B'] = nearest_B_matches[0][1] + ngram_length[nearest_B_matches[0][2][0]] - 1\n",
    "#         decision_tree[skip_node_id]['parent'] = parent_id\n",
    "#         decision_tree[skip_node_id]['children'] = []\n",
    "#         aligned_patterns = decision_tree[parent_id]['aligned-patterns'].copy() # aligned patterns don't change\n",
    "#         decision_tree[skip_node_id]['aligned-patterns'] = aligned_patterns\n",
    "#         transposed_patterns = decision_tree[parent_id]['transposed-patterns'].copy()\n",
    "#         decision_tree[skip_node_id]['transposed-patterns'] = transposed_patterns\n",
    "#         potential_alignments_by_A = decision_tree[parent_id]['potential-alignments-by-A'].copy() # keep only potential greater than current position\n",
    "#         decision_tree[skip_node_id]['potential-alignments-by-A'] = [t for t in potential_alignments_by_A if t[0] > decision_tree[skip_node_id]['current-location-in-A'] and t[1] > decision_tree[skip_node_id]['current-location-in-B']]\n",
    "#         decision_tree[skip_node_id]['potential-alignments-by-B'] = sorted(decision_tree[skip_node_id]['potential-alignments-by-A'], key=lambda x: (x[1], x[0]))\n",
    "#         decision_tree[parent_id]['children'].append(skip_node_id)\n",
    "\n",
    "#         # while figuring the new potential alignments by a and b we will find transpositions that we need to store.\n",
    "#         # We use bitarrays to track (avoid) overlap (subsequences) between detected transposed patterns.\n",
    "#         # ba1 and ba2 record transposed patterns\n",
    "#         from bitarray import bitarray\n",
    "#         ba1 = bitarray(len(witnesses[0]))\n",
    "#         ba1.setall(0)\n",
    "#         ba2 = bitarray(len(witnesses[1]))\n",
    "#         ba2.setall(0)\n",
    "\n",
    "#         #INFO: 'transposed-patterns' looks like: [(2, 2, 'and the'), (4, 1, 'black')],\n",
    "#         for tp in decision_tree[skip_node_id]['transposed-patterns']:\n",
    "#             # now we need to fill the bitarray; We need the start position in each witness and the length of the pattern.\n",
    "#             tp_ngram_length = ngram_length[tp[2]]\n",
    "#             ba1[tp[0]:tp[0] + tp_ngram_length] = 1\n",
    "#             ba2[tp[1]:tp[1] + tp_ngram_length] = 1\n",
    "\n",
    "#         for t in potential_alignments_by_A:\n",
    "#             if t[0] <= decision_tree[skip_node_id]['current-location-in-A'] or t[1] <= decision_tree[skip_node_id]['current-location-in-B']:\n",
    "#                 # transposition, but is it already in the transposed-patterns property?\n",
    "#                 t_ngram_length = ngram_length[t[2][0]]\n",
    "#                 if ba1[t[0]:t[0] + t_ngram_length].any() or ba2[t[1]:t[1] + t_ngram_length].any(): # already among transpositions\n",
    "#                     continue\n",
    "#                 decision_tree[skip_node_id]['transposed-patterns'].append((t[0], t[1], t[2][0])) # update bitarrays with the new transposed pattern\n",
    "#                 ba1[t[0]:t[0] + t_ngram_length] = 1\n",
    "#                 ba2[t[1]:t[1] + t_ngram_length] = 1\n",
    "\n",
    "#         if decision_tree[skip_node_id]['potential-alignments-by-A']:\n",
    "#             add_children(skip_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# params:\n",
    "# aligned_pattern_as_tuple: The pattern that is just aligned in this decision tree node and that might cause transpositions as a result.\n",
    "# id: id of the decision tree node that we are operating on\n",
    "def find_transpositions(aligned_pattern_as_tuple, id):\n",
    "    # Transposed patterns can be found by looking at the potential patterns. If a pattern has a start position before the selected pattern in witness a\n",
    "    # and a start position after the selected pattern in witness B it is transposed. Likewise, if a pattern has a start position after the selected pattern\n",
    "    # in witness A and a start position before in witness B it is a transposition.\n",
    "    sbf = df[['A', 'B', 'ngrams']]\n",
    "    sbf\n",
    "    # while figuring the new potential alignments by a and b we will find transpositions that we need to store.\n",
    "    # We use bitarrays to track (avoid) overlap (subsequences) between detected transposed patterns.\n",
    "    # ba1 and ba2 record transposed patterns\n",
    "    from bitarray import bitarray\n",
    "    ba1 = bitarray(len(witnesses[0]))\n",
    "    ba1.setall(0)\n",
    "    ba2 = bitarray(len(witnesses[1]))\n",
    "    ba2.setall(0)\n",
    "\n",
    "#         #INFO: 'transposed-patterns' looks like: [(2, 2, 'and the'), (4, 1, 'black')],\n",
    "#         for tp in decision_tree[skip_node_id]['transposed-patterns']:\n",
    "#             # now we need to fill the bitarray; We need the start position in each witness and the length of the pattern.\n",
    "#             tp_ngram_length = ngram_length[tp[2]]\n",
    "#             ba1[tp[0]:tp[0] + tp_ngram_length] = 1\n",
    "#             ba2[tp[1]:tp[1] + tp_ngram_length] = 1\n",
    "\n",
    "\n",
    "    # go over the rows of this subframe\n",
    "    for row in sbf.itertuples():\n",
    "#            print(type(row))\n",
    "#            print(row)\n",
    "        # if the row is not the same as the aligned pattern.\n",
    "        # We can check whether a pattern is transposed.\n",
    "        # we need to keep track of already detected transpositions to cover overlap between transpositions.\n",
    "        if row.Index == aligned_pattern_as_tuple[0]:\n",
    "            continue\n",
    "        # check whether the row is in the blocked patterns property\n",
    "        if row.Index in decision_tree[id]['blocked-patterns']:\n",
    "            continue\n",
    "        # print(\"Check for transposition: \", row)\n",
    "        if row.A > aligned_pattern_as_tuple[1] and row.B < aligned_pattern_as_tuple[2] or row.A < aligned_pattern_as_tuple[1] and row.B > aligned_pattern_as_tuple[2]:\n",
    "            t = (row.A, row.B, row.ngrams)\n",
    "            # transposition, but is it already in the transposed-patterns property?\n",
    "            # We need to try different lengths of the transposition\n",
    "            for q in t[2]: # iterate over the different n-grams\n",
    "                q_ngram_length = ngram_length[q] # length of current ngram inside current potential\n",
    "                if ba1[t[0]:t[0] + q_ngram_length].any() or ba2[t[1]:t[1] + q_ngram_length].any(): # already among transpositions\n",
    "                    if not row.Index in decision_tree[id]['blocked-patterns']:\n",
    "                        decision_tree[id]['blocked-patterns'].append(row.Index)\n",
    "                    continue\n",
    "                # print(\"Transposed!\")\n",
    "                decision_tree[id]['transposed-patterns'].append(row.Index)\n",
    "                decision_tree[id]['transposed-patterns-text'].append((t[0], t[1], q))\n",
    "                decision_tree[id]['blocked-patterns'].append(row.Index)\n",
    "                # update bitarrays with the new transposed pattern\n",
    "                ba1[t[0]:t[0] + q_ngram_length] = 1\n",
    "                ba2[t[1]:t[1] + q_ngram_length] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'type': None,\n",
       "  'parent': None,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [],\n",
       "  'aligned-patterns-text': [],\n",
       "  'transposed-patterns': [],\n",
       "  'transposed-patterns-text': [],\n",
       "  'blocked-patterns': [],\n",
       "  'blocked-patterns-text': []},\n",
       " 1: {'id': 1,\n",
       "  'type': 'align',\n",
       "  'parent': 0,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [0],\n",
       "  'aligned-patterns-text': [(0, 3, 'the red')],\n",
       "  'transposed-patterns': [1],\n",
       "  'transposed-patterns-text': [(3, 0, 'the black')],\n",
       "  'blocked-patterns': [0, 2, 5, 6, 7, 1, 4],\n",
       "  'blocked-patterns-text': [(2, 2, ['and the', 'and']),\n",
       "   (1, 4, ['red']),\n",
       "   (0, 0, ['the']),\n",
       "   (3, 3, ['the'])]},\n",
       " 2: {'id': 2,\n",
       "  'type': 'align',\n",
       "  'parent': 0,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [1],\n",
       "  'aligned-patterns-text': [(3, 0, 'the black')],\n",
       "  'transposed-patterns': [0],\n",
       "  'transposed-patterns-text': [(0, 3, 'the red')],\n",
       "  'blocked-patterns': [1, 2, 4, 6, 7, 0, 5],\n",
       "  'blocked-patterns-text': [(2, 2, ['and the', 'and']),\n",
       "   (4, 1, ['black']),\n",
       "   (0, 0, ['the']),\n",
       "   (3, 3, ['the'])]},\n",
       " 3: {'id': 3,\n",
       "  'type': 'align',\n",
       "  'parent': 0,\n",
       "  'children': [],\n",
       "  'aligned-patterns': [2],\n",
       "  'aligned-patterns-text': [(2, 2, 'and the')],\n",
       "  'transposed-patterns': [4, 5],\n",
       "  'transposed-patterns-text': [(4, 1, 'black'), (1, 4, 'red')],\n",
       "  'blocked-patterns': [2, 0, 1, 7, 4, 5],\n",
       "  'blocked-patterns-text': [(0, 3, ['the red', 'the']),\n",
       "   (3, 0, ['the black', 'the']),\n",
       "   (3, 3, ['the'])]}}"
      ]
     },
     "execution_count": 20,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to add child nodes recursively\n",
    "# Within children:\n",
    "#   Add parent\n",
    "#   Update aligned patterns\n",
    "#   Update transposed patterns\n",
    "#   Update potential alignments\n",
    "#\n",
    "# Add one types of nodes:\n",
    "#\n",
    "#   1. Align pattern\n",
    "#\n",
    "# Assign consecutive id values by counting size of dictionary = could break with multithreading\n",
    "\n",
    "# we need to do two things. 1 calculate potential alignments. Remove patterns that overlap with the currently aligned patterns.\n",
    "# Then calculate the transposed patterns.\n",
    "# 2. We need to be able to mask the list of potential patterns from the main table with a list of integers, or later on a bit array to create a subset\n",
    "# (or view) of the table.\n",
    "\n",
    "# if we know which row is the pattern that is aligned (we need to store that) we can look at with which rows the selected pattern overlaps.\n",
    "# These rows then need to be masked.\n",
    "def add_children(parent_id: int):\n",
    "    # Get the rarest patterns from the table\n",
    "    max = df['weight'].max()\n",
    "    rarest_patterns = df.loc[df['weight'] == max].itertuples()\n",
    "\n",
    "    for columns_per_row in rarest_patterns:\n",
    "        aligned_pattern_as_tuple = (columns_per_row.Index, columns_per_row.A, columns_per_row.B, columns_per_row.ngrams)\n",
    "        # print(aligned_pattern_as_tuple)\n",
    "        id = len(decision_tree)\n",
    "        decision_tree[id] = {}\n",
    "        decision_tree[id]['id'] = id\n",
    "        decision_tree[id]['type'] = 'align'\n",
    "        decision_tree[id]['parent'] = parent_id\n",
    "        decision_tree[id]['children'] = []\n",
    "        decision_tree[id]['aligned-patterns'] = decision_tree[parent_id]['aligned-patterns'].copy()\n",
    "        decision_tree[id]['aligned-patterns-text'] = decision_tree[parent_id]['aligned-patterns-text'].copy() # debug\n",
    "        decision_tree[id]['transposed-patterns'] = decision_tree[parent_id]['transposed-patterns'].copy()\n",
    "        decision_tree[id]['transposed-patterns-text'] = decision_tree[parent_id]['transposed-patterns'].copy() # debug\n",
    "        decision_tree[id]['blocked-patterns'] = decision_tree[parent_id]['blocked-patterns'].copy()\n",
    "        decision_tree[id]['blocked-patterns-text'] = decision_tree[parent_id]['blocked-patterns-text'].copy() # debug\n",
    "\n",
    "        # We need to add the selected pattern to the aligned patterns.\n",
    "        decision_tree[id]['aligned-patterns'].append(aligned_pattern_as_tuple[0])\n",
    "        decision_tree[id]['aligned-patterns-text'].append((aligned_pattern_as_tuple[1], aligned_pattern_as_tuple[2], aligned_pattern_as_tuple[3][0]))\n",
    "        decision_tree[id]['blocked-patterns'].append(aligned_pattern_as_tuple[0])\n",
    "        # We need to calculate the overlap with other patterns.\n",
    "        # We walk over the rows of the pattern table and see whether there is overlap.\n",
    "        # Of course we need to skip the row representing the current pattern and in the case of grandchildren we need to skip pattern discarded previously.\n",
    "\n",
    "        # We can do a range check... The values in A and B are the start positions and we know the length of the pattern, meaning that there are two vectors, one         # for Witness A and B.\n",
    "        # Notice how there are multiple patterns associated with one start position.\n",
    "        for row in df.itertuples():\n",
    "            # skip if the row is the same instance as the pattern that is just aligned.\n",
    "            if row.Index == aligned_pattern_as_tuple[0]:\n",
    "                continue\n",
    "\n",
    "            # start by checking only the largest length\n",
    "            # print(\"Checking row: \", row.A, row.B, row.ngrams)\n",
    "            tuple = aligned_pattern_as_tuple\n",
    "            t_length = ngram_length[tuple[3][0]]\n",
    "            r_length = ngram_length[row.ngrams[0]]\n",
    "\n",
    "            # if row.A or row.A + r_length -1 is a point in the range of the tuple[1] to tuple[1] + t_length -1\n",
    "            if row.A >= tuple[1] and row.A <= tuple[1] + t_length - 1 or row.A + r_length - 1 >= tuple[1] and row.A + r_length - 1 <= tuple[1] + t_length - 1:\n",
    "                # print(row.ngrams[0], \" overlaps in witness A!\")\n",
    "                decision_tree[id]['blocked-patterns'].append(row.Index)\n",
    "                decision_tree[id]['blocked-patterns-text'].append((row.A, row.B, row.ngrams))\n",
    "            elif row.B >= tuple[2] and row.B <= tuple[2] + t_length - 1 or row.B + r_length - 1 >= tuple[2] and row.B + r_length - 1 <= tuple[2] + t_length - 1:\n",
    "                # print(row.ngrams[0], \" overlaps in witness B!\")\n",
    "                decision_tree[id]['blocked-patterns'].append(row.Index)\n",
    "                decision_tree[id]['blocked-patterns-text'].append((row.A, row.B, row.ngrams))\n",
    "\n",
    "        find_transpositions(aligned_pattern_as_tuple, id)\n",
    "\n",
    "\n",
    "\n",
    "create_root_node()\n",
    "add_children(0)\n",
    "decision_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[the red, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[the black, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[and the, and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>[cat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[black]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[red]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[the]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B            ngrams\n",
       "0  0  3    [the red, the]\n",
       "1  3  0  [the black, the]\n",
       "2  2  2    [and the, and]\n",
       "3  5  5             [cat]\n",
       "4  4  1           [black]\n",
       "5  1  4             [red]\n",
       "6  0  0             [the]\n",
       "7  3  3             [the]"
      ]
     },
     "execution_count": 21,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbf = df[['A', 'B', 'ngrams']]\n",
    "sbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}