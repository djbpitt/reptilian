{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Collation with decision graph and without pandas\n",
    "\n",
    "Revision based on consultation on *decision-graph-2.ipynb*\n",
    "\n",
    "w1 patterns are on top, w2 on left\n",
    "\n",
    "Order the patterns (shared ngrams of any length) on:\n",
    "\n",
    "1. Coordinate witness A ascending, then\n",
    "1. Coordinate witness B ascending, then\n",
    "1. Length of the pattern from large to small (descending).\n",
    "\n",
    "Patterns have the shape (A:int, B:int, ngram:str)\n",
    "\n",
    "The first part of this notebook, through the identification of shared ngrams, is copied from our earlier efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data\n",
    "\n",
    "There will always be a single root (because we create one!) and exactly one or two leaves:\n",
    "\n",
    "1. One leaf: If the last shared pattern is the last shared pattern in both witnesses, there is a single leaf\n",
    "1. Two leaves: If the last shared pattern in one witness is not the last shared pattern in the other, and vice versa, there are two leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# two witnesses, with repetition and transposition\n",
    "\n",
    "# Original example, single leaf node\n",
    "w1 = '''the red and the black cat'''\n",
    "w2 = '''the black and the red cat'''\n",
    "\n",
    "# Adjacent transposition\n",
    "# w1 = '''the red striped cat'''\n",
    "# w2 = '''the striped red cat'''\n",
    "\n",
    "# Two leaf nodes\n",
    "# w1 = '''cat red black'''\n",
    "# w2 = '''cat black red'''\n",
    "\n",
    "# Branches meet in the middle at koala and then split again, with two leaf nodes\n",
    "# w1 = \"\"\"cat red black koala brown gray\"\"\"\n",
    "# w2 = \"\"\"cat black red koala gray brown\"\"\"\n",
    "\n",
    "# Two split and rejoin\n",
    "# w1 = '''the gray koala'''\n",
    "# w2 = '''the brown koala'''\n",
    "\n",
    "# medium example\n",
    "# w1 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ much more from each other, than do the individuals of any one\n",
    "# species or variety in a state of nature.'''\n",
    "# w2 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature.'''\n",
    "\n",
    "# Larger example\n",
    "# w1 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ much more from each other, than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this greater variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is, also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.'''\n",
    "# w2 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this great variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Construct list of ngrams shared by witnesses\n",
    "\n",
    "Find ngrams and positions in witnesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tokenize witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def tokenize_witnesses(w1_string, w2_string):\n",
    "    '''Return list of witnesses, each represented by a list of tokens'''\n",
    "    # TODO: handle punctuation, upper- ~ lowercase\n",
    "    w1_tokens = w1.split()\n",
    "    w2_tokens = w2.split()\n",
    "    witnesses = [w1_tokens, w2_tokens]\n",
    "    return witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'red', 'and', 'the', 'black', 'cat'], ['the', 'black', 'and', 'the', 'red', 'cat']]\n"
     ]
    }
   ],
   "source": [
    "witnesses = tokenize_witnesses(w1, w2)\n",
    "print(witnesses) # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Find ngrams shared by the witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_ngrams_all(witness):\n",
    "    '''Create n-grams and returns offsets and lengths\n",
    "\n",
    "    Argument:\n",
    "    witness:list -- list of tokens in witness\n",
    "\n",
    "    Returns:\n",
    "    ngrams:dict --       key is ngram\n",
    "                         value is list of start positions in witness for ngram\n",
    "    token_counts:dict -- key is ngram\n",
    "                         value is token count of ngram\n",
    "    '''\n",
    "    ngram_offsets = defaultdict(list)\n",
    "    token_counts = {}\n",
    "    for n in range(1, len(witness) + 1):\n",
    "        for i in range(len(witness)-n+1):\n",
    "            g = ' '.join(witness[i:i+n]) # store each ngram as g temporarily\n",
    "            ngram_offsets[g].append(i)\n",
    "            token_counts[g] = n\n",
    "    return ngram_offsets, token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "ngram_offsets_by_witness_dict = {} # keyed by witness\n",
    "ngram_lengths = {}\n",
    "for index, witness in enumerate(witnesses):\n",
    "    map1, map2 = compute_ngrams_all(witness)\n",
    "    ngram_offsets_by_witness_dict['w' + str(index + 1)] = map1\n",
    "    ngram_lengths.update(map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witness w1\n",
      "defaultdict(<class 'list'>, {'the': [0, 3], 'red': [1], 'and': [2], 'black': [4], 'cat': [5], 'the red': [0], 'red and': [1], 'and the': [2], 'the black': [3], 'black cat': [4], 'the red and': [0], 'red and the': [1], 'and the black': [2], 'the black cat': [3], 'the red and the': [0], 'red and the black': [1], 'and the black cat': [2], 'the red and the black': [0], 'red and the black cat': [1], 'the red and the black cat': [0]})\n",
      "\n",
      "Witness w2\n",
      "defaultdict(<class 'list'>, {'the': [0, 3], 'black': [1], 'and': [2], 'red': [4], 'cat': [5], 'the black': [0], 'black and': [1], 'and the': [2], 'the red': [3], 'red cat': [4], 'the black and': [0], 'black and the': [1], 'and the red': [2], 'the red cat': [3], 'the black and the': [0], 'black and the red': [1], 'and the red cat': [2], 'the black and the red': [0], 'black and the red cat': [1], 'the black and the red cat': [0]})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at ngram lists for each witness\n",
    "# Keys of inner dictionary are ngrams, values are lists of start positions in witness\n",
    "for key in ngram_offsets_by_witness_dict.keys():\n",
    "    print('Witness ' + key)\n",
    "    print(ngram_offsets_by_witness_dict[key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'red': 1, 'and': 1, 'black': 1, 'cat': 1, 'the red': 2, 'red and': 2, 'and the': 2, 'the black': 2, 'black cat': 2, 'the red and': 3, 'red and the': 3, 'and the black': 3, 'the black cat': 3, 'the red and the': 4, 'red and the black': 4, 'and the black cat': 4, 'the red and the black': 5, 'red and the black cat': 5, 'the red and the black cat': 6, 'black and': 2, 'red cat': 2, 'the black and': 3, 'black and the': 3, 'and the red': 3, 'the red cat': 3, 'the black and the': 4, 'black and the red': 4, 'and the red cat': 4, 'the black and the red': 5, 'black and the red cat': 5, 'the black and the red cat': 6}\n"
     ]
    }
   ],
   "source": [
    "# Look at ngram lengths (combined)\n",
    "print(ngram_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'and the', 'black', 'cat', 'red', 'the', 'the black', 'the red'}"
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find keys shared by *all* witnesses\n",
    "shared_ngrams = set(ngram_offsets_by_witness_dict[\"w1\"].keys())\n",
    "for value in ngram_offsets_by_witness_dict.values():\n",
    "    shared_ngrams = shared_ngrams.intersection(value.keys())\n",
    "\n",
    "shared_ngrams # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Use shared ngrams to find potential alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'and the': [(2, 2)], 'red': [(1, 4)], 'and': [(2, 2)], 'the red': [(0, 3)], 'cat': [(5, 5)], 'the': [(0, 0), (0, 3), (3, 0), (3, 3)], 'the black': [(3, 0)], 'black': [(4, 1)]})\n"
     ]
    }
   ],
   "source": [
    "# output format: {ngram : [(0,1), (2,3)]}, where\n",
    "#   the two entries in each tuple are for witnesses A and B\n",
    "potential_alignments = defaultdict(list)\n",
    "for ngram in shared_ngrams:\n",
    "    for w1_offset in ngram_offsets_by_witness_dict['w1'][ngram]:\n",
    "        for w2_offset in ngram_offsets_by_witness_dict['w2'][ngram]:\n",
    "            potential_alignments[ngram].append((w1_offset, w2_offset))\n",
    "\n",
    "print(potential_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Invert keys and values for potential alignments\n",
    "\n",
    "* Keys are now individual tuples of (A, B) start positions\n",
    "* Values are now lists of ngrams of different lengths at those positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {(2, 2): ['and the', 'and'], (1, 4): ['red'], (0, 3): ['the red', 'the'], (5, 5): ['cat'], (0, 0): ['the'], (3, 0): ['the', 'the black'], (3, 3): ['the'], (4, 1): ['black']})\n"
     ]
    }
   ],
   "source": [
    "alignments = defaultdict(list)\n",
    "for key,value in potential_alignments.items():\n",
    "    for t in value:\n",
    "        alignments[t].append(key)\n",
    "\n",
    "print(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# https://docs.python.org/3/library/dataclasses.html\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "@dataclass(unsafe_hash=True)\n",
    "class Pattern:\n",
    "    __slots__ = ['token_start_position_A', 'token_start_position_B', 'ngram', 'ngram_length', 'token_end_position_A', 'token_end_position_B']\n",
    "    token_start_position_A: int\n",
    "    token_start_position_B: int\n",
    "    ngram: str\n",
    "    ngram_length: int\n",
    "    token_end_position_A: int\n",
    "    token_end_position_B: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pattern(token_start_position_A=-1, token_start_position_B=-1, ngram='ROOT', ngram_length=1, token_end_position_A=-1, token_end_position_B=-1),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=0, ngram='the', ngram_length=1, token_end_position_A=0, token_end_position_B=0),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=3, ngram='the red', ngram_length=2, token_end_position_A=1, token_end_position_B=4),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=3, ngram='the', ngram_length=1, token_end_position_A=0, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=1, token_start_position_B=4, ngram='red', ngram_length=1, token_end_position_A=1, token_end_position_B=4),\n",
       " Pattern(token_start_position_A=2, token_start_position_B=2, ngram='and the', ngram_length=2, token_end_position_A=3, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=2, token_start_position_B=2, ngram='and', ngram_length=1, token_end_position_A=2, token_end_position_B=2),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=0, ngram='the black', ngram_length=2, token_end_position_A=4, token_end_position_B=1),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=0, ngram='the', ngram_length=1, token_end_position_A=3, token_end_position_B=0),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=3, ngram='the', ngram_length=1, token_end_position_A=3, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=4, token_start_position_B=1, ngram='black', ngram_length=1, token_end_position_A=4, token_end_position_B=1),\n",
       " Pattern(token_start_position_A=5, token_start_position_B=5, ngram='cat', ngram_length=1, token_end_position_A=5, token_end_position_B=5)]"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column labels, ordered by w1 pos, then w2 pos, then ngram length (long to short)\n",
    "patterns_A = [] # will need to be sorted after all values have been added\n",
    "for k, v in alignments.items():\n",
    "    for ngram in v: # add instance of dataclass Pattern for each ngram at A,B positions\n",
    "        current_ngram_length = ngram_lengths[ngram]\n",
    "        patterns_A.append(Pattern(k[0], k[1], ngram, current_ngram_length, k[0] + current_ngram_length - 1, k[1] + current_ngram_length - 1))\n",
    "patterns_A = sorted(patterns_A, key=lambda x: (x.token_start_position_A, x.token_start_position_B, -x.ngram_length))\n",
    "patterns_A.insert(0, Pattern(-1, -1, 'ROOT', 1, -1, -1))\n",
    "patterns_A # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pattern(token_start_position_A=-1, token_start_position_B=-1, ngram='ROOT', ngram_length=1, token_end_position_A=-1, token_end_position_B=-1),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=0, ngram='the', ngram_length=1, token_end_position_A=0, token_end_position_B=0),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=0, ngram='the black', ngram_length=2, token_end_position_A=4, token_end_position_B=1),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=0, ngram='the', ngram_length=1, token_end_position_A=3, token_end_position_B=0),\n",
       " Pattern(token_start_position_A=4, token_start_position_B=1, ngram='black', ngram_length=1, token_end_position_A=4, token_end_position_B=1),\n",
       " Pattern(token_start_position_A=2, token_start_position_B=2, ngram='and the', ngram_length=2, token_end_position_A=3, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=2, token_start_position_B=2, ngram='and', ngram_length=1, token_end_position_A=2, token_end_position_B=2),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=3, ngram='the red', ngram_length=2, token_end_position_A=1, token_end_position_B=4),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=3, ngram='the', ngram_length=1, token_end_position_A=0, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=3, ngram='the', ngram_length=1, token_end_position_A=3, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=1, token_start_position_B=4, ngram='red', ngram_length=1, token_end_position_A=1, token_end_position_B=4),\n",
       " Pattern(token_start_position_A=5, token_start_position_B=5, ngram='cat', ngram_length=1, token_end_position_A=5, token_end_position_B=5)]"
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patterns_B = sorted(patterns_A, key=lambda x: (x.token_start_position_B, x.token_start_position_A, -x.ngram_length))\n",
    "patterns_B # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Node objects contain unique id values plus pattern (not token) coordinates for both witnesses\n",
    "@dataclass(unsafe_hash=True)\n",
    "class Node:\n",
    "    __slots__ = ['id', 'pattern_coordinate_witness_A', 'pattern_coordinate_witness_B']\n",
    "    id: int\n",
    "    pattern_coordinate_witness_A: int # offset into list of patterns (not the same as token coordinate)\n",
    "    pattern_coordinate_witness_B: int\n",
    "    # score: int # count of aligned tokens, or should that be on the edges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Dictionary to check whether node has already been added for a pattern:\n",
    "#\n",
    "# If the node has already been added, don't add a new node, but retrieve the node id to add a new edge\n",
    "# If the node has not already been added, add it, along with an edge\n",
    "\n",
    "node_finder = {} #dictionary; key is pattern coordinate A, value is node id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# First create root node\n",
    "root = Node(0, 0, 0)\n",
    "node_finder[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Configure to show multiple value for development and debugging\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node(id=0, pattern_coordinate_witness_A=0, pattern_coordinate_witness_B=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{0: 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root # take a look\n",
    "node_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pattern(token_start_position_A=-1, token_start_position_B=-1, ngram='ROOT', ngram_length=1, token_end_position_A=-1, token_end_position_B=-1),\n",
       " Pattern(token_start_position_A=0, token_start_position_B=0, ngram='the', ngram_length=1, token_end_position_A=0, token_end_position_B=0),\n",
       " Pattern(token_start_position_A=2, token_start_position_B=2, ngram='and the', ngram_length=2, token_end_position_A=3, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=2, token_start_position_B=2, ngram='and', ngram_length=1, token_end_position_A=2, token_end_position_B=2),\n",
       " Pattern(token_start_position_A=3, token_start_position_B=3, ngram='the', ngram_length=1, token_end_position_A=3, token_end_position_B=3),\n",
       " Pattern(token_start_position_A=5, token_start_position_B=5, ngram='cat', ngram_length=1, token_end_position_A=5, token_end_position_B=5)]"
      ]
     },
     "execution_count": 20,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find and save all diagonal patterns in list\n",
    "# TODO: can we use a copy constructor to avoid having to copy all of the properties individually?\n",
    "diagonal_patterns = []\n",
    "for table_offset_A, pattern in enumerate(patterns_A): # find table offset for each A pattern\n",
    "    if patterns_B[table_offset_A] is pattern: # is the pattern at the same offset in B the same object?\n",
    "        diagonal_patterns.append(pattern) # if so, it's a diagonal\n",
    "diagonal_patterns # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pattern(token_start_position_A=0, token_start_position_B=0, ngram='the', ngram_length=1, token_end_position_A=0, token_end_position_B=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_diagonal_pattern_for_node(current_node : Node):\n",
    "    # go over the diagional patterns and find the first pattern that begins after the end token of the current pattern.\n",
    "    current_pattern_A = patterns_A[current_node.pattern_coordinate_witness_A] # offset into list of patterns\n",
    "    current_pattern_B = patterns_B[current_node.pattern_coordinate_witness_B]\n",
    "\n",
    "    next_diagonal_pattern = next(filter(lambda dp: dp.token_start_position_A > current_pattern_A.token_end_position_A and dp.token_start_position_B > current_pattern_B.token_end_position_B, diagonal_patterns), None)\n",
    "    return next_diagonal_pattern\n",
    "\n",
    "next_pattern_in_both = find_diagonal_pattern_for_node(root)\n",
    "next_pattern_in_both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 1: Create graph and add root node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(nodes={Node(id=0, pattern_coordinate_witness_A=0, pattern_coordinate_witness_B=0)}, edges=set())"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Set\n",
    "\n",
    "@dataclass(unsafe_hash=True)\n",
    "class Edge:\n",
    "    __slots__ = ['source', 'target']\n",
    "    source: int\n",
    "    target: int\n",
    "\n",
    "@dataclass\n",
    "class Graph: # set of nodes (TODO: also set of edges)\n",
    "    __slots__ = ['nodes', 'edges']\n",
    "    nodes: Set[Node]\n",
    "    edges: Set[Edge]\n",
    "\n",
    "nodes = {root} # set of nodes\n",
    "edges = set()\n",
    "graph = Graph(nodes, edges)\n",
    "graph # take a look; so far just one node (root) and no edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Steps 2â€“4, 6: Add children of root node recursively, with edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# stable lookup for index position of pattern in witness-specific lists of patterns\n",
    "patterns_A_position_by_value = {val: index for index, val in enumerate(patterns_A)} # retrieve offset in witness-specific list of patterns by pattern\n",
    "patterns_B_position_by_value = {val: index for index, val in enumerate(patterns_B)} # retrieve offset in witness-specific list of patterns by pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Recursive function to add all nodes to graph in depth-first-order\n",
    "# Starts from root, with has already been added manually\n",
    "from typing import List\n",
    "# Ror each node we create at most three children plus edges (or just edges if a child node already exists):\n",
    "#\n",
    "#   1. Next pattern in Witness A. Look for the same pattern in Witness B. Should not be a diagional, see below.\n",
    "#   2. Next pattern in Witness B. Look for the same pattern in Witness A. Should not be a diagional, see below.\n",
    "#   3. Next pattern on a diagional. Could result in a skip of the patterns mentioned above.\n",
    "\n",
    "# function to identify and add all children of specified node\n",
    "# TODO: do not create child if it already exists\n",
    "def add_children(parent: Node): # find and create children of input (parent), returns nothing\n",
    "    # BUG: we currently exclude diagonals from closest in A and B incorrectly; diagonals are from the parent at each step, and not invariably from the root\n",
    "    # find closest in A and B that are not also diagonals and create node plus edge (or just edge, if node has already been added)\n",
    "    # find closest diagonal and create node (or just edge, if node has already been added)\n",
    "    pattern_A = patterns_A[parent.pattern_coordinate_witness_A] # offset of parent Pattern in list of patterns ordered by witness A\n",
    "    token_coordinate_witness_A = pattern_A.token_end_position_A # ending token position of parent in witness A\n",
    "    token_coordinate_witness_B = pattern_A.token_end_position_B\n",
    "    next_A_pattern = next(filter(lambda x : x.token_start_position_A > token_coordinate_witness_A and x.token_start_position_B > token_coordinate_witness_B \\\n",
    "                               and x not in diagonal_patterns, patterns_A[parent.pattern_coordinate_witness_A:]), None) # first pattern after parent token position\n",
    "    next_B_pattern = next(filter(lambda x : x.token_start_position_A > token_coordinate_witness_A and x.token_start_position_B > token_coordinate_witness_B \\\n",
    "                               and x not in diagonal_patterns, patterns_B[parent.pattern_coordinate_witness_B:]), None) # first pattern after parent token position\n",
    "    next_diag_pattern = find_diagonal_pattern_for_node(parent)\n",
    "\n",
    "    if next_A_pattern:\n",
    "        next_A_pattern_index_A = patterns_A_position_by_value[next_A_pattern]\n",
    "        next_A_pattern_index_B = patterns_B_position_by_value[next_A_pattern]\n",
    "\n",
    "        if not next_A_pattern_index_A in node_finder: # add new node only if it hasn't already been added\n",
    "            new_node_id = len(graph.nodes)\n",
    "            first_node = Node(new_node_id, next_A_pattern_index_A, next_A_pattern_index_B) # create new node\n",
    "            nodes.add(first_node)\n",
    "            node_finder[next_A_pattern_index_A] = new_node_id # and update node finder\n",
    "            edge1 = Edge(parent.id, first_node.id) # add edge to newly created node\n",
    "            edges.add(edge1)\n",
    "            add_children(first_node)\n",
    "        else:\n",
    "            edge1 = Edge(parent.id, node_finder[next_A_pattern_index_A]) # add new edge to pre-existing node\n",
    "            edges.add(edge1)\n",
    "\n",
    "    if next_B_pattern:\n",
    "        next_B_pattern_index_A = patterns_A_position_by_value[next_B_pattern]\n",
    "        next_B_pattern_index_B = patterns_B_position_by_value[next_B_pattern]\n",
    "\n",
    "        if not next_B_pattern_index_A in node_finder:\n",
    "            new_node_id = len(graph.nodes)\n",
    "            second_node = Node(new_node_id, next_B_pattern_index_A, next_B_pattern_index_B)\n",
    "            nodes.add(second_node)\n",
    "            node_finder[next_B_pattern_index_A] = new_node_id\n",
    "            edge2 = Edge(parent.id, second_node.id)\n",
    "            edges.add(edge2)\n",
    "            add_children(second_node)\n",
    "        else:\n",
    "            edge2 = Edge(parent.id, node_finder[next_B_pattern_index_A])\n",
    "            edges.add(edge2)\n",
    "\n",
    "    if next_diag_pattern:\n",
    "        next_diag_pattern_index_A = patterns_A_position_by_value[next_diag_pattern]\n",
    "        next_diag_pattern_index_B = patterns_B_position_by_value[next_diag_pattern]\n",
    "\n",
    "        if not next_diag_pattern_index_A in node_finder:\n",
    "            new_node_id = len(graph.nodes)\n",
    "            third_node = Node(new_node_id, next_diag_pattern_index_A, next_diag_pattern_index_B)\n",
    "            nodes.add(third_node)\n",
    "            node_finder[next_diag_pattern_index_A] = new_node_id\n",
    "            edge3 = Edge(parent.id, third_node.id)\n",
    "            edges.add(edge3)\n",
    "            add_children(third_node)\n",
    "        else:\n",
    "            edge3 = Edge(parent.id, node_finder[next_diag_pattern_index_A])\n",
    "            edges.add(edge3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Populate the graph (all nodes and edges)\n",
    "add_children(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"413pt\" height=\"260pt\" viewBox=\"0.00 0.00 413.04 260.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 409.04,-256 409.04,4 -4,4\"/>\n<!-- 1 -->\n<g id=\"node1\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"53.3\" cy=\"-162\" rx=\"53.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"53.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">1:the red</text>\n</g>\n<!-- 2 -->\n<g id=\"node4\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"186.3\" cy=\"-18\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"186.3\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">2:cat</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M45.72,-143.93C38.44,-124.68 30.55,-93.3 45.3,-72 67.06,-40.57 109.94,-27.75 142.73,-22.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"143.56,-25.96 152.98,-21.1 142.59,-19.03 143.56,-25.96\"/>\n</g>\n<!-- 0 -->\n<g id=\"node2\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"186.3\" cy=\"-234\" rx=\"46.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"186.3\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">0:ROOT</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0-&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M159.7,-219C139.67,-208.46 111.97,-193.88 89.86,-182.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"91.24,-179.01 80.76,-177.45 87.98,-185.21 91.24,-179.01\"/>\n</g>\n<!-- 4 -->\n<g id=\"node3\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"186.3\" cy=\"-162\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"186.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">4:the</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M186.3,-215.7C186.3,-207.98 186.3,-198.71 186.3,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.8,-190.1 186.3,-180.1 182.8,-190.1 189.8,-190.1\"/>\n</g>\n<!-- 3 -->\n<g id=\"node6\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"343.3\" cy=\"-162\" rx=\"61.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"343.3\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">3:the black</text>\n</g>\n<!-- 0&#45;&gt;3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>0-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215.83,-219.83C240.06,-209.03 274.66,-193.6 301.7,-181.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"303.21,-184.7 310.92,-177.43 300.36,-178.31 303.21,-184.7\"/>\n</g>\n<!-- 5 -->\n<g id=\"node5\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"89.3\" cy=\"-90\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"89.3\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">5:red</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4-&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.67,-146.83C152.47,-136.59 133.08,-122.59 117.26,-111.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"119.05,-108.16 108.9,-105.14 114.96,-113.83 119.05,-108.16\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"186.3\" cy=\"-90\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"186.3\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">6:black</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4-&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M186.3,-143.7C186.3,-135.98 186.3,-126.71 186.3,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.8,-118.1 186.3,-108.1 182.8,-118.1 189.8,-118.1\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"303.3\" cy=\"-90\" rx=\"54.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"303.3\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">7:and the</text>\n</g>\n<!-- 4&#45;&gt;7 -->\n<g id=\"edge10\" class=\"edge\">\n<title>4-&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M208.03,-148C225.22,-137.71 249.54,-123.16 269.3,-111.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"271.23,-114.26 278.02,-106.12 267.64,-108.25 271.23,-114.26\"/>\n</g>\n<!-- 5&#45;&gt;2 -->\n<g id=\"edge11\" class=\"edge\">\n<title>5-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M108.92,-74.83C123.22,-64.52 142.77,-50.41 158.64,-38.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"160.97,-41.6 167.03,-32.91 156.87,-35.92 160.97,-41.6\"/>\n</g>\n<!-- 3&#45;&gt;2 -->\n<g id=\"edge9\" class=\"edge\">\n<title>3-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M355.57,-144.31C368.04,-125.12 383.42,-93.52 367.3,-72 350.65,-49.78 276.65,-33.75 228.58,-25.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"228.89,-21.95 218.45,-23.75 227.73,-28.86 228.89,-21.95\"/>\n</g>\n<!-- 6&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>6-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M186.3,-71.7C186.3,-63.98 186.3,-54.71 186.3,-46.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"189.8,-46.1 186.3,-36.1 182.8,-46.1 189.8,-46.1\"/>\n</g>\n<!-- 7&#45;&gt;2 -->\n<g id=\"edge8\" class=\"edge\">\n<title>7-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M278.2,-73.98C260.23,-63.23 235.93,-48.7 216.84,-37.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"218.58,-34.24 208.2,-32.11 214.99,-40.24 218.58,-34.24\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 26,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ready to visualize the decision tree in SVG\n",
    "import graphviz\n",
    "from IPython.display import SVG\n",
    "\n",
    "# node id values must be strings for graphviz\n",
    "a = graphviz.Digraph(format=\"svg\")\n",
    "for item in graph.nodes: # set of Node objects, call it \"item\" to avoid overusing the keyword \"node\"\n",
    "    a.node(str(item.id), label=str(item.id) + ':' + patterns_A[item.pattern_coordinate_witness_A].ngram)\n",
    "for item in graph.edges:\n",
    "    a.edge(str(item.source), str(item.target))\n",
    "SVG(a.view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Node(id=0, pattern_coordinate_witness_A=0, pattern_coordinate_witness_B=0),\n",
       " Node(id=1, pattern_coordinate_witness_A=2, pattern_coordinate_witness_B=7),\n",
       " Node(id=2, pattern_coordinate_witness_A=11, pattern_coordinate_witness_B=11),\n",
       " Node(id=3, pattern_coordinate_witness_A=7, pattern_coordinate_witness_B=2),\n",
       " Node(id=4, pattern_coordinate_witness_A=1, pattern_coordinate_witness_B=1),\n",
       " Node(id=5, pattern_coordinate_witness_A=4, pattern_coordinate_witness_B=10),\n",
       " Node(id=6, pattern_coordinate_witness_A=10, pattern_coordinate_witness_B=4),\n",
       " Node(id=7, pattern_coordinate_witness_A=5, pattern_coordinate_witness_B=5)}"
      ]
     },
     "execution_count": 27,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{Edge(source=0, target=1),\n",
       " Edge(source=0, target=3),\n",
       " Edge(source=0, target=4),\n",
       " Edge(source=1, target=2),\n",
       " Edge(source=3, target=2),\n",
       " Edge(source=4, target=5),\n",
       " Edge(source=4, target=6),\n",
       " Edge(source=4, target=7),\n",
       " Edge(source=5, target=2),\n",
       " Edge(source=6, target=2),\n",
       " Edge(source=7, target=2)}"
      ]
     },
     "execution_count": 27,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nodes\n",
    "graph.edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Non-OO Python implementation of Kahn's topological sort algorithm\n",
    "\n",
    "https://algocoding.wordpress.com/2015/04/05/topological-sorting-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [1, 4, 3],\n",
       "             1: [2],\n",
       "             6: [2],\n",
       "             2: [],\n",
       "             4: [6, 5, 7],\n",
       "             3: [2],\n",
       "             5: [2],\n",
       "             7: [2]})"
      ]
     },
     "execution_count": 28,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert set of edges to adjacency list, preparatory to topological sorting\n",
    "adjacency_list = defaultdict(list) # key is source, value is list of targets\n",
    "for edge in graph.edges:\n",
    "    adjacency_list[edge.source].append(edge.target)\n",
    "    if edge.target not in adjacency_list: # adjacency list needs a key for every node, even if \n",
    "        adjacency_list[edge.target] = []\n",
    "adjacency_list # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# copied from https://algocoding.wordpress.com/2015/04/05/topological-sorting-python/\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "def kahn_topsort(graph):\n",
    "    in_degree = { u : 0 for u in graph }     # determine in-degree\n",
    "    for u in graph:                          # of each node\n",
    "        for v in graph[u]:\n",
    "            in_degree[v] += 1\n",
    "\n",
    "    Q = deque()                 # collect nodes with zero in-degree\n",
    "    for u in in_degree:\n",
    "        if in_degree[u] == 0:\n",
    "            Q.appendleft(u)\n",
    "\n",
    "    L = []     # list for order of nodes\n",
    "\n",
    "    while Q:\n",
    "        u = Q.pop()          # choose node of zero in-degree\n",
    "        L.append(u)          # and 'remove' it from graph\n",
    "        for v in graph[u]:\n",
    "            in_degree[v] -= 1\n",
    "            if in_degree[v] == 0:\n",
    "                Q.appendleft(v)\n",
    "\n",
    "    if len(L) == len(graph):\n",
    "        return L\n",
    "    else:                    # if there is a cycle,\n",
    "        return []            # then return an empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "order = kahn_topsort(adjacency_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 3, 6, 5, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "print(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: [0],\n",
       "             4: [0],\n",
       "             3: [0],\n",
       "             2: [1, 6, 3, 5, 7],\n",
       "             6: [4],\n",
       "             5: [4],\n",
       "             7: [4]})"
      ]
     },
     "execution_count": 32,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary to retrieve parent by child\n",
    "parent_by_child = defaultdict(list)\n",
    "for k, v in adjacency_list.items():\n",
    "    for node in v:\n",
    "        parent_by_child[node].append(k)\n",
    "parent_by_child # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Score(total=0, parent=[])}"
      ]
     },
     "execution_count": 33,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# traverse in topological order to find best path\n",
    "# for each node, track cumulative score (token score plus best token count of parents) and best parent\n",
    "# may be ties for best score / parent\n",
    "\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class Score:\n",
    "    __slots__ = ['total', 'parent']\n",
    "    total: int # best cumulative total\n",
    "    parent: List[int] # node id\n",
    "\n",
    "scores = {}\n",
    "scores[0] = Score(total = 0, parent = []) # add root manually\n",
    "\n",
    "scores # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: Node(id=1, pattern_coordinate_witness_A=2, pattern_coordinate_witness_B=7),\n",
       " 0: Node(id=0, pattern_coordinate_witness_A=0, pattern_coordinate_witness_B=0),\n",
       " 4: Node(id=4, pattern_coordinate_witness_A=1, pattern_coordinate_witness_B=1),\n",
       " 2: Node(id=2, pattern_coordinate_witness_A=11, pattern_coordinate_witness_B=11),\n",
       " 5: Node(id=5, pattern_coordinate_witness_A=4, pattern_coordinate_witness_B=10),\n",
       " 3: Node(id=3, pattern_coordinate_witness_A=7, pattern_coordinate_witness_B=2),\n",
       " 6: Node(id=6, pattern_coordinate_witness_A=10, pattern_coordinate_witness_B=4),\n",
       " 7: Node(id=7, pattern_coordinate_witness_A=5, pattern_coordinate_witness_B=5)}"
      ]
     },
     "execution_count": 34,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sigh ... another dictionary!\n",
    "node_by_id = {}\n",
    "for node in graph.nodes:\n",
    "    node_by_id[node.id] = node\n",
    "node_by_id # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Score(total=0, parent=[]),\n",
       " 1: Score(total=2, parent=[0]),\n",
       " 4: Score(total=1, parent=[0]),\n",
       " 3: Score(total=2, parent=[0]),\n",
       " 6: Score(total=2, parent=[4]),\n",
       " 5: Score(total=2, parent=[4]),\n",
       " 7: Score(total=3, parent=[4]),\n",
       " 2: Score(total=4, parent=[7])}"
      ]
     },
     "execution_count": 35,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 35,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score all nodes, keep track of best cumulative score\n",
    "best_score = 0 # best cumulative score for all nodes\n",
    "for node in order[1:]: # skip root; already done\n",
    "    local_ngram_count = patterns_A[node_by_id[node].pattern_coordinate_witness_A].ngram_length # ngram token count for current node\n",
    "    parents = parent_by_child[node] # all parents\n",
    "    best_parent_score = 0\n",
    "    best_parents = [] # parents with highest score\n",
    "    for parent in parents:\n",
    "        current_parent_score = scores[parent].total\n",
    "        if current_parent_score > best_parent_score: # replace old best score and parent pointers\n",
    "            best_parent_score = current_parent_score\n",
    "            best_parents = [parent]\n",
    "        elif current_parent_score == best_parent_score: # tie for best parent, so add to list\n",
    "            best_parents.append(parent)\n",
    "    scores[node] = Score(total = best_parent_score + local_ngram_count, parent = best_parents)\n",
    "    if scores[node].total > best_score: # if new score is highest of all so far, update best_score\n",
    "        best_score = scores[node].total\n",
    "scores # take a look at all scores,\n",
    "best_score # and at best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 36,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there will be exactly one or exactly two best leaves, return as list\n",
    "best_leaves = [k for k,v in scores.items() if v.total == best_score] # id(s) of leaves with best cumulative score\n",
    "best_leaves # take a look at leaves with best score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Work plan\n",
    "\n",
    "1. Traverse backward from best leaf (choose one) to find best path (choose one)\n",
    "1. Build and render variant graph (no transpositions yet)\n",
    "1. Find transpositions and add to variant graph; visualize variant graph with transpositions\n",
    "1. Visualize alignment as table\n",
    "1. Perhaps: Find all best paths, instead of just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# function to traverse backward from best leaf to find best path\n",
    "# arbitrarily chooses one path in case of ties\n",
    "def find_best_path(node: int) -> list: # start at leaf\n",
    "    path = find_next_path_step([node]) # beginning of path as list, end of list is most recent step\n",
    "    return path\n",
    "\n",
    "def find_next_path_step(_path:list) -> list:\n",
    "    if scores[_path[-1]].parent: # does last step (end of list) have a parent?\n",
    "        next_step = scores[_path[-1]].parent[0] # if so, add first of its parents to end list\n",
    "        _path.append(next_step)\n",
    "        return find_next_path_step(_path) # now look for the next step up the chain\n",
    "    else: # if no parent, we're at the root\n",
    "        return _path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 7, 2]\n"
     ]
    }
   ],
   "source": [
    "# find a best path from root to leaf\n",
    "best_path = find_best_path(best_leaves[0]) # arbitrarily choose first if there are two best leaves\n",
    "best_path.reverse() # built backward from leaf, so reverse in place (no return)\n",
    "print(best_path) # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# create variant graph\n",
    "# we have a list of aligned ngrams, but not of aligned tokens, so we need to look up the tokens\n",
    "@dataclass\n",
    "class Variant_graph_node: # text can be retrieved from token, since no normalization (yet)\n",
    "    id: int\n",
    "    token_positions: defaultdict(int)\n",
    "\n",
    "@dataclass\n",
    "class Variant_graph_edge:\n",
    "    source: int\n",
    "    target: int\n",
    "\n",
    "@dataclass\n",
    "class Variant_graph:\n",
    "    nodes: Set[Variant_graph_node]\n",
    "    edges: Set[Variant_graph_edge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variant_graph_node(id=0, token_positions={'A': -1, 'B': -1}),\n",
       " Variant_graph_node(id=1, token_positions={'A': 6, 'B': 6}),\n",
       " Variant_graph_node(id=2, token_positions={'A': 0}),\n",
       " Variant_graph_node(id=3, token_positions={'A': 1}),\n",
       " Variant_graph_node(id=4, token_positions={'A': 2}),\n",
       " Variant_graph_node(id=5, token_positions={'A': 3}),\n",
       " Variant_graph_node(id=6, token_positions={'A': 4}),\n",
       " Variant_graph_node(id=7, token_positions={'A': 5})]"
      ]
     },
     "execution_count": 40,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the graph and the start and end nodes\n",
    "variant_graph = Variant_graph(nodes=[], edges=[])\n",
    "max_token_pos = max({len(witness) for witness in witnesses}) # 1 greater than position of last token in longest witness\n",
    "variant_graph_start = Variant_graph_node(id=0, token_positions={'A': -1, 'B': -1})\n",
    "variant_graph_end = Variant_graph_node(id=1, token_positions={'A': max_token_pos, 'B': max_token_pos})\n",
    "variant_graph.nodes.append(variant_graph_start)\n",
    "variant_graph.nodes.append(variant_graph_end)\n",
    "\n",
    "# to add first witness, create a variant-graph node for each token in the witness\n",
    "# create pointer from token_position_A to node\n",
    "# create pointer from variant graph node id to the node itself\n",
    "# create edges from each token in A to the next\n",
    "variant_graph_node_by_token_position_A = {}\n",
    "variant_graph_node_by_id = {}\n",
    "variant_graph_node_by_id[0] = variant_graph_start\n",
    "variant_graph_node_by_id[1] = variant_graph_end\n",
    "most_recent_variant_graph_node_id = 0\n",
    "variant_graph_edge_target_by_source = {}\n",
    "for index, token in enumerate(witnesses[0]):\n",
    "    id = len(variant_graph.nodes)\n",
    "    new_variant_graph_node = Variant_graph_node(id=id, token_positions = {'A': index})\n",
    "    variant_graph.nodes.append(new_variant_graph_node)\n",
    "    variant_graph_node_by_token_position_A[index] = id\n",
    "    variant_graph_node_by_id[id] = new_variant_graph_node\n",
    "\n",
    "    variant_graph.edges.append(Variant_graph_edge(source=most_recent_variant_graph_node_id , target=id))\n",
    "    variant_graph_edge_target_by_source[most_recent_variant_graph_node_id] = id\n",
    "    most_recent_variant_graph_node_id = id\n",
    "\n",
    "variant_graph.edges.append(Variant_graph_edge(source=most_recent_variant_graph_node_id, target=variant_graph_end.id)) # add edge from last A node to end node\n",
    "variant_graph_edge_target_by_source[most_recent_variant_graph_node_id] = variant_graph_end.id\n",
    "variant_graph.nodes # take a look\n",
    "# variant_graph.edges\n",
    "# variant_graph_node_by_token_position_A\n",
    "# variant_graph_node_by_id\n",
    "# variant_graph_edge_target_by_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: -1, 0: 0, 2: 2, 3: 3, 5: 5}"
      ]
     },
     "execution_count": 41,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what we want to have: is a mapping from witness B tokens to nodes in the variant graph\n",
    "# What we have (or can easily derive):\n",
    "# A mapping from tokens in witness B to tokens in withness A\n",
    "# A mapping from tokens in witness A to variant-graph nodes\n",
    "#\n",
    "# To get the mapping from tokens A to tokens B we have to go over the alignment path calculated above.\n",
    "# for each item in the path we have a Pattern with two offsets.\n",
    "# We need to convert that into a set of tokens from B mapped to tokens in A\n",
    "\n",
    "tokens_in_A_by_B = {} # use B token position to retrieve A token position\n",
    "\n",
    "for path_node_number in best_path: # best_path is list of node ids, which can be used to find patterns\n",
    "    current_node = node_by_id[path_node_number]\n",
    "    current_pattern = patterns_A[current_node.pattern_coordinate_witness_A] # stores start and end positions for both witnesses\n",
    "    token_position_range_A = range(current_pattern.token_start_position_A, current_pattern.token_end_position_A + 1)\n",
    "    token_position_range_B = range(current_pattern.token_start_position_B, current_pattern.token_end_position_B + 1)\n",
    "    pairs = list(zip(token_position_range_A,token_position_range_B))\n",
    "    ngram = current_pattern.ngram\n",
    "    for pair in pairs:\n",
    "        tokens_in_A_by_B[pair[1]] = pair[0]\n",
    "\n",
    "tokens_in_A_by_B # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variant_graph_node(id=0, token_positions={'A': -1, 'B': -1}),\n",
       " Variant_graph_node(id=1, token_positions={'A': 6, 'B': 6}),\n",
       " Variant_graph_node(id=2, token_positions={'A': 0, 'B': 0}),\n",
       " Variant_graph_node(id=3, token_positions={'A': 1}),\n",
       " Variant_graph_node(id=4, token_positions={'A': 2, 'B': 2}),\n",
       " Variant_graph_node(id=5, token_positions={'A': 3, 'B': 3}),\n",
       " Variant_graph_node(id=6, token_positions={'A': 4}),\n",
       " Variant_graph_node(id=7, token_positions={'A': 5, 'B': 5}),\n",
       " Variant_graph_node(id=8, token_positions={'B': 1}),\n",
       " Variant_graph_node(id=9, token_positions={'B': 4})]"
      ]
     },
     "execution_count": 42,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[Variant_graph_edge(source=0, target=2),\n",
       " Variant_graph_edge(source=2, target=3),\n",
       " Variant_graph_edge(source=3, target=4),\n",
       " Variant_graph_edge(source=4, target=5),\n",
       " Variant_graph_edge(source=5, target=6),\n",
       " Variant_graph_edge(source=6, target=7),\n",
       " Variant_graph_edge(source=7, target=1),\n",
       " Variant_graph_edge(source=2, target=8),\n",
       " Variant_graph_edge(source=8, target=4),\n",
       " Variant_graph_edge(source=5, target=9),\n",
       " Variant_graph_edge(source=9, target=7)]"
      ]
     },
     "execution_count": 42,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loop over tokens in B\n",
    "# if token is aligned and already present in A, update properties of variant graph node\n",
    "# otherwise create new node\n",
    "most_recent_variant_graph_node_id = 0 # source of first edge\n",
    "for index, token in enumerate(witnesses[1]): # each token in B\n",
    "    node_id_to_work_on = -1\n",
    "    if index in tokens_in_A_by_B: # token is aligned and already present for A\n",
    "        current_variant_graph_node_id = variant_graph_node_by_token_position_A[tokens_in_A_by_B[index]]\n",
    "        variant_graph_node_by_id[current_variant_graph_node_id].token_positions['B'] = index\n",
    "        node_id_to_work_on = current_variant_graph_node_id\n",
    "    else: # not in A, so add new node\n",
    "        id = len(variant_graph.nodes)\n",
    "        new_variant_graph_node = Variant_graph_node(id=id, token_positions = {'B': index})\n",
    "        variant_graph.nodes.append(new_variant_graph_node)\n",
    "        variant_graph_node_by_id[id] = new_variant_graph_node\n",
    "        node_id_to_work_on = id\n",
    "\n",
    "    # now we process the edge\n",
    "    if most_recent_variant_graph_node_id in variant_graph_edge_target_by_source and variant_graph_edge_target_by_source[most_recent_variant_graph_node_id] == node_id_to_work_on: # already exists\n",
    "        pass\n",
    "    else: #create it\n",
    "        variant_graph.edges.append(Variant_graph_edge(source=most_recent_variant_graph_node_id , target=node_id_to_work_on))\n",
    "        variant_graph_edge_target_by_source[most_recent_variant_graph_node_id] = node_id_to_work_on\n",
    "    most_recent_variant_graph_node_id = node_id_to_work_on\n",
    "\n",
    "if most_recent_variant_graph_node_id in variant_graph_edge_target_by_source and not variant_graph_edge_target_by_source[most_recent_variant_graph_node_id] == variant_graph_end.id:\n",
    "    variant_graph.edges.append(Variant_graph_edge(source=most_recent_variant_graph_node_id, target=variant_graph_end.id)) # add edge from last B node to end node\n",
    "\n",
    "variant_graph.nodes\n",
    "variant_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Variant_graph_node(id=0, token_positions={'A': -1, 'B': -1}),\n",
       " 1: Variant_graph_node(id=1, token_positions={'A': 6, 'B': 6}),\n",
       " 2: Variant_graph_node(id=2, token_positions={'A': 0, 'B': 0}),\n",
       " 3: Variant_graph_node(id=3, token_positions={'A': 1}),\n",
       " 4: Variant_graph_node(id=4, token_positions={'A': 2, 'B': 2}),\n",
       " 5: Variant_graph_node(id=5, token_positions={'A': 3, 'B': 3}),\n",
       " 6: Variant_graph_node(id=6, token_positions={'A': 4}),\n",
       " 7: Variant_graph_node(id=7, token_positions={'A': 5, 'B': 5}),\n",
       " 8: Variant_graph_node(id=8, token_positions={'B': 1}),\n",
       " 9: Variant_graph_node(id=9, token_positions={'B': 4})}"
      ]
     },
     "execution_count": 43,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variant_graph_node_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: [2],\n",
       "             2: [3, 8],\n",
       "             3: [4],\n",
       "             4: [5],\n",
       "             5: [6, 9],\n",
       "             6: [7],\n",
       "             7: [1],\n",
       "             1: [],\n",
       "             8: [4],\n",
       "             9: [7]})"
      ]
     },
     "execution_count": 44,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create adjacency list for variant graph\n",
    "variant_graph_adjacency_list = defaultdict(list) # key is source, value is list of targets\n",
    "for edge in variant_graph.edges:\n",
    "    variant_graph_adjacency_list[edge.source].append(edge.target)\n",
    "    if edge.target not in variant_graph_adjacency_list: # adjacency list needs a key for every node, even if \n",
    "        variant_graph_adjacency_list[edge.target] = []\n",
    "variant_graph_adjacency_list # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1007pt\" height=\"98pt\" viewBox=\"0.00 0.00 1006.54 98.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 1002.54,-94 1002.54,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"50.7\" cy=\"-45\" rx=\"50.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"50.7\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">0:START</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"192.84\" cy=\"-45\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"192.84\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">2:the</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M101.5,-45C116.57,-45 133,-45 147.67,-45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"148,-48.5 158,-45 148,-41.5 148,-48.5\"/>\n<text text-anchor=\"middle\" x=\"129.89\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">AB</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"956.95\" cy=\"-45\" rx=\"41.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"956.95\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">1:END</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"318.48\" cy=\"-72\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"318.48\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">3:red</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge2\" class=\"edge\">\n<title>2-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M225.04,-51.81C240.44,-55.18 259.24,-59.28 275.85,-62.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"275.34,-66.38 285.86,-65.1 276.84,-59.54 275.34,-66.38\"/>\n<text text-anchor=\"middle\" x=\"250.78\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"318.48\" cy=\"-18\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"318.48\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">8:black</text>\n</g>\n<!-- 2&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>2-&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M225.04,-38.19C238.41,-35.27 254.33,-31.79 269.17,-28.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"270.19,-31.91 279.22,-26.36 268.7,-25.07 270.19,-31.91\"/>\n<text text-anchor=\"middle\" x=\"250.78\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"446.07\" cy=\"-45\" rx=\"36.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"446.07\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">4:and</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge3\" class=\"edge\">\n<title>3-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M351.17,-65.19C366.7,-61.85 385.62,-57.78 402.4,-54.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"403.48,-57.52 412.52,-52 402,-50.68 403.48,-57.52\"/>\n<text text-anchor=\"middle\" x=\"386.18\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"573.92\" cy=\"-45\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"573.92\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">5:the</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge4\" class=\"edge\">\n<title>4-&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M482.8,-45C497.2,-45 513.97,-45 529.1,-45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"529.27,-48.5 539.27,-45 529.27,-41.5 529.27,-48.5\"/>\n<text text-anchor=\"middle\" x=\"510.97\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">AB</text>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"699.56\" cy=\"-72\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"699.56\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">6:black</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge5\" class=\"edge\">\n<title>5-&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M606.12,-51.81C619.49,-54.73 635.41,-58.21 650.25,-61.45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"649.78,-64.93 660.3,-63.64 651.27,-58.09 649.78,-64.93\"/>\n<text text-anchor=\"middle\" x=\"631.86\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"699.56\" cy=\"-18\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"699.56\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">9:red</text>\n</g>\n<!-- 5&#45;&gt;9 -->\n<g id=\"edge10\" class=\"edge\">\n<title>5-&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M606.12,-38.19C621.52,-34.82 640.32,-30.72 656.93,-27.09\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"657.92,-30.46 666.94,-24.9 656.42,-23.62 657.92,-30.46\"/>\n<text text-anchor=\"middle\" x=\"631.86\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"824.55\" cy=\"-45\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"824.55\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">7:cat</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge6\" class=\"edge\">\n<title>6-&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M738.8,-63.61C752.87,-60.52 768.85,-57.01 783.11,-53.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"784.12,-57.24 793.14,-51.68 782.62,-50.4 784.12,-57.24\"/>\n<text text-anchor=\"middle\" x=\"767.26\" y=\"-61.8\" font-family=\"Times,serif\" font-size=\"14.00\">A</text>\n</g>\n<!-- 7&#45;&gt;1 -->\n<g id=\"edge7\" class=\"edge\">\n<title>7-&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M858.46,-45C872.57,-45 889.38,-45 905.03,-45\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"905.11,-48.5 915.11,-45 905.11,-41.5 905.11,-48.5\"/>\n<text text-anchor=\"middle\" x=\"886.85\" y=\"-48.8\" font-family=\"Times,serif\" font-size=\"14.00\">AB</text>\n</g>\n<!-- 8&#45;&gt;4 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M357.85,-26.25C371.89,-29.27 387.87,-32.7 402.28,-35.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"401.94,-39.31 412.45,-37.99 403.41,-32.46 401.94,-39.31\"/>\n<text text-anchor=\"middle\" x=\"386.18\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n</g>\n<!-- 9&#45;&gt;7 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9-&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M732.23,-24.95C747.68,-28.34 766.43,-32.46 782.92,-36.08\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"782.32,-39.53 792.84,-38.26 783.82,-32.69 782.32,-39.53\"/>\n<text text-anchor=\"middle\" x=\"767.26\" y=\"-36.8\" font-family=\"Times,serif\" font-size=\"14.00\">B</text>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 45,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = graphviz.Digraph(format=\"svg\")\n",
    "a.graph_attr['rankdir'] = 'LR'\n",
    "for item in variant_graph.nodes: # set of Node objects, call it \"item\" to avoid overusing the keyword \"node\"\n",
    "    if item.id == 0:\n",
    "        ngram = 'START'\n",
    "    elif item.id== 1:\n",
    "        ngram = 'END'\n",
    "    elif 'A' in item.token_positions:\n",
    "        ngram = witnesses[0][item.token_positions['A']]\n",
    "    elif 'B' in item.token_positions:\n",
    "        ngram = witnesses[1][item.token_positions['B']]\n",
    "    else:\n",
    "        ngram = 'ERROR'\n",
    "    a.node(str(item.id), label=str(item.id) + ':' + ngram)\n",
    "for item in variant_graph.edges:\n",
    "    outgoing_edge_targets = variant_graph_adjacency_list[item.source]\n",
    "    if len(outgoing_edge_targets) == 1: # if there is one edge, get its label from its source\n",
    "        label = \"\".join(variant_graph.nodes[item.source].token_positions.keys())\n",
    "    else: # there are two edges, so two possible cases\n",
    "        outgoing_edge_target_counts = sum([len(variant_graph_node_by_id[target_node].token_positions) for target_node in variant_graph_adjacency_list[item.source]]) # 2 in simple case, 3 in dificult one\n",
    "        if outgoing_edge_target_counts == 2: # easy case; each target has one witness\n",
    "            label = \"\".join([k for k, v in variant_graph_node_by_id[item.target].token_positions.items()]) # ugly way to retrieve a single siglum\n",
    "        else: # difficult case; one target has one witness and one has two; which is which?\n",
    "            node_with_two_witnesses = outgoing_edge_targets[0] if len(variant_graph_node_by_id[outgoing_edge_targets[0]].token_positions) == 2 else outgoing_edge_targets[1]\n",
    "            node_with_one_witness = outgoing_edge_targets[0] if len(variant_graph_node_by_id[outgoing_edge_targets[0]].token_positions) == 1 else outgoing_edge_targets[1]\n",
    "            single_witness_label = [k for k,v in variant_graph_node_by_id[node_with_one_witness].token_positions.items()][0] # ugly way to get only key as string value\n",
    "            difficult_label = ({'A', 'B'} - {single_witness_label})\n",
    "            if item.target == node_with_two_witnesses:\n",
    "                label = difficult_label.pop() # get the lone set member as a string\n",
    "            else:\n",
    "                label = single_witness_label\n",
    "    a.edge(str(item.source), str(item.target), label=label)\n",
    "SVG(a.view())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.svg'"
      ]
     },
     "execution_count": 46,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variant_graph_edge(source=0, target=2),\n",
       " Variant_graph_edge(source=2, target=3),\n",
       " Variant_graph_edge(source=3, target=4),\n",
       " Variant_graph_edge(source=4, target=5),\n",
       " Variant_graph_edge(source=5, target=6),\n",
       " Variant_graph_edge(source=6, target=7),\n",
       " Variant_graph_edge(source=7, target=1),\n",
       " Variant_graph_edge(source=2, target=8),\n",
       " Variant_graph_edge(source=8, target=4),\n",
       " Variant_graph_edge(source=5, target=9),\n",
       " Variant_graph_edge(source=9, target=7)]"
      ]
     },
     "execution_count": 47,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variant_graph.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 2: 8, 3: 4, 4: 5, 5: 9, 6: 7, 7: 1, 8: 4, 9: 7}"
      ]
     },
     "execution_count": 48,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variant_graph_edge_target_by_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}