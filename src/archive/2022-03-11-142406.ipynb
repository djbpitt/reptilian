{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Python wrapper for Java VPMF implementation\n",
    "\n",
    "## Built-in I/O assumptions\n",
    "\n",
    "* Input must be a file from the filesystem with integers (not word tokens)\n",
    "* Output must be a file written to disk with integers\n",
    "\n",
    "## Method\n",
    "\n",
    "1. Read in input file that contains string data\n",
    "1. Create dictionary with mapping from unique strings to unique integers\n",
    "1. Use dictionary to convert token strings to integers and store as *input.txt*\n",
    "1. Run VSMP, which creates *output.txt* with integer data\n",
    "1. Read in *output.txt* and convert integers back to work tokens\n",
    "\n",
    "## Data samples\n",
    "\n",
    "1. cat1.txt, cat2.txt, cat3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# NO INTERNAL REFERENCE\n",
    "# from https://github.com/fandu/maximal-sequential-patterns-mining\n",
    "import subprocess\n",
    "\n",
    "\n",
    "class Vmsp:\n",
    "    def __init__(self):\n",
    "        self._executable = \"spmf.jar\"\n",
    "        self._input = \"input.txt\"\n",
    "        self._output = \"output.txt\"\n",
    "\n",
    "    def run(self, min_supp=1): # originally min_supp=0.5; change to 1 means must be in all witnesses\n",
    "        # java -jar spmf.jar run VMSP contextPrefixSpan.txt output.txt 50%\n",
    "        subprocess.call([\"java\", \"-jar\", self._executable, \"run\", \"VMSP\", self._input, self._output, str(min_supp)])\n",
    "\n",
    "    def encode_input(self, data):\n",
    "        pass\n",
    "\n",
    "    def decode_output(self):\n",
    "        # read\n",
    "        lines = []\n",
    "        try:\n",
    "            with open(self._output, \"r\") as f: # modified to remove deprecated U mode\n",
    "                lines = f.readlines()\n",
    "        except:\n",
    "            print(\"read_output error\") # modified to add parentheses\n",
    "\n",
    "        # decode\n",
    "        patterns = []\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            patterns.append(line.split(\" -1 \"))\n",
    "\n",
    "        return patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# Create list of lists with word tokens\n",
    "# text_data = []\n",
    "#\n",
    "# for i in range(1,4): # Small example with cats\n",
    "#     with open('cat' + str(i) + '.txt', 'r') as f:\n",
    "#         text_data.append([token for token in f.read().split()])\n",
    "#\n",
    "# Find all six Darwin witnesses; filename is darwin18\\d\\d.txt\n",
    "# Each paragraph is one line\n",
    "#\n",
    "# import glob\n",
    "# filenames = glob.glob('darwin18??.txt')\n",
    "# for filename in filenames[:2]: # each of six files\n",
    "#     file_tokens = [] # all tokens for single file\n",
    "#     with open(filename, 'r') as f:\n",
    "#         for paragraph in range(2): # read two paragraphs\n",
    "#             file_tokens.extend([token for token in f.readline().rstrip().split()])\n",
    "#         text_data.append(file_tokens)\n",
    "# print(len(text_data))\n",
    "# print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Create integer data\n",
    "# token_to_integer = {}\n",
    "# integer_data = []\n",
    "# for witness_data in text_data:\n",
    "#     witness_integers = []\n",
    "#     for token in witness_data:\n",
    "#         if token not in token_to_integer:\n",
    "#             token_to_integer[token] = len(token_to_integer) # add value to dictionary, use len() for unique value\n",
    "#         witness_integers.append(str(token_to_integer[token]))\n",
    "#     integer_data.append(witness_integers)\n",
    "# print(integer_data)\n",
    "# print(token_to_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Write integer data to disk as 'input.txt'\n",
    "# Each witness is a line\n",
    "# with open('input.txt', 'w') as f:\n",
    "#     for witness in integer_data:\n",
    "#         f.write(\" -1 \".join(witness))\n",
    "#         f.write(' -1 -2\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Check new integer file\n",
    "# with open('input.txt', 'r') as f:\n",
    "#     lines = f.readlines()\n",
    "#     print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/home/user/tmp -Xms64m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">/home/user/our_experiment/spmf.jar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error while trying to run the algorithm. \n",
      " ERROR MESSAGE = java.lang.OutOfMemoryError: Java heap space\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.BitSet.initWords(BitSet.java:167)\n",
      "\tat java.base/java.util.BitSet.<init>(BitSet.java:162)\n",
      "\tat ca.pfv.spmf.algorithms.sequentialpatterns.spam.Bitmap.<init>(Bitmap.java:63)\n",
      "\tat ca.pfv.spmf.algorithms.sequentialpatterns.spam.AlgoVMSP.vmsp(AlgoVMSP.java:270)\n",
      "\tat ca.pfv.spmf.algorithms.sequentialpatterns.spam.AlgoVMSP.runAlgorithm(AlgoVMSP.java:134)\n",
      "\tat ca.pfv.spmf.algorithmmanager.descriptions.DescriptionAlgoVMSP.runAlgorithm(DescriptionAlgoVMSP.java:70)\n",
      "\tat ca.pfv.spmf.gui.CommandProcessor.runAlgorithm(CommandProcessor.java:385)\n",
      "\tat ca.pfv.spmf.gui.Main.processCommandLineArguments(Main.java:128)\n",
      "\tat ca.pfv.spmf.gui.Main.main(Main.java:54)\n"
     ]
    }
   ],
   "source": [
    "# Do the work\n",
    "if __name__ == \"__main__\":\n",
    "    vmsp = Vmsp()\n",
    "    vmsp.encode_input([])\n",
    "    vmsp.run()\n",
    "    print(vmsp.decode_output()) # modified to add parentheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Convert integer output back to strings\n",
    "# integer_to_token = {v:k for k, v in token_to_integer.items()} # invert dictionary to decode\n",
    "# results = [] # hold results as list of lists\n",
    "# with open('output.txt', 'r') as f:\n",
    "#     for line in f:\n",
    "#         results.append([integer_to_token[int(token)] for token in line.split()[:-2] if int(token) != -1])\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}