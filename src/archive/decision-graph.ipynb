{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Collation with decision graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# two witnesses, with repetition and transposition\n",
    "\n",
    "w1 = \"\"\"the red and the black cat\"\"\"\n",
    "w2 = \"\"\"the black and the red cat\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Construct list of ngrams shared by witnesses\n",
    "\n",
    "Find ngrams and positions in witnesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tokenize witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def tokenize_witnesses(w1_string, w2_string):\n",
    "    '''Return list of witnesses, each represented by a list of tokens'''\n",
    "    # TODO: handle punctuation, upper- ~ lowercase\n",
    "    w1_tokens = w1.split()\n",
    "    w2_tokens = w2.split()\n",
    "    witnesses = [w1_tokens, w2_tokens]\n",
    "    return witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the', 'red', 'and', 'the', 'black', 'cat'], ['the', 'black', 'and', 'the', 'red', 'cat']]\n"
     ]
    }
   ],
   "source": [
    "witnesses = tokenize_witnesses(w1, w2)\n",
    "print(witnesses) # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Find ngrams shared by the witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def compute_ngrams_all(witness):\n",
    "    '''Create n-grams and returns offsets and lengths\n",
    "\n",
    "    Argument:\n",
    "    witness:list -- list of tokens in witness\n",
    "\n",
    "    Returns:\n",
    "    ngrams:dict --       key is ngram\n",
    "                         value is list of start positions in witness for ngram\n",
    "    token_counts:dict -- key is ngram\n",
    "                         value is token count of ngram\n",
    "    '''\n",
    "    ngram_offsets = defaultdict(list)\n",
    "    token_counts = {}\n",
    "    for n in range(1, len(witness) + 1):\n",
    "        for i in range(len(witness)-n+1):\n",
    "            g = ' '.join(witness[i:i+n]) # store each ngram as g temporarily\n",
    "            ngram_offsets[g].append(i)\n",
    "            token_counts[g] = n\n",
    "    return ngram_offsets, token_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "ngram_offsets_by_witness_dict = {} # keyed by witness\n",
    "ngram_lengths = {}\n",
    "for index, witness in enumerate(witnesses):\n",
    "    map1, map2 = compute_ngrams_all(witness)\n",
    "    ngram_offsets_by_witness_dict['w' + str(index + 1)] = map1\n",
    "    ngram_lengths.update(map2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witness w1\n",
      "defaultdict(<class 'list'>, {'the': [0, 3], 'red': [1], 'and': [2], 'black': [4], 'cat': [5], 'the red': [0], 'red and': [1], 'and the': [2], 'the black': [3], 'black cat': [4], 'the red and': [0], 'red and the': [1], 'and the black': [2], 'the black cat': [3], 'the red and the': [0], 'red and the black': [1], 'and the black cat': [2], 'the red and the black': [0], 'red and the black cat': [1], 'the red and the black cat': [0]})\n",
      "\n",
      "Witness w2\n",
      "defaultdict(<class 'list'>, {'the': [0, 3], 'black': [1], 'and': [2], 'red': [4], 'cat': [5], 'the black': [0], 'black and': [1], 'and the': [2], 'the red': [3], 'red cat': [4], 'the black and': [0], 'black and the': [1], 'and the red': [2], 'the red cat': [3], 'the black and the': [0], 'black and the red': [1], 'and the red cat': [2], 'the black and the red': [0], 'black and the red cat': [1], 'the black and the red cat': [0]})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at ngram lists for each witness\n",
    "# Keys of inner dictionary are ngrams, values are lists of start positions in witness\n",
    "for key in ngram_offsets_by_witness_dict.keys():\n",
    "    print('Witness ' + key)\n",
    "    print(ngram_offsets_by_witness_dict[key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'red': 1, 'and': 1, 'black': 1, 'cat': 1, 'the red': 2, 'red and': 2, 'and the': 2, 'the black': 2, 'black cat': 2, 'the red and': 3, 'red and the': 3, 'and the black': 3, 'the black cat': 3, 'the red and the': 4, 'red and the black': 4, 'and the black cat': 4, 'the red and the black': 5, 'red and the black cat': 5, 'the red and the black cat': 6, 'black and': 2, 'red cat': 2, 'the black and': 3, 'black and the': 3, 'and the red': 3, 'the red cat': 3, 'the black and the': 4, 'black and the red': 4, 'and the red cat': 4, 'the black and the red': 5, 'black and the red cat': 5, 'the black and the red cat': 6}\n"
     ]
    }
   ],
   "source": [
    "# Look at ngram lengths (combined)\n",
    "print(ngram_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and', 'and the', 'black', 'cat', 'red', 'the', 'the black', 'the red'}"
      ]
     },
     "execution_count": 8,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find keys shared by *all* witnesses\n",
    "shared_ngrams = set(ngram_offsets_by_witness_dict[\"w1\"].keys())\n",
    "for value in ngram_offsets_by_witness_dict.values():\n",
    "    shared_ngrams = shared_ngrams.intersection(value.keys())\n",
    "\n",
    "shared_ngrams # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Use shared ngrams to find potential alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'black': [(4, 1)], 'the black': [(3, 0)], 'the': [(0, 0), (0, 3), (3, 0), (3, 3)], 'and': [(2, 2)], 'cat': [(5, 5)], 'red': [(1, 4)], 'the red': [(0, 3)], 'and the': [(2, 2)]})\n"
     ]
    }
   ],
   "source": [
    "# output format: {ngram : [(0,1), (2,3)]}, where\n",
    "#   the two entries in each tuple are for witnesses A and B\n",
    "potential_alignments = defaultdict(list)\n",
    "for ngram in shared_ngrams:\n",
    "    for w1_offset in ngram_offsets_by_witness_dict['w1'][ngram]:\n",
    "        for w2_offset in ngram_offsets_by_witness_dict['w2'][ngram]:\n",
    "            potential_alignments[ngram].append((w1_offset, w2_offset))\n",
    "\n",
    "print(potential_alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Invert keys and values for potential alignments\n",
    "\n",
    "* Keys are now individual tuples of (A, B) start positions\n",
    "* Values are now lists of ngrams of different lengths at those positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {(4, 1): ['black'], (3, 0): ['the black', 'the'], (0, 0): ['the'], (0, 3): ['the', 'the red'], (3, 3): ['the'], (2, 2): ['and', 'and the'], (5, 5): ['cat'], (1, 4): ['red']})\n"
     ]
    }
   ],
   "source": [
    "alignments = defaultdict(list)\n",
    "for key,value in potential_alignments.items():\n",
    "    for t in value:\n",
    "        alignments[t].append(key)\n",
    "\n",
    "print(alignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create bitarrays of all potentials to track committed tokens\n",
    "\n",
    "Keys are tuples of A-start, B-start, ngram\n",
    "Values are bitarrays the length of the witness token-count, with bits set for ngram\n",
    "\n",
    "Why? To avoid having to recompute each time we compare. To compare:\n",
    "\n",
    "1. Compute bitarray for pattern being tested\n",
    "1. Perform bitwise \"and\" operation (`&`) on pattern being tested and pattern to which it is being compared\n",
    "1. Yields 0 result only if the two have no bits in common, i.e., no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# globals\n",
    "from bitarray import bitarray\n",
    "bitarray_A = bitarray(len(witnesses[0]))\n",
    "bitarray_A.setall(0)\n",
    "bitarray_B = bitarray(len(witnesses[1]))\n",
    "bitarray_B.setall(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def compute_bitarray(pattern:tuple) -> dict:\n",
    "    '''Compute bitarray for (A, B, 'ngram')\n",
    "\n",
    "    Arguments:\n",
    "\n",
    "    pattern:tuple -- (A, B, 'ngram1')\n",
    "\n",
    "    Returns dictionary with keys 'A', 'B'\n",
    "    '''\n",
    "    ngram_length = ngram_lengths[pattern[2]]\n",
    "    ba_A = bitarray(bitarray_A)\n",
    "    ba_A[pattern[0]: pattern[0] + ngram_length] = 1\n",
    "    ba_B = bitarray(bitarray_B)\n",
    "    ba_B[pattern[1]: pattern[1] + ngram_length] = 1\n",
    "    return {'A': ba_A, 'B': ba_B}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': bitarray('110000'), 'B': bitarray('000110')}"
      ]
     },
     "execution_count": 13,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test compute_bitarray function\n",
    "\n",
    "compute_bitarray((0, 3, 'the red'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(4, 1, 'black'): {'A': bitarray('000010'), 'B': bitarray('010000')},\n",
       " (3, 0, 'the black'): {'A': bitarray('000110'), 'B': bitarray('110000')},\n",
       " (3, 0, 'the'): {'A': bitarray('000100'), 'B': bitarray('100000')},\n",
       " (0, 0, 'the'): {'A': bitarray('100000'), 'B': bitarray('100000')},\n",
       " (0, 3, 'the'): {'A': bitarray('100000'), 'B': bitarray('000100')},\n",
       " (0, 3, 'the red'): {'A': bitarray('110000'), 'B': bitarray('000110')},\n",
       " (3, 3, 'the'): {'A': bitarray('000100'), 'B': bitarray('000100')},\n",
       " (2, 2, 'and'): {'A': bitarray('001000'), 'B': bitarray('001000')},\n",
       " (2, 2, 'and the'): {'A': bitarray('001100'), 'B': bitarray('001100')},\n",
       " (5, 5, 'cat'): {'A': bitarray('000001'), 'B': bitarray('000001')},\n",
       " (1, 4, 'red'): {'A': bitarray('010000'), 'B': bitarray('000010')}}"
      ]
     },
     "execution_count": 14,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precompute bitarrays for all (A, B, 'ngram') combinations as dictionary (tuple key) of dictionaries ('A' or 'B' key)\n",
    "committed_tokens = {} # (A,B,'ngram') : {'A': 0000110, 'B': 000100}, for token positions in two witnesses\n",
    "for location, ngrams in alignments.items(): # may contain multiple ngrams at same location\n",
    "    for ngram in ngrams:\n",
    "        committed_tokens[(location[0], location[1], ngram)] = compute_bitarray((location[0], location[1], ngram))\n",
    "committed_tokens # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Create function to compare bitarrays to check for overlap\n",
    "\n",
    "Logical and (`&`) returns 1 for overlapping bits. `.any()` method of bitarray object returns True if any bit is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def compare_bitarrays(new:bitarray, old:bitarray) -> bool:\n",
    "    '''Compare two bitarrays, return true if overlap\n",
    "\n",
    "    Retrieves values from precomputed dictionary of all possible (A, B, 'ngram') tuples\n",
    "\n",
    "    Arguments:\n",
    "        new:bitarray\n",
    "        old:bitarray\n",
    "    '''\n",
    "    return (new & old).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# test comparisons\n",
    "with_overlap = compare_bitarrays(committed_tokens[(0, 3, 'the')]['A'], \\\n",
    "                                 committed_tokens[(0, 3, 'the red')]['A']) # true because overlap\n",
    "print(with_overlap)\n",
    "without_overlap = compare_bitarrays(committed_tokens[(0,3,'the')]['A'], \\\n",
    "                                    committed_tokens[(5, 5, 'cat')]['A']) # false because no overlap\n",
    "print(without_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def add_to_bitarray(new:bitarray, old:bitarray):\n",
    "    '''Add new bitarray to accumulated one with logical or (|)\n",
    "\n",
    "    Used in loop to build cumulative bitarray to store state of all committed patterns\n",
    "\n",
    "    Arguments:\n",
    "        new:bitarray -- bitarray for a new pattern (from compute_bitarray(pattern:tuple))\n",
    "        old:bitarray -- accumulated bitarray\n",
    "    '''\n",
    "    return (new | old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data: bitarray('000010'), interim result: bitarray('000010')\n",
      "New data: bitarray('000110'), interim result: bitarray('000110')\n",
      "New data: bitarray('000100'), interim result: bitarray('000110')\n",
      "New data: bitarray('100000'), interim result: bitarray('100110')\n",
      "New data: bitarray('100000'), interim result: bitarray('100110')\n",
      "New data: bitarray('110000'), interim result: bitarray('110110')\n",
      "New data: bitarray('000100'), interim result: bitarray('110110')\n",
      "New data: bitarray('001000'), interim result: bitarray('111110')\n",
      "New data: bitarray('001100'), interim result: bitarray('111110')\n",
      "New data: bitarray('000001'), interim result: bitarray('111111')\n",
      "New data: bitarray('010000'), interim result: bitarray('111111')\n",
      "Final result: bitarray('111111')\n"
     ]
    }
   ],
   "source": [
    "# test add_to_bitarray\n",
    "old = bitarray(bitarray_A) # initialize as all zeros\n",
    "for k, v in committed_tokens.items(): # initialized above as (A, B, 'ngram') : {'A': ba_A, 'B': ba_B}\n",
    "    old = add_to_bitarray(v['A'], old) # logical or with new bitarray\n",
    "    print('New data: ' + str(v['A']) + ', interim result: ' + str(old)) # interim new bitarray and new result\n",
    "print('Final result: ' + str(old))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Convert alignments dictionary to sorted list of tuples, where ngrams within are sorted tuples of strings\n",
    "\n",
    "* Tuples are (A-position:int, B-position:int, ngrams), sorted by A position from left to right\n",
    "* Ngrams are tuples of all ngrams at that position, sorted from longest to shorted\n",
    "\n",
    "Note: Use tuple instead of list for ngrams to support sorting; this functions as a frozen list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, ('the',)), (0, 3, ('the red', 'the')), (1, 4, ('red',)), (2, 2, ('and the', 'and')), (3, 0, ('the black', 'the')), (3, 3, ('the',)), (4, 1, ('black',)), (5, 5, ('cat',))]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "sorted_alignments_witness_A = []\n",
    "for key in sorted(alignments):\n",
    "    sorted_alignments_witness_A.append((key[0],key[1], tuple(sorted(alignments[key], key=lambda x: ngram_lengths[x], reverse=True))))\n",
    "\n",
    "print(sorted_alignments_witness_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, ('the',))\n",
      "(0, 3, ('the red', 'the'))\n",
      "(1, 4, ('red',))\n",
      "(2, 2, ('and the', 'and'))\n",
      "(3, 0, ('the black', 'the'))\n",
      "(3, 3, ('the',))\n",
      "(4, 1, ('black',))\n",
      "(5, 5, ('cat',))\n"
     ]
    }
   ],
   "source": [
    "# Does it work?\n",
    "for entry in sorted_alignments_witness_A:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, ('the',)),\n",
       " (3, 0, ('the black', 'the')),\n",
       " (4, 1, ('black',)),\n",
       " (2, 2, ('and the', 'and')),\n",
       " (0, 3, ('the red', 'the')),\n",
       " (3, 3, ('the',)),\n",
       " (1, 4, ('red',)),\n",
       " (5, 5, ('cat',))]"
      ]
     },
     "execution_count": 21,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also sort by witness B\n",
    "sorted_alignments_witness_B = sorted(sorted_alignments_witness_A, key=lambda x:(x[1], x[0]))\n",
    "sorted_alignments_witness_B # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Build the decision graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Node subdictionary, keyed by node id, stores the following properties\n",
    "\n",
    "Key is unique integer\n",
    "\n",
    "Properties:\n",
    "\n",
    "* **id**:int (same as key for this node)\n",
    "* **current-location-in-A**:int (last token position committed in witness A)\n",
    "* **current-location-in-B**:int (last token position committed in witness A)\n",
    "* **aligned-patterns**:list [(offsetA:int, offsetB:int, ngram:str)], where offsets are start positions of ngrams\n",
    "* **transposed-patterns**:list [(offsetA:int, offsetB:int, ngram:str)], where offsets are start positions of ngrams\n",
    "* **potential-alignments-by-A**:list [(offsetA:int, offsetB:int, ngram:str)]\n",
    "* **potential-alignments-by-B**:list [(offsetB:int, offsetA:int, ngram:str)]\n",
    "\n",
    "### Internal edge subdictionaries, for incoming and outgoing edges\n",
    "\n",
    "Key is id of parent or child for outgoing and incoming subdictionaries, respectively\n",
    "\n",
    "Value is list of ids of parents or children for incoming and outgoing subdictionaries, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': defaultdict(dict, {}),\n",
       " 'edges': {'incoming': defaultdict(list, {}),\n",
       "  'outgoing': defaultdict(list, {})}}"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create outer dictionary for decision tree nodes\n",
    "decision_graph = {}\n",
    "\n",
    "# Create inner dictionaries for nodes and edges\n",
    "\n",
    "decision_graph['nodes'] = defaultdict(dict)\n",
    "decision_graph['edges'] = {}\n",
    "decision_graph['edges']['incoming'] = defaultdict(list)\n",
    "decision_graph['edges']['outgoing'] = defaultdict(list)\n",
    "\n",
    "decision_graph # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Keep track of nodes by position value in dataframe\n",
    "\n",
    "Columns:\n",
    "\n",
    "* **start_A**:int\n",
    "* **end_A**:int\n",
    "* **start_B**:int\n",
    "* **end_B**:int\n",
    "* **best_sum**:int               Best sum of tokens in alignments and potential alignments for that set of four positions\n",
    "\n",
    "For each new node:\n",
    "\n",
    "**TODO:** Is this correct?\n",
    "\n",
    "1. If the df does not have an entry at that position: create new row\n",
    "2. If the df already has an entry at that position, compare best_sum for aligned and potential patterns\n",
    "   (Note: avoid double-counting tokens with subpatterns)\n",
    "    1. If the best_sum of new item already in df at location (by both start and end nodes) is higher than new node\n",
    "        1. Don't add new node to graph\n",
    "        1. Don't update df\n",
    "    1. If the best_sum of new item is higher (better) than the existing one\n",
    "        1. Add new node to graph\n",
    "        1. Update best_sum in df with new higher value\n",
    "        1. (TODO: Prune nodes now discovered to be suboptimal)\n",
    "    1. If the new sum is the same as the existing one\n",
    "        1. Add new node to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Computes weights used to make ... er ... decisions\n",
    "# Counts tokens, not patterns\n",
    "def count_tokens(patterns:list) -> int:\n",
    "    '''Count tokens covered by list of patterns, accounting for overlap\n",
    "\n",
    "    Since patterns are shared by witness, just count for A\n",
    "\n",
    "    Arguments:\n",
    "    patterns:list -- list of aligned or potential patterns\n",
    "    '''\n",
    "    token_positions = [] # list of integers, with duplicates\n",
    "    for pattern in patterns: # check each aligned or potential pattern\n",
    "        ngram_length = ngram_lengths[pattern[2][0]] # token length\n",
    "        committed_tokens = list(range(pattern[0], pattern[0] + ngram_length)) # expand range\n",
    "        token_positions.append(committed_tokens) # append committed token positions for current pattern\n",
    "    return len(set(item for sublist in token_positions for item in sublist)) # flatten, deduplicate, count\n",
    "\n",
    "def compute_pattern_sum(node: dict) -> int:\n",
    "    '''Compute sum of alignments and potential alignments\n",
    "\n",
    "    Higher values are better\n",
    "\n",
    "    Arguments:\n",
    "    node:dict -- node to evaluate (look at 'aligned-patterns' and 'potential-alignments-by-A' properties)\n",
    "    '''\n",
    "    return count_tokens(node['aligned-patterns']) + \\\n",
    "        count_tokens(node['potential-alignments-by-A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# test count_tokens() function\n",
    "test1 = [(0, 0, ('the',)), (0, 3, ('the red', 'the')), (1, 4, ('red',))]\n",
    "print(count_tokens(test1)) # returns 2, since positions 0 and 1 are committed in A)\n",
    "test2 = [(3, 0, ('the black', 'the')), (3, 3, ('the',)), (4, 1, ('black',)), (5, 5, ('cat',))]\n",
    "print(count_tokens(test2)) # returns 3, since positions 3, 4, and 5 are committed in A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# test compute_pattern_sum() function\n",
    "# Note: fake data\n",
    "test = {'id': 0, \\\n",
    " 'aligned-patterns': [(0, 0, ('the',)), (0, 3, ('the red', 'the')), (1, 4, ('red',))], \\\n",
    " 'transposed-patterns': [], \\\n",
    " 'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
    "       }\n",
    "print(compute_pattern_sum(test)) # returns 3 because 0 and 1 are committed as aligned in A and 5 as potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_A</th>\n",
       "      <th>end_A</th>\n",
       "      <th>start_B</th>\n",
       "      <th>end_B</th>\n",
       "      <th>best_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [start_A, end_A, start_B, end_B, best_sum]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "node_tracker = pd.DataFrame({'start_A': pd.Series([], dtype='int'), \\\n",
    "                             'end_A': pd.Series([], dtype='int'), \\\n",
    "                             'start_B': pd.Series([], dtype='int'), \\\n",
    "                             'end_B': pd.Series([], dtype='int'), \\\n",
    "                             'best_sum': pd.Series([], dtype='int') \\\n",
    "                            })\n",
    "node_tracker # take a look"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Add root note to graph\n",
    "\n",
    "No edges yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "decision_graph['nodes'][0] = {}\n",
    "\n",
    "# Supply properties for root node\n",
    "decision_graph['nodes'][0]['id'] = 0 # what's my key?\n",
    "decision_graph['nodes'][0]['type'] = None # normally 'align' or 'transpose'\n",
    "decision_graph['nodes'][0]['current-location-in-A'] = -1 # 0 would be the first position\n",
    "decision_graph['nodes'][0]['current-location-in-B'] = -1\n",
    "decision_graph['nodes'][0]['aligned-patterns'] = []\n",
    "decision_graph['nodes'][0]['transposed-patterns'] = []\n",
    "decision_graph['nodes'][0]['potential-alignments-by-A'] = sorted_alignments_witness_A\n",
    "decision_graph['nodes'][0]['potential-alignments-by-B'] = sorted_alignments_witness_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'type': None,\n",
       " 'current-location-in-A': -1,\n",
       " 'current-location-in-B': -1,\n",
       " 'aligned-patterns': [],\n",
       " 'transposed-patterns': [],\n",
       " 'potential-alignments-by-A': [(0, 0, ('the',)),\n",
       "  (0, 3, ('the red', 'the')),\n",
       "  (1, 4, ('red',)),\n",
       "  (2, 2, ('and the', 'and')),\n",
       "  (3, 0, ('the black', 'the')),\n",
       "  (3, 3, ('the',)),\n",
       "  (4, 1, ('black',)),\n",
       "  (5, 5, ('cat',))],\n",
       " 'potential-alignments-by-B': [(0, 0, ('the',)),\n",
       "  (3, 0, ('the black', 'the')),\n",
       "  (4, 1, ('black',)),\n",
       "  (2, 2, ('and the', 'and')),\n",
       "  (0, 3, ('the red', 'the')),\n",
       "  (3, 3, ('the',)),\n",
       "  (1, 4, ('red',)),\n",
       "  (5, 5, ('cat',))]}"
      ]
     },
     "execution_count": 28,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at nodes (just root node)\n",
    "# Don't bother with edges; there aren't any yet\n",
    "decision_graph['nodes'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Add root node to node_tracker dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# To add row to df without copying:\n",
    "#   df.loc[df.index.max() + 1] (note: must set 0 explicitly because max() errors on no rows)\n",
    "#   See: https://stackoverflow.com/questions/10715965/add-one-row-to-pandas-dataframe\n",
    "best_sum = compute_pattern_sum(decision_graph['nodes'][0])\n",
    "node_tracker.loc[0] = [-1, -1, -1, -1, best_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_A     int64\n",
      "end_A       int64\n",
      "start_B     int64\n",
      "end_B       int64\n",
      "best_sum    int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_A</th>\n",
       "      <th>end_A</th>\n",
       "      <th>start_B</th>\n",
       "      <th>end_B</th>\n",
       "      <th>best_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_A  end_A  start_B  end_B  best_sum\n",
       "0       -1     -1       -1     -1         6"
      ]
     },
     "execution_count": 30,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at the df\n",
    "print(node_tracker.dtypes)\n",
    "node_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Function to add child nodes recursively\n",
    "#\n",
    "# Note: Currently depth-first; would breadth-first be more efficient?\n",
    "#\n",
    "# Within children:\n",
    "#   Update current location in A and B\n",
    "#   Update aligned patterns\n",
    "#   Update transposed patterns\n",
    "#   Update potential alignments for A and B\n",
    "#\n",
    "# Add three types of nodes:\n",
    "#\n",
    "#   1. Align closest in both witnesses, advance both locations by 1\n",
    "#      There should be zero or one of these\n",
    "#   2. Align closest in one witness, but not the other, advance pointers different amounts\n",
    "#      There should be zero or two or more, closest in witness A (but not B) and vice versa\n",
    "#      May not be symmetrical because of repetition\n",
    "#   3. Advance pointer by one in both witnesses, but no alignment\n",
    "#      If we get to type 2, there should be one of type 3\n",
    "#\n",
    "# Uses globals:\n",
    "#   node_tracker:pd.DataFrame()\n",
    "#   decision_graph:dict\n",
    "#   ngram_lengths:dict\n",
    "\n",
    "\n",
    "def add_children(parent_id: int) -> dict: # children know their parents when they're called\n",
    "    # get nearest matches in new child node and prepare to recur over its children\n",
    "    # Sort the union of nearest matches for consistency during development; does not affect logic\n",
    "    # This gets node types 1 and 2 (see comment above), but not 3\n",
    "    nearest_A_matches = [item for item in decision_graph['nodes'][parent_id]['potential-alignments-by-A'] if item[0] == decision_graph['nodes'][parent_id]['potential-alignments-by-A'][0][0]]\n",
    "    nearest_B_matches = [item for item in decision_graph['nodes'][parent_id]['potential-alignments-by-B'] if item[1] == decision_graph['nodes'][parent_id]['potential-alignments-by-B'][0][1]]\n",
    "    nearest_matches = sorted({item for item in nearest_A_matches + nearest_B_matches})\n",
    "\n",
    "    for child in nearest_matches:\n",
    "        # child looks like: (1, 2, ('hi mon', 'hi')): start location in A, in B, ngrams at that location\n",
    "        location = np.array([child[0], child[1]]) # to check for presence in node_tracker\n",
    "\n",
    "        if (node_tracker[node_tracker.columns[:2]] == location).all(1).any(): # https://stackoverflow.com/questions/24761133/pandas-check-if-row-exists-with-certain-values, (df == a).all(1).any()\n",
    "            # https://stackoverflow.com/questions/21800169/python-pandas-get-index-of-rows-which-column-matches-certain-value\n",
    "            # node is already in graph, so:\n",
    "            #   add new edges\n",
    "            id = node_tracker.index[((node_tracker['start_A'] == child[0]) & (node_tracker['start_B'] == child[1]))][0] # index of node in dataframe\n",
    "            decision_graph['edges']['incoming'][id].append(parent_id)\n",
    "            decision_graph['edges']['outgoing'][parent_id].append(id)\n",
    "            #   TODO: if weight is better, update node (aligned and transposed patterns) and sum in df\n",
    "        else: # add new node to graph and df, add new edges\n",
    "            #################################\n",
    "            # Add new node to graph\n",
    "            #################################\n",
    "            current_ngram_length = ngram_lengths[child[2][0]]\n",
    "            id = len(decision_graph['nodes'])\n",
    "            decision_graph['nodes'][id] = {} # create new node\n",
    "            decision_graph['nodes'][id]['id'] = id\n",
    "            if child[0] == decision_graph['nodes'][parent_id]['potential-alignments-by-A'][0][0] and child[1] == decision_graph['nodes'][parent_id]['potential-alignments-by-B'][0][1]:\n",
    "                decision_graph['nodes'][id]['type'] = 'closest-in-both'\n",
    "            else:\n",
    "                decision_graph['nodes'][id]['type'] = 'closest-in-one'\n",
    "            decision_graph['nodes'][id]['current-location-in-A'] = child[0] + current_ngram_length - 1\n",
    "            decision_graph['nodes'][id]['current-location-in-B'] = child[1] + current_ngram_length - 1\n",
    "\n",
    "            # copy parent's aligned and transposed patterns first; adjust below\n",
    "            aligned_patterns = decision_graph['nodes'][parent_id]['aligned-patterns'].copy()\n",
    "            aligned_patterns.append(child)\n",
    "            decision_graph['nodes'][id]['aligned-patterns'] = aligned_patterns\n",
    "            transposed_patterns = decision_graph['nodes'][parent_id]['transposed-patterns'].copy()\n",
    "            decision_graph['nodes'][id]['transposed-patterns'] = transposed_patterns\n",
    "            decision_graph['nodes'][id]['potential-alignments-by-A'] = []\n",
    "\n",
    "            # create cumulative bitmaps of transposed tokens in each witness (ba1 and ba2 in old version)\n",
    "            transposed_patterns_A_bitarray = bitarray(bitarray_A) # initialize as all unset\n",
    "            for transposed_pattern in decision_graph['nodes'][id]['transposed-patterns']:\n",
    "                transposed_patterns_A_bitarray[transposed_pattern[0]:transposed_pattern[0] + ngram_lengths[transposed_pattern[2][0]]] = 1\n",
    "            transposed_patterns_B_bitarray = bitarray(bitarray_B)\n",
    "            for transposed_pattern in decision_graph['nodes'][id]['transposed-patterns']:\n",
    "                transposed_patterns_B_bitarray[transposed_pattern[1]:transposed_pattern[1] + ngram_lengths[transposed_pattern[2][0]]] = 1\n",
    "            current_pattern_bitarrays = compute_bitarray((child[0], child[1], child[2][0]))\n",
    "\n",
    "            for potential_alignment in decision_graph['nodes'][parent_id]['potential-alignments-by-A']: # (A, B, ('ngram1', 'ngram2'))\n",
    "                if potential_alignment[0] > decision_graph['nodes'][id]['current-location-in-A'] and potential_alignment[1] > decision_graph['nodes'][id]['current-location-in-B']:\n",
    "                    decision_graph['nodes'][id]['potential-alignments-by-A'].append(potential_alignment) # to the right of current, so still potential\n",
    "                else: # check for transpositions and overlaps\n",
    "                    for local_ngram in potential_alignment[2]: # check each ngram in current candidate\n",
    "                        local_ngram_length = ngram_lengths[local_ngram] # get its length\n",
    "                        local_ngram_bitarrays = compute_bitarray((potential_alignment[0], potential_alignment[1], local_ngram))\n",
    "                        if compare_bitarrays(current_pattern_bitarrays['A'], local_ngram_bitarrays['A']) or compare_bitarrays(current_pattern_bitarrays['B'], local_ngram_bitarrays['B']): # overlap; throw it away\n",
    "                            continue\n",
    "                        else: #transposed, but is it already in transposed-patterns list?\n",
    "                            decision_graph['nodes'][id]['transposed-patterns'].append((potential_alignment[0], potential_alignment[1], (local_ngram,)))\n",
    "\n",
    "\n",
    "#         #TEMP: transposed-patterns': [(2, 2, 'and the'), (4, 1, 'black')],\n",
    "#         for tp in decision_tree[id]['transposed-patterns']:\n",
    "#             # now we need to fill the bitarray; We need the start position in each witness and the length of the pattern.\n",
    "#             tp_ngram_length = ngram_length[tp[2]]\n",
    "#             ba1[tp[0]:tp[0] + tp_ngram_length] = 1\n",
    "#             ba2[tp[1]:tp[1] + tp_ngram_length] = 1\n",
    "\n",
    "#         # ba3 and ba4 record aligned pattern being added\n",
    "#         ba3 = bitarray(len(witnesses[0]))\n",
    "#         ba3.setall(0)\n",
    "#         ba4 = bitarray(len(witnesses[1]))\n",
    "#         ba4.setall(0)\n",
    "#         ba3[child[0]:child[0] + current_ngram_length] = 1\n",
    "#         ba4[child[1]:child[1] + current_ngram_length] = 1\n",
    "\n",
    "#         for p in decision_tree[parent_id]['potential-alignments-by-A']: # check for potentials and transpositions\n",
    "#             if p[0] > decision_tree[id]['current-location-in-A'] and p[1] > decision_tree[id]['current-location-in-B']:\n",
    "#                 decision_tree[id]['potential-alignments-by-A'].append(p) # both are to the right, so it's still potential\n",
    "#             else: # check whether it's a transposition or an overlap\n",
    "#                 for q in p[2]: # iterate over the different n-grams\n",
    "#                     q_ngram_length = ngram_length[q] # length of current ngram inside current potential\n",
    "#                     if ba3[p[0]:p[0] + q_ngram_length].any() or ba4[p[1]:p[1] + q_ngram_length].any(): # overlap; throw it away\n",
    "#                         continue\n",
    "#                     else: # transposition but is it alreadyin the transposed patterns property?\n",
    "#                         if ba1[p[0]:p[0] + q_ngram_length].any() or ba2[p[1]:p[1] + q_ngram_length].any(): # already among transpositions\n",
    "#                             continue\n",
    "#                         decision_tree[id]['transposed-patterns'].append((p[0], p[1], q)) # update bitarrays with the new transposed pattern\n",
    "#                         ba1[p[0]:p[0] + q_ngram_length] = 1\n",
    "#                         ba2[p[1]:p[1] + q_ngram_length] = 1\n",
    "\n",
    "            # potentials by A and B are the same tuples, but sorted differently\n",
    "            decision_graph['nodes'][id]['potential-alignments-by-B'] = sorted(decision_graph['nodes'][id]['potential-alignments-by-A'], key=lambda x: (x[1], x[0]))\n",
    "\n",
    "            #################################\n",
    "            # Add new row to df\n",
    "            #################################\n",
    "            node_tracker.loc[id] = [child[0], \\\n",
    "                                     child[0] + current_ngram_length - 1, \\\n",
    "                                     child[1], child[1] + current_ngram_length - 1, \\\n",
    "                                     compute_pattern_sum(decision_graph['nodes'][id]) \\\n",
    "                                    ]\n",
    "\n",
    "            #################################\n",
    "            # Add new edges to graph\n",
    "            #################################\n",
    "            decision_graph['edges']['incoming'][id].append(parent_id)\n",
    "            decision_graph['edges']['outgoing'][parent_id].append(id)\n",
    "\n",
    "            if decision_graph['nodes'][id]['potential-alignments-by-A']:\n",
    "                add_children(id) # recur to process children of new child\n",
    "\n",
    "#     # add type #3 (skip) node\n",
    "#     if len(decision_tree[parent_id]['children']) > 1:\n",
    "#         skip_node_id = len(decision_tree)\n",
    "#         decision_tree[skip_node_id] = {}\n",
    "#         decision_tree[skip_node_id]['id'] = skip_node_id\n",
    "#         decision_tree[skip_node_id]['type'] = 'skip'\n",
    "#         decision_tree[skip_node_id]['current-location-in-A'] = nearest_A_matches[0][0] + ngram_length[nearest_A_matches[0][2][0]] - 1\n",
    "#         decision_tree[skip_node_id]['current-location-in-B'] = nearest_B_matches[0][1] + ngram_length[nearest_B_matches[0][2][0]] - 1\n",
    "#         decision_tree[skip_node_id]['parent'] = parent_id\n",
    "#         decision_tree[skip_node_id]['children'] = []\n",
    "#         aligned_patterns = decision_tree[parent_id]['aligned-patterns'].copy() # aligned patterns don't change\n",
    "#         decision_tree[skip_node_id]['aligned-patterns'] = aligned_patterns\n",
    "#         transposed_patterns = decision_tree[parent_id]['transposed-patterns'].copy()\n",
    "#         decision_tree[skip_node_id]['transposed-patterns'] = transposed_patterns\n",
    "#         potential_alignments_by_A = decision_tree[parent_id]['potential-alignments-by-A'].copy() # keep only potential greater than current position\n",
    "#         decision_tree[skip_node_id]['potential-alignments-by-A'] = [t for t in potential_alignments_by_A if t[0] > decision_tree[skip_node_id]['current-location-in-A'] and t[1] > decision_tree[skip_node_id]['current-location-in-B']]\n",
    "#         decision_tree[skip_node_id]['potential-alignments-by-B'] = sorted(decision_tree[skip_node_id]['potential-alignments-by-A'], key=lambda x: (x[1], x[0]))\n",
    "#         decision_tree[parent_id]['children'].append(skip_node_id)\n",
    "\n",
    "#         # while figuring the new potential alignments by a and b we will find transpositions that we need to store.\n",
    "#         # We use bitarrays to track (avoid) overlap (subsequences) between detected transposed patterns.\n",
    "#         # ba1 and ba2 record transposed patterns\n",
    "#         from bitarray import bitarray\n",
    "#         ba1 = bitarray(len(witnesses[0]))\n",
    "#         ba1.setall(0)\n",
    "#         ba2 = bitarray(len(witnesses[1]))\n",
    "#         ba2.setall(0)\n",
    "\n",
    "#         #INFO: 'transposed-patterns' looks like: [(2, 2, 'and the'), (4, 1, 'black')],\n",
    "#         for tp in decision_tree[skip_node_id]['transposed-patterns']:\n",
    "#             # now we need to fill the bitarray; We need the start position in each witness and the length of the pattern.\n",
    "#             tp_ngram_length = ngram_length[tp[2]]\n",
    "#             ba1[tp[0]:tp[0] + tp_ngram_length] = 1\n",
    "#             ba2[tp[1]:tp[1] + tp_ngram_length] = 1\n",
    "\n",
    "#         for t in potential_alignments_by_A:\n",
    "#             if t[0] <= decision_tree[skip_node_id]['current-location-in-A'] or t[1] <= decision_tree[skip_node_id]['current-location-in-B']:\n",
    "#                 # transposition, but is it already in the transposed-patterns property?\n",
    "#                 t_ngram_length = ngram_length[t[2][0]]\n",
    "#                 if ba1[t[0]:t[0] + t_ngram_length].any() or ba2[t[1]:t[1] + t_ngram_length].any(): # already among transpositions\n",
    "#                     continue\n",
    "#                 decision_tree[skip_node_id]['transposed-patterns'].append((t[0], t[1], t[2][0])) # update bitarrays with the new transposed pattern\n",
    "#                 ba1[t[0]:t[0] + t_ngram_length] = 1\n",
    "#                 ba2[t[1]:t[1] + t_ngram_length] = 1\n",
    "\n",
    "#         if decision_tree[skip_node_id]['potential-alignments-by-A']:\n",
    "#             add_children(skip_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': defaultdict(dict,\n",
       "             {0: {'id': 0,\n",
       "               'type': None,\n",
       "               'current-location-in-A': -1,\n",
       "               'current-location-in-B': -1,\n",
       "               'aligned-patterns': [],\n",
       "               'transposed-patterns': [],\n",
       "               'potential-alignments-by-A': [(0, 0, ('the',)),\n",
       "                (0, 3, ('the red', 'the')),\n",
       "                (1, 4, ('red',)),\n",
       "                (2, 2, ('and the', 'and')),\n",
       "                (3, 0, ('the black', 'the')),\n",
       "                (3, 3, ('the',)),\n",
       "                (4, 1, ('black',)),\n",
       "                (5, 5, ('cat',))],\n",
       "               'potential-alignments-by-B': [(0, 0, ('the',)),\n",
       "                (3, 0, ('the black', 'the')),\n",
       "                (4, 1, ('black',)),\n",
       "                (2, 2, ('and the', 'and')),\n",
       "                (0, 3, ('the red', 'the')),\n",
       "                (3, 3, ('the',)),\n",
       "                (1, 4, ('red',)),\n",
       "                (5, 5, ('cat',))]},\n",
       "              1: {'id': 1,\n",
       "               'type': 'closest-in-both',\n",
       "               'current-location-in-A': 0,\n",
       "               'current-location-in-B': 0,\n",
       "               'aligned-patterns': [(0, 0, ('the',))],\n",
       "               'transposed-patterns': [],\n",
       "               'potential-alignments-by-A': [(1, 4, ('red',)),\n",
       "                (2, 2, ('and the', 'and')),\n",
       "                (3, 3, ('the',)),\n",
       "                (4, 1, ('black',)),\n",
       "                (5, 5, ('cat',))],\n",
       "               'potential-alignments-by-B': [(4, 1, ('black',)),\n",
       "                (2, 2, ('and the', 'and')),\n",
       "                (3, 3, ('the',)),\n",
       "                (1, 4, ('red',)),\n",
       "                (5, 5, ('cat',))]},\n",
       "              2: {'id': 2,\n",
       "               'type': 'closest-in-one',\n",
       "               'current-location-in-A': 1,\n",
       "               'current-location-in-B': 4,\n",
       "               'aligned-patterns': [(0, 0, ('the',)), (1, 4, ('red',))],\n",
       "               'transposed-patterns': [(2, 2, ('and the',)),\n",
       "                (2, 2, ('and',)),\n",
       "                (3, 3, ('the',)),\n",
       "                (4, 1, ('black',))],\n",
       "               'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "               'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       "              3: {'id': 3,\n",
       "               'type': 'closest-in-both',\n",
       "               'current-location-in-A': 5,\n",
       "               'current-location-in-B': 5,\n",
       "               'aligned-patterns': [(0, 0, ('the',)),\n",
       "                (1, 4, ('red',)),\n",
       "                (5, 5, ('cat',))],\n",
       "               'transposed-patterns': [(2, 2, ('and the',)),\n",
       "                (2, 2, ('and',)),\n",
       "                (3, 3, ('the',)),\n",
       "                (4, 1, ('black',))],\n",
       "               'potential-alignments-by-A': [],\n",
       "               'potential-alignments-by-B': []},\n",
       "              4: {'id': 4,\n",
       "               'type': 'closest-in-one',\n",
       "               'current-location-in-A': 4,\n",
       "               'current-location-in-B': 1,\n",
       "               'aligned-patterns': [(0, 0, ('the',)), (4, 1, ('black',))],\n",
       "               'transposed-patterns': [(1, 4, ('red',)),\n",
       "                (2, 2, ('and the',)),\n",
       "                (2, 2, ('and',)),\n",
       "                (3, 3, ('the',))],\n",
       "               'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "               'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       "              5: {'id': 5,\n",
       "               'type': 'closest-in-one',\n",
       "               'current-location-in-A': 1,\n",
       "               'current-location-in-B': 4,\n",
       "               'aligned-patterns': [(0, 3, ('the red', 'the'))],\n",
       "               'transposed-patterns': [(2, 2, ('and',)),\n",
       "                (3, 0, ('the black',)),\n",
       "                (3, 0, ('the',)),\n",
       "                (4, 1, ('black',))],\n",
       "               'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "               'potential-alignments-by-B': [(5, 5, ('cat',))]},\n",
       "              6: {'id': 6,\n",
       "               'type': 'closest-in-one',\n",
       "               'current-location-in-A': 4,\n",
       "               'current-location-in-B': 1,\n",
       "               'aligned-patterns': [(3, 0, ('the black', 'the'))],\n",
       "               'transposed-patterns': [(0, 3, ('the red',)),\n",
       "                (0, 3, ('the',)),\n",
       "                (1, 4, ('red',)),\n",
       "                (2, 2, ('and',))],\n",
       "               'potential-alignments-by-A': [(5, 5, ('cat',))],\n",
       "               'potential-alignments-by-B': [(5, 5, ('cat',))]}}),\n",
       " 'edges': {'incoming': defaultdict(list,\n",
       "              {1: [0], 2: [1], 3: [2, 4, 5, 6], 4: [1], 5: [0], 6: [0]}),\n",
       "  'outgoing': defaultdict(list,\n",
       "              {0: [1, 5, 6], 1: [2, 4], 2: [3], 4: [3], 5: [3], 6: [3]})}}"
      ]
     },
     "execution_count": 32,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process the root node to start building the graph recursively\n",
    "\n",
    "# Update root node to add children (recursively, to bottom of tree)\n",
    "add_children(0) # function uses global \"decision_graph\" dictionary\n",
    "\n",
    "# take a look\n",
    "decision_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_A</th>\n",
       "      <th>end_A</th>\n",
       "      <th>start_B</th>\n",
       "      <th>end_B</th>\n",
       "      <th>best_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_A  end_A  start_B  end_B  best_sum\n",
       "0       -1     -1       -1     -1         6\n",
       "1        0      0        0      0         6\n",
       "2        1      1        4      4         3\n",
       "3        5      5        5      5         3\n",
       "4        4      4        1      1         3\n",
       "5        0      1        3      4         3\n",
       "6        3      4        0      1         3"
      ]
     },
     "execution_count": 33,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_tracker # take a look at the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# get ready to visualize the decision tree in SVG\n",
    "import graphviz\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Render decision graph in SVG\n",
    "\n",
    "**Align** nodes are cyan; **transpose** nodes are pink\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"398pt\" height=\"260pt\" viewBox=\"0.00 0.00 397.84 260.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 393.84,-256 393.84,4 -4,4\"/>\n<!-- 1 -->\n<g id=\"node1\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"cyan\" stroke=\"cyan\" cx=\"132.1\" cy=\"-162\" rx=\"34.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"132.1\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">1:the</text>\n</g>\n<!-- 2 -->\n<g id=\"node2\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"pink\" stroke=\"pink\" cx=\"35.1\" cy=\"-90\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"35.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">2:red</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>1-&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M112.47,-146.83C98.27,-136.59 78.88,-122.59 63.06,-111.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"64.85,-108.16 54.7,-105.14 60.76,-113.83 64.85,-108.16\"/>\n</g>\n<!-- 4 -->\n<g id=\"node4\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"pink\" stroke=\"pink\" cx=\"132.1\" cy=\"-90\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"132.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">4:black</text>\n</g>\n<!-- 1&#45;&gt;4 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1-&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M132.1,-143.7C132.1,-135.98 132.1,-126.71 132.1,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.6,-118.1 132.1,-108.1 128.6,-118.1 135.6,-118.1\"/>\n</g>\n<!-- 3 -->\n<g id=\"node3\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"cyan\" stroke=\"cyan\" cx=\"189.1\" cy=\"-18\" rx=\"33.6\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"189.1\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">3:cat</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge6\" class=\"edge\">\n<title>2-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M60.53,-77.44C86.32,-65.72 126.39,-47.5 154.94,-34.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"156.48,-37.67 164.14,-30.34 153.59,-31.3 156.48,-37.67\"/>\n</g>\n<!-- 4&#45;&gt;3 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M145.32,-72.76C152.51,-63.93 161.55,-52.83 169.54,-43.01\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"172.35,-45.11 175.95,-35.15 166.92,-40.69 172.35,-45.11\"/>\n</g>\n<!-- 5 -->\n<g id=\"node5\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"pink\" stroke=\"pink\" cx=\"247.1\" cy=\"-90\" rx=\"53.09\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"247.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">5:the red</text>\n</g>\n<!-- 5&#45;&gt;3 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M233.35,-72.41C226.02,-63.57 216.88,-52.53 208.81,-42.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"211.42,-40.46 202.34,-34.99 206.03,-44.92 211.42,-40.46\"/>\n</g>\n<!-- 6 -->\n<g id=\"node6\" class=\"node\">\n<title>6</title>\n<ellipse fill=\"pink\" stroke=\"pink\" cx=\"328.1\" cy=\"-162\" rx=\"61.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"328.1\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">6:the black</text>\n</g>\n<!-- 6&#45;&gt;3 -->\n<g id=\"edge9\" class=\"edge\">\n<title>6-&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M328.84,-143.98C328.79,-124.49 325.84,-92.6 309.1,-72 289.54,-47.95 256.86,-34.49 230.53,-27.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"231.36,-23.76 220.8,-24.64 229.6,-30.53 231.36,-23.76\"/>\n</g>\n<!-- 0 -->\n<g id=\"node7\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"238.1\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"238.1\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">0</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0-&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M219.63,-220.81C203.55,-210.19 179.96,-194.61 161.32,-182.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.16,-179.32 152.89,-176.73 159.3,-185.16 163.16,-179.32\"/>\n</g>\n<!-- 0&#45;&gt;5 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0-&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M239.18,-215.87C240.72,-191.67 243.53,-147.21 245.36,-118.39\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"248.87,-118.39 246.01,-108.19 241.88,-117.95 248.87,-118.39\"/>\n</g>\n<!-- 0&#45;&gt;6 -->\n<g id=\"edge3\" class=\"edge\">\n<title>0-&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M255.03,-219.83C267.45,-210.17 284.64,-196.8 299.22,-185.46\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"301.71,-187.96 307.45,-179.06 297.41,-182.43 301.71,-187.96\"/>\n</g>\n</g>\n</svg>",
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 35,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Source: https://github.com/interedition/collatex/blob/master/collatex-pythonport/collatex/display_module.py\n",
    "# node id values must be strings for graphviz\n",
    "a = graphviz.Digraph(format=\"svg\")\n",
    "for key,value in decision_graph['nodes'].items():\n",
    "    if value['id'] != 0:\n",
    "        node_id = str(value['id'])\n",
    "        if value['type'] == 'closest-in-one':\n",
    "            fill_color = 'pink'\n",
    "        elif value['type'] == 'closest-in-both':\n",
    "            fill_color = 'cyan'\n",
    "        else:\n",
    "            fill_color = 'white'\n",
    "        try:\n",
    "            if value['type'] == 'skip':\n",
    "                ngram_text = 'skip'\n",
    "            else:\n",
    "                ngram_text = value['aligned-patterns'][len(value['aligned-patterns']) - 1][2][0]\n",
    "        except:\n",
    "            ngram_text = 'oops'\n",
    "        a.node(node_id, label=node_id + ':' + ngram_text, style='filled', color=fill_color)\n",
    "for key,values in decision_graph['edges']['outgoing'].items(): # values is list of integers\n",
    "    for value in values:\n",
    "        a.edge(str(key), str(value))\n",
    "SVG(a.view())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Output table of paths, sorted from best to worst\n",
    "\n",
    "Sort by, in order:\n",
    "\n",
    "1. Aligned token count (high is better)\n",
    "1. Path length (node count; low is better)\n",
    "1. Transposition count (pattern count; low is better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border><tr style=\"text-align:center;\"><th>Leaf<br/>id</th><th>Aligned<br/>tokens</th><th>Path<br/>length</th><th>Transposed<br/>patterns</th></tr><tr style=\"text-align:right;\"><td>3</td><td>3</td><td>3</td><td>4</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "evaluation_report = ['<table border><tr style=\"text-align:center;\"><th>Leaf<br/>id</th><th>Aligned<br/>tokens</th><th>Path<br/>length</th><th>Transposed<br/>patterns</th></tr>']\n",
    "evaluation_data = []\n",
    "for key, value in decision_graph['nodes'].items():\n",
    "    if not key in decision_graph['edges']['outgoing']: # it's a leaf node\n",
    "        path_length = len(value['aligned-patterns'])\n",
    "        token_count = 0 # counts tokens, not ngrams (nodes)\n",
    "        transposition_count = 0 # counts nodes (not tokens)\n",
    "        for t in value['aligned-patterns']:\n",
    "            token_count += ngram_lengths[t[2][0]]\n",
    "        for t in value['transposed-patterns']:\n",
    "            transposition_count += 1\n",
    "        evaluation_data.append((value['id'], token_count, path_length, transposition_count))\n",
    "evaluation_data.sort(key = lambda x : (-x[1], x[2], x[3], x[0]))\n",
    "for leaf in (evaluation_data):\n",
    "    evaluation_report.append('<tr style=\"text-align:right;\"><td>' + str(leaf[0]) + '</td><td>' + str(leaf[1]) + '</td><td>' + str(leaf[2]) + '</td><td>' + str(leaf[3]) + '</td></tr>')\n",
    "evaluation_report.append('</table>')\n",
    "HTML(''.join(evaluation_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}