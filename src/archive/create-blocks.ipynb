{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create blocks\n",
    "\n",
    "To be imported into other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Configure to show multiple value for development and debugging\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from typing import List\n",
    "from linsuffarr import SuffixArray\n",
    "from linsuffarr import UNIT_BYTE\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# dir(linsuffarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# two witnesses, with repetition and transposition\n",
    "\n",
    "# Original example, single leaf node\n",
    "# raw_data_dict = {\n",
    "#     'w0' : '''the red and the black cat''',\n",
    "#     'w1' : '''the black and the red cat'''\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Different lengths\n",
    "# w0 = '''the red and the black and blue cat'''\n",
    "# w1 = '''the black and the red cat'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Three witnesses\n",
    "# w0 = '''the red and the black cat'''\n",
    "# w1 = '''the black and the red cat'''\n",
    "# w2 = '''the black and red and the blue and green cat'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Three witnesses with transposition\n",
    "# w0 = '''the red and the black cat'''\n",
    "# w1 = '''the black and the red cat'''\n",
    "# w2 = '''the black and red and the blue and green cat'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Adjacent transposition\n",
    "# w1 = '''the red striped cat'''\n",
    "# w2 = '''the striped red cat'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Two leaf nodes\n",
    "# w1 = '''cat red black'''\n",
    "# w2 = '''cat black red'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Branches meet in the middle at koala and then split again, with two leaf nodes\n",
    "# w1 = \"\"\"cat red black koala brown gray\"\"\"\n",
    "# w2 = \"\"\"cat black red koala gray brown\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Two split and rejoin\n",
    "# w1 = '''the gray koala'''\n",
    "# w2 = '''the brown koala'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# medium example\n",
    "# w0 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ much more from each other, than do the individuals of any one\n",
    "# species or variety in a state of nature.'''\n",
    "# w1 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature.'''\n",
    "# w2 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Larger example with three witnesses\n",
    "# w0 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ much more from each other, than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this greater variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is, also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.'''\n",
    "# w1 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this great variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.'''\n",
    "# w2 = '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this great variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# # Larger example with six witnesses\n",
    "# raw_data_dict = {'w0' : '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ much more from each other, than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this greater variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is, also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.''',\n",
    "# 'w1' : '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this great variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.''',\n",
    "# 'w2' : '''WHEN we look to the individuals of the same variety or sub-variety of\n",
    "# our older cultivated plants and animals, one of the first points which strikes us, is,\n",
    "# that they generally differ more from each other than do the individuals of any one\n",
    "# species or variety in a state of nature. When we reflect on the vast diversity of the\n",
    "# plants and animals which have been cultivated, and which have varied during all ages\n",
    "# under the most different climates and treatment, I think we are driven to conclude that\n",
    "# this great variability is simply due to our domestic productions having been raised\n",
    "# under conditions of life not so uniform as, and somewhat different from, those to which\n",
    "# the parent-species have been exposed under nature. There is also, I think, some\n",
    "# probability in the view propounded by Andrew Knight, that this variability may be partly\n",
    "# connected with excess of food. It seems pretty clear that organic beings must be exposed\n",
    "# during several generations to the new conditions of life to cause any appreciable amount\n",
    "# of variation; and that when the organisation has once begun to vary, it generally\n",
    "# continues to vary for many generations. No case is on record of a variable being ceasing\n",
    "# to be variable under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# often yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.''',\n",
    "# 'w3' : '''Causes of Variability. WHEN we look to the individuals of the same\n",
    "# variety or sub-variety of our older cultivated plants and animals, one of the first\n",
    "# points which strikes us, is, that they generally differ more from each other than do the\n",
    "# individuals of any one species or variety in a state of nature. When we reflect on the\n",
    "# vast diversity of the plants and animals which have been cultivated, and which have\n",
    "# varied during all ages under the most different climates and treatment, I think we are\n",
    "# driven to conclude that this great variability is simply due to our domestic productions\n",
    "# having been raised under conditions of life not so uniform as, and somewhat different\n",
    "# from, those to which the parent-species have been exposed under nature. There is also, I\n",
    "# think, some probability in the view propounded by Andrew Knight, that this variability\n",
    "# may be partly connected with excess of food. It seems pretty clear that organic beings\n",
    "# must be exposed during several generations to the new conditions of life to cause any\n",
    "# appreciable amount of variation; and that, when the organisation has once begun to vary,\n",
    "# it generally continues to vary for many generations. No case is on record of a variable\n",
    "# being ceasing to be variable under cultivation. Our oldest cultivated plants, such as\n",
    "# wheat, still often yield new varieties: our oldest domesticated animals are still\n",
    "# capable of rapid improvement or modification.''',\n",
    "# 'w4' : '''Causes of Variability. WHEN we compare the individuals of the same variety or\n",
    "# sub-variety of our older cultivated plants and animals, one of the first points which\n",
    "# strikes us is, that they generally differ from each other more than do the individuals\n",
    "# of any one species or variety in a state of nature. And if we reflect on the vast\n",
    "# diversity of the plants and animals which have been cultivated, and which have varied\n",
    "# during all ages under the most different climates and treatment, we are driven to\n",
    "# conclude that this great variability is due to our domestic productions having been\n",
    "# raised under conditions of life not so uniform as, and somewhat different from, those\n",
    "# to which the parent-species had been exposed under nature. There is also, I think,\n",
    "# some probability in the view propounded by Andrew Knight, that this variability may\n",
    "# be partly connected with excess of food. It seems clear that organic beings must be\n",
    "# exposed during several generations to new conditions to cause any appreciable amount\n",
    "# of variation; and that, when the organisation has once begun to vary, it generally\n",
    "# continues varying for many generations. No case is on record of a variable organism\n",
    "# ceasing to vary under cultivation. Our oldest cultivated plants, such as wheat, still\n",
    "# yield new varieties: our oldest domesticated animals are still capable of rapid\n",
    "# improvement or modification.''',\n",
    "# 'w5' : '''Causes of Variability. WHEN we compare the individuals of the same variety or\n",
    "# sub-variety of our older cultivated plants and animals, one of the first points which\n",
    "# strikes us is, that they generally differ more from each other than do the individuals\n",
    "# of any one species or variety in a state of nature. And if we reflect on the vast\n",
    "# diversity of the plants and animals which have been cultivated, and which have varied\n",
    "# during all ages under the most different climates and treatment, we are driven to conclude\n",
    "# that this great variability is due to our domestic productions having been raised under\n",
    "# conditions of life not so uniform as, and somewhat different from, those to which the\n",
    "# parent-species had been exposed under nature. There is, also, some probability in the\n",
    "# view propounded by Andrew Knight, that this variability may be partly connected with\n",
    "# excess of food. It seems clear that organic beings must be exposed during several\n",
    "# generations to new conditions to cause any great amount of variation; and that, when\n",
    "# the organisation has once begun to vary, it generally continues varying for many\n",
    "# generations. No case is on record of a variable organism ceasing to vary under cultivation.\n",
    "# Our oldest cultivated plants, such as wheat, still yield new varieties: our oldest\n",
    "# domesticated animals are still capable of rapid improvement or modification.'''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# For discussion\n",
    "# raw_data_dict = {\n",
    "#     'w0': '''The red and the black cat''',\n",
    "#     'w1': '''The black and the red cat''',\n",
    "#     'w2': '''The big black and small green cat'''\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 paragraphs from 3 witnesses\n"
     ]
    }
   ],
   "source": [
    "# Load first chapter of six editions of the Origin of species from disk\n",
    "# Each paragraph is a line, with blank lines between (which we filter out)\n",
    "# sigla = ['w0', 'w1', 'w2', 'w3', 'w4', 'w5']\n",
    "# filenames = ['darwin1859.txt', 'darwin1860.txt', 'darwin1861.txt', 'darwin1866.txt', 'darwin1869.txt', 'darwin1872.txt', ]\n",
    "sigla = ['w0', 'w3', 'w4']\n",
    "filenames = ['darwin1859.txt', 'darwin1866.txt', 'darwin1869.txt']\n",
    "first_paragraph = 0\n",
    "last_paragraph = 2\n",
    "how_many_paragraphs = last_paragraph - first_paragraph\n",
    "raw_data_dict = {}\n",
    "for siglum, filename in zip(sigla, filenames):\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line for line in lines if line != '\\n']\n",
    "        raw_data_dict[siglum] = \" \".join(lines[first_paragraph : last_paragraph])\n",
    "# pp.pprint(raw_data_dict)\n",
    "print(f\"{how_many_paragraphs} paragraphs from {len(sigla)} witnesses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Work plan\n",
    "\n",
    "1. Create token array (Python **list**)\n",
    "1. Create suffix array\n",
    "1. Create LCP (**longest common prefix**) array\n",
    "1. Calculate LCP intervals\n",
    "1. Create patterns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Construct list of ngrams shared by witnesses\n",
    "\n",
    "Find ngrams and positions in witnesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tokenize witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def tokenize_witnesses(witness_strings: List[str]): # one string per witness\n",
    "    '''Return list of witnesses, each represented by a list of tokens'''\n",
    "    # TODO: handle punctuation, upper- vs lowercase\n",
    "    witnesses = []\n",
    "    for witness_string in witness_strings:\n",
    "        witness_tokens = witness_string.split()\n",
    "        witnesses.append(witness_tokens)\n",
    "    return witnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "witness_sigla = [key for key in raw_data_dict.keys()]\n",
    "witnesses = tokenize_witnesses([value for value in raw_data_dict.values()]) # strings\n",
    "# witnesses # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def create_token_array(witness_token_lists): # list of token lists per witness\n",
    "    '''Create token array (single list, with separator \" # \" between witnesses'''\n",
    "    token_array = []\n",
    "    token_membership_array = []\n",
    "    token_witness_offset_array = []\n",
    "    last_witness_offset = len(witness_token_lists) - 1\n",
    "    for index, witness_token_list in enumerate(witness_token_lists):\n",
    "        token_array.extend(witness_token_list)\n",
    "        for token_offset, token in enumerate(witness_token_list):\n",
    "            token_witness_offset_array.append(token_offset)\n",
    "        token_membership_array.extend([index for token in witness_token_list])\n",
    "        if index < last_witness_offset:\n",
    "            separator = \" #\" + str(index + 1) + \" \"\n",
    "            token_array.append(separator)\n",
    "            token_membership_array.append(separator)\n",
    "            token_witness_offset_array.append(-1)\n",
    "    return token_array, token_membership_array, token_witness_offset_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "token_array, token_membership_array, token_witness_offset_array = create_token_array(witnesses)\n",
    "# print(token_array) # take a look\n",
    "# print(token_membership_array)\n",
    "# print(token_witness_offset_array)\n",
    "# list(zip(token_array, token_membership_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# def create_suffix_array(_token_array):\n",
    "#     '''Add docstring'''\n",
    "#     _suffixes = []\n",
    "#     for index, tokens in enumerate(_token_array):\n",
    "#         suffix = _token_array[index:]\n",
    "#         _suffixes.append((suffix, index))\n",
    "#     _suffixes.sort() # sort in place\n",
    "#     return [x[1] for x in _suffixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "suffix_array = SuffixArray(token_array, unit=UNIT_BYTE)\n",
    "# suffix_array = create_suffix_array(token_array)\n",
    "# print(suffix_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# def create_lcp_array(_suffix_array, _token_array):\n",
    "#     '''compute LCP array\n",
    "#     which is a sequence of integers representing the number of tokens shared by consecutive alphabetically sorted suffixes\n",
    "#     sequential pairs of values in suffix array, which are two offsets in the sorted suffixes\n",
    "#     '''\n",
    "#     _lcp_array = [0]\n",
    "#     for i in range(0, len(_suffix_array) - 1): # for each pair of suffixes, retrieve list of tokens starting at that position\n",
    "#         pair = _suffix_array[i:i+2] # for each pair of suffixes\n",
    "#         suffix_1 = _token_array[pair[0]:] # tokens starting at first position\n",
    "#         suffix_2 = _token_array[pair[1]:] # tokens starting at second position\n",
    "#         # print(suffix_1, suffix_2) # diagnostic: verify that they're paired correctly\n",
    "#         # pair the tokens up by position, return (number of matches, first non-match)\n",
    "#         _lcp_value = next(filter(lambda t: t[1][0] != t[1][1], enumerate(zip(suffix_1, suffix_2))), min(len(suffix_1), len(suffix_2)))\n",
    "#         _lcp_array.append(_lcp_value[0] if type(_lcp_value) == tuple else _lcp_value) # most are tuples, but some are just an integer\n",
    "#     return _lcp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('i', [0, 0, 0, 0, 0, 48, 0, 0, 15, 40, 0, 0, 55, 0, 5, 0, 0, 0, 82, 0])\n"
     ]
    }
   ],
   "source": [
    "lcp_array = suffix_array._LCP_values\n",
    "# lcp_array = create_lcp_array(suffix_array, token_array)\n",
    "print(lcp_array[:20]) # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# uncomment to verify the accuracy of the lcp array\n",
    "# for offset in suffix_array:\n",
    "#     print(token_array[offset: offset + 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# Use LCP array to calculate patterns (efficiently)\n",
    "#   1. 0 means that whatever follows will have nothing in common with it\n",
    "#   2. Repetition of same number means same pattern\n",
    "#   3. Consecutive non-zero values identify how much of the pattern they have in common,\n",
    "#      Counts are always +1, so there must be two instances of \"the red\", two of \"the black\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# create Block dataclass\n",
    "from dataclasses import dataclass\n",
    "@dataclass(unsafe_hash=True)\n",
    "class Block:\n",
    "    token_count: int\n",
    "    start_position: int # offset into suffix array (not into token array!)\n",
    "    end_position: int # start and end position give number of occurrences\n",
    "    all_start_positions: [] # compute after blocks have been completed\n",
    "    witnesses: set\n",
    "    witness_count: int # number of witnesses in which pattern occurs, omitted temporarily because requires further computation\n",
    "    frequency: int # number of times pattern occurs in whole witness set (may be more than once in a witness), end_position - start_position + 1\n",
    "    # how_created: int # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def create_blocks (_lcp_array):\n",
    "    '''Create blocks from lcp array\n",
    "\n",
    "    Skip first lcp value, which is a fake; otherwise compare lcp value to length of block at top of stack.\n",
    "    Four possibilities:\n",
    "\n",
    "        stack is empty\n",
    "            * if lcp value == 0, proceed to next lcp value (continue)\n",
    "            * if lcp value > 0, create block and push onto stack, then proceed to next lcp value (continue)\n",
    "\n",
    "        lcp value (cannot equal 0) matches block length at top of stack\n",
    "            * proceed to next lcp value (continue)\n",
    "\n",
    "        lcp value (cannot equal 0) is longer than block length at top of stack\n",
    "            * create and push new block\n",
    "\n",
    "        lcp value is shorter than block length at top of stack\n",
    "            * (recursive) if block at top of stack is longer than current lcp value, pop and append to _blocks\n",
    "            * if block at top of stack is equal to lcp value, proceed to next lcp value (continue)\n",
    "            * if block at top of stack is shorter than current lcp value ...\n",
    "            *   create and push new block starting at start position of most recently closed block, then proceed to next lcp value (continue)\n",
    "\n",
    "    In other words:\n",
    "\n",
    "        We proceed to next lcp value if:\n",
    "            * stack is empty and lcp value == 0\n",
    "            * lcp value matches block length at top of stack (can we combine this with the preceding, since an empty stack effectively has a zero-length block on top?)\n",
    "\n",
    "        We push a new value on stack and then proceed to next lcp value if:\n",
    "            * stack is empty and lcp value > 0\n",
    "            * lcp value is longer than block length at top of stack (where is the start position?)\n",
    "\n",
    "        We pop from the stack to _blocks and then check the next stack value (stick with same lcp) if:\n",
    "            * lcp value is shorter than current block value\n",
    "\n",
    "cases (occurrences are always one more than number of repetitions):\n",
    "    5 5 2     --> 1 block of 5 occures 3 times, 1 block of 2 occures 4 times\n",
    "    2 5 5 2   --> 1 block of 2 occures 5 times, 1 block of 5 occures 3 times\n",
    "    5 5 0 2   --> 1 block of 5 occures 3 times, 1 block of 2 occures 2 times\n",
    "    2 5 5 2 3 --> \n",
    "\n",
    "\n",
    "Nested while structures:\n",
    "\n",
    "(Create blocks in two places because they have different start positions)\n",
    "(Nested while loops because we traverse two things: lcp array and, sometimes, stack)\n",
    "\n",
    "while next-lcp-value: # traverse lcp array\n",
    "    if something\n",
    "    elif something else\n",
    "    elif perhaps yet another something else\n",
    "    else: # possible hidden block (or possibly not)\n",
    "        while something-on-the-stack: # traverse stack for some lcp value situations\n",
    "            pop larger values\n",
    "        if hidden-block:\n",
    "            create and push\n",
    "clean-up-stack-after-last-lcp-value # or tack a 0 onto the end of the lcp to avoid extra clean-up code\n",
    "'''\n",
    "    from collections import deque # deque has faster append and pop than list\n",
    "    _blocks = []\n",
    "    open_block_stack = deque()\n",
    "    for offset, lcp in enumerate(lcp_array):\n",
    "        # three situations: next one is same value, higher that last, or lower than last\n",
    "        # if same value: same pattern\n",
    "        # if higher or lower, new pattern (may overlap with previous, unless one or the other value is 0)\n",
    "        peek = open_block_stack[-1] if open_block_stack else None\n",
    "        peek_token_count = peek.token_count if peek else 0\n",
    "        if offset == 0: # skip the first one, which is a transition from a fake start value\n",
    "            continue # resume loop with next item in lcp array\n",
    "        elif lcp == peek_token_count:\n",
    "            pass # same pattern (happens with repetition), so do nothing\n",
    "        elif lcp > peek_token_count: # new prefix is longer than previous one, so start new pattern\n",
    "            # can fill in end_position and frequency only when we encounter a shorter value in the LCP array\n",
    "            # start_position is number of patterns that are the same \n",
    "            open_block_stack.append(Block(token_count = lcp, start_position = offset - 1, end_position = -1, all_start_positions = [], witnesses = (), witness_count = -1, frequency = -1))\n",
    "        else: # new prefix is shorter than previous one, so:\n",
    "                # 1. close open blocks with higher values\n",
    "                # 2. do something else\n",
    "            while open_block_stack and open_block_stack[-1].token_count > lcp: # if an open block is longer than the current length, pop and close it\n",
    "                block_being_modified = open_block_stack.pop()\n",
    "                block_being_modified.end_position = offset - 1\n",
    "                block_being_modified.frequency = block_being_modified.end_position - block_being_modified.start_position + 1\n",
    "                _blocks.append(block_being_modified)\n",
    "            if lcp > 0 and (not open_block_stack or open_block_stack[-1].token_count < lcp):\n",
    "                open_block_stack.append(Block(token_count = lcp, start_position = _blocks[-1].start_position, end_position = -1, all_start_positions = [], witnesses = (), witness_count = -1, frequency = -1))\n",
    "\n",
    "    while open_block_stack: # pop anything left in open_block_stack\n",
    "        block_being_modified = open_block_stack.pop()\n",
    "        block_being_modified.end_position = len(lcp_array) - 1\n",
    "        block_being_modified.frequency = block_being_modified.end_position - block_being_modified.start_position + 1\n",
    "        _blocks.append(block_being_modified)\n",
    "\n",
    "    # add all_start_positions and then witness_count properties to blocks\n",
    "    for _index, _block in enumerate(_blocks):\n",
    "        # block_start_position through block_end_position gives offsets of all start positions in suffix_array\n",
    "        _block.all_start_positions = sorted([suffix_array.SA[x] for x in range(_block.start_position,_block.end_position + 1)])\n",
    "        # use all start positions to find witness count\n",
    "        _block.witnesses = set(token_membership_array[offset] for offset in _block.all_start_positions)\n",
    "        _block.witness_count = len(_block.witnesses)\n",
    "    return _blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "blocks = create_blocks(lcp_array)\n",
    "# blocks # take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "# diagnostic: are the blocks complete and correct\n",
    "# print('Token array:', token_array)\n",
    "# for block in blocks:\n",
    "#     print(token_array[suffix_array[block.start_position]:suffix_array[block.start_position] + block.token_count])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "## What to do\n",
    "\n",
    "NOTE: This is a simplified greedy approach; will later be integrated into decision tree / graph\n",
    "\n",
    "### Create data structure to store results\n",
    "\n",
    "Eventually this will be a variant graph, but it's easier to build otherwise and construct the graph later. Interim\n",
    "structure is a list of occurrences, which can be compared to a topological sort of a variant graph, and can be used\n",
    "to construct a full variant graph later.\n",
    "\n",
    "### Assign priority to blocks\n",
    "\n",
    "1. Favor those with high witness count, high token count, low frequency (and no transpositions, which we don't know yet); sort blocks by descending priority\n",
    "1. Priority = number of witnesses (depth) divided by (frequency * length) (er … we no longer remember why we selected this formula, but it seemed like a Good Idea)\n",
    "1. Sort blocks by priority from higher to lower, break ties arbitrarily from beginning of alphabet (blocks are already sorted alphabetically)\n",
    "\n",
    "NOTE: We do not take transpositions into consideration, although ultimately the matter, because in the graph \n",
    "approach we'll consider more than one possibility.\n",
    "\n",
    "### Select highest-priority remaining block\n",
    "\n",
    "1. Take all occurrences of current block\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def priority(block: Block) -> float:\n",
    "    '''Priority ranges from 0 to ∞\n",
    "\n",
    "    depth (number of witnesses) / (frequency * length)\n",
    "        modified (by trial and error) to weight the components\n",
    "    scale: # TODO: how can we set these in a generally meaningful way?\n",
    "        high depth (more witnesses) is most important\n",
    "        low frequency (less repetition) is next most important\n",
    "        high length (token count) is least important\n",
    "    higher numbers are better\n",
    "        distance between neighboring values is irrelevant; all that matters is order\n",
    "    '''\n",
    "    # score = pow(block.witness_count,4) / (pow(block.frequency,3) * block.token_count)\n",
    "    score = pow(block.witness_count,6)  * block.token_count / pow(block.frequency,3)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from typing import List\n",
    "def sort_blocks_by_priority (_blocks: List[Block]) -> List[Block]:\n",
    "    return sorted(_blocks, key=lambda x: priority(x), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "prioritized_blocks = sort_blocks_by_priority(blocks)\n",
    "# take a look\n",
    "# [(token_array[suffix_array[_block.start_position]:suffix_array[_block.start_position] + _block.token_count], priority(_block)) for _block in prioritized_blocks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(prioritized_blocks)=1063\n",
      "len(lcp_array)=1916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Block(token_count=174, start_position=1848, end_position=1849, all_start_positions=[178, 864], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=173, start_position=1540, end_position=1541, all_start_positions=[179, 865], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=172, start_position=1178, end_position=1179, all_start_positions=[180, 866], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=171, start_position=722, end_position=723, all_start_positions=[181, 867], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=170, start_position=1135, end_position=1136, all_start_positions=[182, 868], witnesses={0, 1}, witness_count=2, frequency=2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{len(prioritized_blocks)=}\")\n",
    "print(f\"{len(lcp_array)=}\")\n",
    "prioritized_blocks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Block(token_count=48, start_position=4, end_position=5, all_start_positions=[632, 1321], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=40, start_position=8, end_position=9, all_start_positions=[137, 823], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=15, start_position=7, end_position=9, all_start_positions=[137, 823, 1507], witnesses={0, 1, 2}, witness_count=3, frequency=3),\n",
       " Block(token_count=55, start_position=11, end_position=12, all_start_positions=[297, 983], witnesses={0, 1}, witness_count=2, frequency=2),\n",
       " Block(token_count=5, start_position=13, end_position=14, all_start_positions=[684, 1371], witnesses={1, 2}, witness_count=2, frequency=2)]"
      ]
     },
     "execution_count": 34,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# maintain token-to-block multivalued dictionary (defaultdict, imported from collections below)\n",
    "from collections import defaultdict\n",
    "\n",
    "def add_token_to_block_mapping(token_to_block_dict: defaultdict, token_offset: int, block: Block) -> defaultdict:\n",
    "    token_to_block_dict[token_offset].append(block)\n",
    "    return token_to_block_dict\n",
    "\n",
    "def create_token_to_block_dict(blocks: List[Block]) -> defaultdict:\n",
    "    token_to_block_dict = defaultdict(list) # mapping from token offset to list of blocks that contain the token\n",
    "    for index, block in enumerate(prioritized_blocks):\n",
    "        for block_start_position in block.all_start_positions:\n",
    "            for block_token_offset in range(block.token_count):\n",
    "                add_token_to_block_mapping(token_to_block_dict, block_start_position + block_token_offset, index)\n",
    "    return token_to_block_dict\n",
    "\n",
    "token_to_block_dict = create_token_to_block_dict(prioritized_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Some output was deleted.\n"
     ]
    }
   ],
   "source": [
    "# diagnostic\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(enumerate(token_array))\n",
    "pp.pprint(prioritized_blocks)\n",
    "for token_position, block_ids in sorted(token_to_block_dict.items()):\n",
    "    print(\"Token:\", token_array[token_position] , \"(\", token_position , \"in witness\", token_membership_array[token_position] , \")\")\n",
    "    for block_id in block_ids:\n",
    "        print(block_id, \":\", blocks[block_id])\n",
    "    print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}